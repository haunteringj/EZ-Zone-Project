{"version":3,"file":"database-3cfd76ce-6b4521db.js","sources":["../node-esm2017/database-3cfd76ce.js"],"sourcesContent":["import { getModularInstance } from '@firebase/util';\nimport { Logger, LogLevel } from '@firebase/logger';\nimport { inspect, TextEncoder, TextDecoder } from 'util';\nimport { randomBytes as randomBytes$1 } from 'crypto';\nimport { credentials, Metadata, loadPackageDefinition } from '@grpc/grpc-js';\nimport { version as version$1 } from '@grpc/grpc-js/package.json';\nimport { resolve, join } from 'path';\nimport { loadSync } from '@grpc/proto-loader';\n\n/**\r\n * @license\r\n * Copyright 2018 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\n/**\r\n * `ListenSequence` is a monotonic sequence. It is initialized with a minimum value to\r\n * exceed. All subsequent calls to next will return increasing values. If provided with a\r\n * `SequenceNumberSyncer`, it will additionally bump its next value when told of a new value, as\r\n * well as write out sequence numbers that it produces via `next()`.\r\n */\r\nclass ListenSequence {\r\n    constructor(previousValue, sequenceNumberSyncer) {\r\n        this.previousValue = previousValue;\r\n        if (sequenceNumberSyncer) {\r\n            sequenceNumberSyncer.sequenceNumberHandler = sequenceNumber => this.setPreviousValue(sequenceNumber);\r\n            this.writeNewSequenceNumber = sequenceNumber => sequenceNumberSyncer.writeSequenceNumber(sequenceNumber);\r\n        }\r\n    }\r\n    setPreviousValue(externalPreviousValue) {\r\n        this.previousValue = Math.max(externalPreviousValue, this.previousValue);\r\n        return this.previousValue;\r\n    }\r\n    next() {\r\n        const nextValue = ++this.previousValue;\r\n        if (this.writeNewSequenceNumber) {\r\n            this.writeNewSequenceNumber(nextValue);\r\n        }\r\n        return nextValue;\r\n    }\r\n}\r\nListenSequence.INVALID = -1;\n\nconst version = \"8.4.0\";\n\n/**\r\n * @license\r\n * Copyright 2020 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\n/** Formats an object as a JSON string, suitable for logging. */\r\nfunction formatJSON(value) {\r\n    // util.inspect() results in much more readable output than JSON.stringify()\r\n    return inspect(value, { depth: 100 });\r\n}\n\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\nconst logClient = new Logger('@firebase/firestore');\r\n// Helper methods are needed because variables can't be exported as read/write\r\nfunction getLogLevel() {\r\n    return logClient.logLevel;\r\n}\r\n/**\r\n * Sets the verbosity of Cloud Firestore logs (debug, error, or silent).\r\n *\r\n * @param logLevel - The verbosity you set for activity and error logging. Can\r\n *   be any of the following values:\r\n *\r\n *   <ul>\r\n *     <li>`debug` for the most verbose logging level, primarily for\r\n *     debugging.</li>\r\n *     <li>`error` to log errors only.</li>\r\n *     <li><code>`silent` to turn off logging.</li>\r\n *   </ul>\r\n */\r\nfunction setLogLevel(logLevel) {\r\n    logClient.setLogLevel(logLevel);\r\n}\r\nfunction logDebug(msg, ...obj) {\r\n    if (logClient.logLevel <= LogLevel.DEBUG) {\r\n        const args = obj.map(argToString);\r\n        logClient.debug(`Firestore (${version}): ${msg}`, ...args);\r\n    }\r\n}\r\nfunction logError(msg, ...obj) {\r\n    if (logClient.logLevel <= LogLevel.ERROR) {\r\n        const args = obj.map(argToString);\r\n        logClient.error(`Firestore (${version}): ${msg}`, ...args);\r\n    }\r\n}\r\nfunction logWarn(msg, ...obj) {\r\n    if (logClient.logLevel <= LogLevel.WARN) {\r\n        const args = obj.map(argToString);\r\n        logClient.warn(`Firestore (${version}): ${msg}`, ...args);\r\n    }\r\n}\r\n/**\r\n * Converts an additional log parameter to a string representation.\r\n */\r\nfunction argToString(obj) {\r\n    if (typeof obj === 'string') {\r\n        return obj;\r\n    }\r\n    else {\r\n        try {\r\n            return formatJSON(obj);\r\n        }\r\n        catch (e) {\r\n            // Converting to JSON failed, just log the object directly\r\n            return obj;\r\n        }\r\n    }\r\n}\n\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\n/**\r\n * Unconditionally fails, throwing an Error with the given message.\r\n * Messages are stripped in production builds.\r\n *\r\n * Returns `never` and can be used in expressions:\r\n * @example\r\n * let futureVar = fail('not implemented yet');\r\n */\r\nfunction fail(failure = 'Unexpected state') {\r\n    // Log the failure in addition to throw an exception, just in case the\r\n    // exception is swallowed.\r\n    const message = `FIRESTORE (${version}) INTERNAL ASSERTION FAILED: ` + failure;\r\n    logError(message);\r\n    // NOTE: We don't use FirestoreError here because these are internal failures\r\n    // that cannot be handled by the user. (Also it would create a circular\r\n    // dependency between the error and assert modules which doesn't work.)\r\n    throw new Error(message);\r\n}\r\n/**\r\n * Fails if the given assertion condition is false, throwing an Error with the\r\n * given message if it did.\r\n *\r\n * Messages are stripped in production builds.\r\n */\r\nfunction hardAssert(assertion, message) {\r\n    if (!assertion) {\r\n        fail();\r\n    }\r\n}\r\n/**\r\n * Casts `obj` to `T`. In non-production builds, verifies that `obj` is an\r\n * instance of `T` before casting.\r\n */\r\nfunction debugCast(obj, \r\n// eslint-disable-next-line @typescript-eslint/no-explicit-any\r\nconstructor) {\r\n    return obj;\r\n}\n\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\nconst Code = {\r\n    // Causes are copied from:\r\n    // https://github.com/grpc/grpc/blob/bceec94ea4fc5f0085d81235d8e1c06798dc341a/include/grpc%2B%2B/impl/codegen/status_code_enum.h\r\n    /** Not an error; returned on success. */\r\n    OK: 'ok',\r\n    /** The operation was cancelled (typically by the caller). */\r\n    CANCELLED: 'cancelled',\r\n    /** Unknown error or an error from a different error domain. */\r\n    UNKNOWN: 'unknown',\r\n    /**\r\n     * Client specified an invalid argument. Note that this differs from\r\n     * FAILED_PRECONDITION. INVALID_ARGUMENT indicates arguments that are\r\n     * problematic regardless of the state of the system (e.g., a malformed file\r\n     * name).\r\n     */\r\n    INVALID_ARGUMENT: 'invalid-argument',\r\n    /**\r\n     * Deadline expired before operation could complete. For operations that\r\n     * change the state of the system, this error may be returned even if the\r\n     * operation has completed successfully. For example, a successful response\r\n     * from a server could have been delayed long enough for the deadline to\r\n     * expire.\r\n     */\r\n    DEADLINE_EXCEEDED: 'deadline-exceeded',\r\n    /** Some requested entity (e.g., file or directory) was not found. */\r\n    NOT_FOUND: 'not-found',\r\n    /**\r\n     * Some entity that we attempted to create (e.g., file or directory) already\r\n     * exists.\r\n     */\r\n    ALREADY_EXISTS: 'already-exists',\r\n    /**\r\n     * The caller does not have permission to execute the specified operation.\r\n     * PERMISSION_DENIED must not be used for rejections caused by exhausting\r\n     * some resource (use RESOURCE_EXHAUSTED instead for those errors).\r\n     * PERMISSION_DENIED must not be used if the caller can not be identified\r\n     * (use UNAUTHENTICATED instead for those errors).\r\n     */\r\n    PERMISSION_DENIED: 'permission-denied',\r\n    /**\r\n     * The request does not have valid authentication credentials for the\r\n     * operation.\r\n     */\r\n    UNAUTHENTICATED: 'unauthenticated',\r\n    /**\r\n     * Some resource has been exhausted, perhaps a per-user quota, or perhaps the\r\n     * entire file system is out of space.\r\n     */\r\n    RESOURCE_EXHAUSTED: 'resource-exhausted',\r\n    /**\r\n     * Operation was rejected because the system is not in a state required for\r\n     * the operation's execution. For example, directory to be deleted may be\r\n     * non-empty, an rmdir operation is applied to a non-directory, etc.\r\n     *\r\n     * A litmus test that may help a service implementor in deciding\r\n     * between FAILED_PRECONDITION, ABORTED, and UNAVAILABLE:\r\n     *  (a) Use UNAVAILABLE if the client can retry just the failing call.\r\n     *  (b) Use ABORTED if the client should retry at a higher-level\r\n     *      (e.g., restarting a read-modify-write sequence).\r\n     *  (c) Use FAILED_PRECONDITION if the client should not retry until\r\n     *      the system state has been explicitly fixed. E.g., if an \"rmdir\"\r\n     *      fails because the directory is non-empty, FAILED_PRECONDITION\r\n     *      should be returned since the client should not retry unless\r\n     *      they have first fixed up the directory by deleting files from it.\r\n     *  (d) Use FAILED_PRECONDITION if the client performs conditional\r\n     *      REST Get/Update/Delete on a resource and the resource on the\r\n     *      server does not match the condition. E.g., conflicting\r\n     *      read-modify-write on the same resource.\r\n     */\r\n    FAILED_PRECONDITION: 'failed-precondition',\r\n    /**\r\n     * The operation was aborted, typically due to a concurrency issue like\r\n     * sequencer check failures, transaction aborts, etc.\r\n     *\r\n     * See litmus test above for deciding between FAILED_PRECONDITION, ABORTED,\r\n     * and UNAVAILABLE.\r\n     */\r\n    ABORTED: 'aborted',\r\n    /**\r\n     * Operation was attempted past the valid range. E.g., seeking or reading\r\n     * past end of file.\r\n     *\r\n     * Unlike INVALID_ARGUMENT, this error indicates a problem that may be fixed\r\n     * if the system state changes. For example, a 32-bit file system will\r\n     * generate INVALID_ARGUMENT if asked to read at an offset that is not in the\r\n     * range [0,2^32-1], but it will generate OUT_OF_RANGE if asked to read from\r\n     * an offset past the current file size.\r\n     *\r\n     * There is a fair bit of overlap between FAILED_PRECONDITION and\r\n     * OUT_OF_RANGE. We recommend using OUT_OF_RANGE (the more specific error)\r\n     * when it applies so that callers who are iterating through a space can\r\n     * easily look for an OUT_OF_RANGE error to detect when they are done.\r\n     */\r\n    OUT_OF_RANGE: 'out-of-range',\r\n    /** Operation is not implemented or not supported/enabled in this service. */\r\n    UNIMPLEMENTED: 'unimplemented',\r\n    /**\r\n     * Internal errors. Means some invariants expected by underlying System has\r\n     * been broken. If you see one of these errors, Something is very broken.\r\n     */\r\n    INTERNAL: 'internal',\r\n    /**\r\n     * The service is currently unavailable. This is a most likely a transient\r\n     * condition and may be corrected by retrying with a backoff.\r\n     *\r\n     * See litmus test above for deciding between FAILED_PRECONDITION, ABORTED,\r\n     * and UNAVAILABLE.\r\n     */\r\n    UNAVAILABLE: 'unavailable',\r\n    /** Unrecoverable data loss or corruption. */\r\n    DATA_LOSS: 'data-loss'\r\n};\r\n/** An error returned by a Firestore operation. */\r\nclass FirestoreError extends Error {\r\n    /** @hideconstructor */\r\n    constructor(\r\n    /**\r\n     * The backend error code associated with this error.\r\n     */\r\n    code, \r\n    /**\r\n     * A custom error description.\r\n     */\r\n    message) {\r\n        super(message);\r\n        this.code = code;\r\n        this.message = message;\r\n        /** The custom name for all FirestoreErrors. */\r\n        this.name = 'FirebaseError';\r\n        // HACK: We write a toString property directly because Error is not a real\r\n        // class and so inheritance does not work correctly. We could alternatively\r\n        // do the same \"back-door inheritance\" trick that FirebaseError does.\r\n        this.toString = () => `${this.name}: [code=${this.code}]: ${this.message}`;\r\n    }\r\n}\n\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\nconst DOCUMENT_KEY_NAME = '__name__';\r\n/**\r\n * Path represents an ordered sequence of string segments.\r\n */\r\nclass BasePath {\r\n    constructor(segments, offset, length) {\r\n        if (offset === undefined) {\r\n            offset = 0;\r\n        }\r\n        else if (offset > segments.length) {\r\n            fail();\r\n        }\r\n        if (length === undefined) {\r\n            length = segments.length - offset;\r\n        }\r\n        else if (length > segments.length - offset) {\r\n            fail();\r\n        }\r\n        this.segments = segments;\r\n        this.offset = offset;\r\n        this.len = length;\r\n    }\r\n    get length() {\r\n        return this.len;\r\n    }\r\n    isEqual(other) {\r\n        return BasePath.comparator(this, other) === 0;\r\n    }\r\n    child(nameOrPath) {\r\n        const segments = this.segments.slice(this.offset, this.limit());\r\n        if (nameOrPath instanceof BasePath) {\r\n            nameOrPath.forEach(segment => {\r\n                segments.push(segment);\r\n            });\r\n        }\r\n        else {\r\n            segments.push(nameOrPath);\r\n        }\r\n        return this.construct(segments);\r\n    }\r\n    /** The index of one past the last segment of the path. */\r\n    limit() {\r\n        return this.offset + this.length;\r\n    }\r\n    popFirst(size) {\r\n        size = size === undefined ? 1 : size;\r\n        return this.construct(this.segments, this.offset + size, this.length - size);\r\n    }\r\n    popLast() {\r\n        return this.construct(this.segments, this.offset, this.length - 1);\r\n    }\r\n    firstSegment() {\r\n        return this.segments[this.offset];\r\n    }\r\n    lastSegment() {\r\n        return this.get(this.length - 1);\r\n    }\r\n    get(index) {\r\n        return this.segments[this.offset + index];\r\n    }\r\n    isEmpty() {\r\n        return this.length === 0;\r\n    }\r\n    isPrefixOf(other) {\r\n        if (other.length < this.length) {\r\n            return false;\r\n        }\r\n        for (let i = 0; i < this.length; i++) {\r\n            if (this.get(i) !== other.get(i)) {\r\n                return false;\r\n            }\r\n        }\r\n        return true;\r\n    }\r\n    isImmediateParentOf(potentialChild) {\r\n        if (this.length + 1 !== potentialChild.length) {\r\n            return false;\r\n        }\r\n        for (let i = 0; i < this.length; i++) {\r\n            if (this.get(i) !== potentialChild.get(i)) {\r\n                return false;\r\n            }\r\n        }\r\n        return true;\r\n    }\r\n    forEach(fn) {\r\n        for (let i = this.offset, end = this.limit(); i < end; i++) {\r\n            fn(this.segments[i]);\r\n        }\r\n    }\r\n    toArray() {\r\n        return this.segments.slice(this.offset, this.limit());\r\n    }\r\n    static comparator(p1, p2) {\r\n        const len = Math.min(p1.length, p2.length);\r\n        for (let i = 0; i < len; i++) {\r\n            const left = p1.get(i);\r\n            const right = p2.get(i);\r\n            if (left < right) {\r\n                return -1;\r\n            }\r\n            if (left > right) {\r\n                return 1;\r\n            }\r\n        }\r\n        if (p1.length < p2.length) {\r\n            return -1;\r\n        }\r\n        if (p1.length > p2.length) {\r\n            return 1;\r\n        }\r\n        return 0;\r\n    }\r\n}\r\n/**\r\n * A slash-separated path for navigating resources (documents and collections)\r\n * within Firestore.\r\n */\r\nclass ResourcePath extends BasePath {\r\n    construct(segments, offset, length) {\r\n        return new ResourcePath(segments, offset, length);\r\n    }\r\n    canonicalString() {\r\n        // NOTE: The client is ignorant of any path segments containing escape\r\n        // sequences (e.g. __id123__) and just passes them through raw (they exist\r\n        // for legacy reasons and should not be used frequently).\r\n        return this.toArray().join('/');\r\n    }\r\n    toString() {\r\n        return this.canonicalString();\r\n    }\r\n    /**\r\n     * Creates a resource path from the given slash-delimited string. If multiple\r\n     * arguments are provided, all components are combined. Leading and trailing\r\n     * slashes from all components are ignored.\r\n     */\r\n    static fromString(...pathComponents) {\r\n        // NOTE: The client is ignorant of any path segments containing escape\r\n        // sequences (e.g. __id123__) and just passes them through raw (they exist\r\n        // for legacy reasons and should not be used frequently).\r\n        const segments = [];\r\n        for (const path of pathComponents) {\r\n            if (path.indexOf('//') >= 0) {\r\n                throw new FirestoreError(Code.INVALID_ARGUMENT, `Invalid segment (${path}). Paths must not contain // in them.`);\r\n            }\r\n            // Strip leading and traling slashed.\r\n            segments.push(...path.split('/').filter(segment => segment.length > 0));\r\n        }\r\n        return new ResourcePath(segments);\r\n    }\r\n    static emptyPath() {\r\n        return new ResourcePath([]);\r\n    }\r\n}\r\nconst identifierRegExp = /^[_a-zA-Z][_a-zA-Z0-9]*$/;\r\n/** A dot-separated path for navigating sub-objects within a document. */\r\nclass FieldPath extends BasePath {\r\n    construct(segments, offset, length) {\r\n        return new FieldPath(segments, offset, length);\r\n    }\r\n    /**\r\n     * Returns true if the string could be used as a segment in a field path\r\n     * without escaping.\r\n     */\r\n    static isValidIdentifier(segment) {\r\n        return identifierRegExp.test(segment);\r\n    }\r\n    canonicalString() {\r\n        return this.toArray()\r\n            .map(str => {\r\n            str = str.replace(/\\\\/g, '\\\\\\\\').replace(/`/g, '\\\\`');\r\n            if (!FieldPath.isValidIdentifier(str)) {\r\n                str = '`' + str + '`';\r\n            }\r\n            return str;\r\n        })\r\n            .join('.');\r\n    }\r\n    toString() {\r\n        return this.canonicalString();\r\n    }\r\n    /**\r\n     * Returns true if this field references the key of a document.\r\n     */\r\n    isKeyField() {\r\n        return this.length === 1 && this.get(0) === DOCUMENT_KEY_NAME;\r\n    }\r\n    /**\r\n     * The field designating the key of a document.\r\n     */\r\n    static keyField() {\r\n        return new FieldPath([DOCUMENT_KEY_NAME]);\r\n    }\r\n    /**\r\n     * Parses a field string from the given server-formatted string.\r\n     *\r\n     * - Splitting the empty string is not allowed (for now at least).\r\n     * - Empty segments within the string (e.g. if there are two consecutive\r\n     *   separators) are not allowed.\r\n     *\r\n     * TODO(b/37244157): we should make this more strict. Right now, it allows\r\n     * non-identifier path components, even if they aren't escaped.\r\n     */\r\n    static fromServerFormat(path) {\r\n        const segments = [];\r\n        let current = '';\r\n        let i = 0;\r\n        const addCurrentSegment = () => {\r\n            if (current.length === 0) {\r\n                throw new FirestoreError(Code.INVALID_ARGUMENT, `Invalid field path (${path}). Paths must not be empty, begin ` +\r\n                    `with '.', end with '.', or contain '..'`);\r\n            }\r\n            segments.push(current);\r\n            current = '';\r\n        };\r\n        let inBackticks = false;\r\n        while (i < path.length) {\r\n            const c = path[i];\r\n            if (c === '\\\\') {\r\n                if (i + 1 === path.length) {\r\n                    throw new FirestoreError(Code.INVALID_ARGUMENT, 'Path has trailing escape character: ' + path);\r\n                }\r\n                const next = path[i + 1];\r\n                if (!(next === '\\\\' || next === '.' || next === '`')) {\r\n                    throw new FirestoreError(Code.INVALID_ARGUMENT, 'Path has invalid escape sequence: ' + path);\r\n                }\r\n                current += next;\r\n                i += 2;\r\n            }\r\n            else if (c === '`') {\r\n                inBackticks = !inBackticks;\r\n                i++;\r\n            }\r\n            else if (c === '.' && !inBackticks) {\r\n                addCurrentSegment();\r\n                i++;\r\n            }\r\n            else {\r\n                current += c;\r\n                i++;\r\n            }\r\n        }\r\n        addCurrentSegment();\r\n        if (inBackticks) {\r\n            throw new FirestoreError(Code.INVALID_ARGUMENT, 'Unterminated ` in path: ' + path);\r\n        }\r\n        return new FieldPath(segments);\r\n    }\r\n    static emptyPath() {\r\n        return new FieldPath([]);\r\n    }\r\n}\n\n/**\r\n * @license\r\n * Copyright 2020 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\nconst PRIMARY_LEASE_LOST_ERROR_MSG = 'The current tab is not in the required state to perform this operation. ' +\r\n    'It might be necessary to refresh the browser tab.';\r\n/**\r\n * A base class representing a persistence transaction, encapsulating both the\r\n * transaction's sequence numbers as well as a list of onCommitted listeners.\r\n *\r\n * When you call Persistence.runTransaction(), it will create a transaction and\r\n * pass it to your callback. You then pass it to any method that operates\r\n * on persistence.\r\n */\r\nclass PersistenceTransaction {\r\n    constructor() {\r\n        this.onCommittedListeners = [];\r\n    }\r\n    addOnCommittedListener(listener) {\r\n        this.onCommittedListeners.push(listener);\r\n    }\r\n    raiseOnCommittedEvent() {\r\n        this.onCommittedListeners.forEach(listener => listener());\r\n    }\r\n}\n\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\nclass Deferred {\r\n    constructor() {\r\n        this.promise = new Promise((resolve, reject) => {\r\n            this.resolve = resolve;\r\n            this.reject = reject;\r\n        });\r\n    }\r\n}\n\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\n/**\r\n * PersistencePromise is essentially a re-implementation of Promise except\r\n * it has a .next() method instead of .then() and .next() and .catch() callbacks\r\n * are executed synchronously when a PersistencePromise resolves rather than\r\n * asynchronously (Promise implementations use setImmediate() or similar).\r\n *\r\n * This is necessary to interoperate with IndexedDB which will automatically\r\n * commit transactions if control is returned to the event loop without\r\n * synchronously initiating another operation on the transaction.\r\n *\r\n * NOTE: .then() and .catch() only allow a single consumer, unlike normal\r\n * Promises.\r\n */\r\nclass PersistencePromise {\r\n    constructor(callback) {\r\n        // NOTE: next/catchCallback will always point to our own wrapper functions,\r\n        // not the user's raw next() or catch() callbacks.\r\n        this.nextCallback = null;\r\n        this.catchCallback = null;\r\n        // When the operation resolves, we'll set result or error and mark isDone.\r\n        this.result = undefined;\r\n        this.error = undefined;\r\n        this.isDone = false;\r\n        // Set to true when .then() or .catch() are called and prevents additional\r\n        // chaining.\r\n        this.callbackAttached = false;\r\n        callback(value => {\r\n            this.isDone = true;\r\n            this.result = value;\r\n            if (this.nextCallback) {\r\n                // value should be defined unless T is Void, but we can't express\r\n                // that in the type system.\r\n                this.nextCallback(value);\r\n            }\r\n        }, error => {\r\n            this.isDone = true;\r\n            this.error = error;\r\n            if (this.catchCallback) {\r\n                this.catchCallback(error);\r\n            }\r\n        });\r\n    }\r\n    catch(fn) {\r\n        return this.next(undefined, fn);\r\n    }\r\n    next(nextFn, catchFn) {\r\n        if (this.callbackAttached) {\r\n            fail();\r\n        }\r\n        this.callbackAttached = true;\r\n        if (this.isDone) {\r\n            if (!this.error) {\r\n                return this.wrapSuccess(nextFn, this.result);\r\n            }\r\n            else {\r\n                return this.wrapFailure(catchFn, this.error);\r\n            }\r\n        }\r\n        else {\r\n            return new PersistencePromise((resolve, reject) => {\r\n                this.nextCallback = (value) => {\r\n                    this.wrapSuccess(nextFn, value).next(resolve, reject);\r\n                };\r\n                this.catchCallback = (error) => {\r\n                    this.wrapFailure(catchFn, error).next(resolve, reject);\r\n                };\r\n            });\r\n        }\r\n    }\r\n    toPromise() {\r\n        return new Promise((resolve, reject) => {\r\n            this.next(resolve, reject);\r\n        });\r\n    }\r\n    wrapUserFunction(fn) {\r\n        try {\r\n            const result = fn();\r\n            if (result instanceof PersistencePromise) {\r\n                return result;\r\n            }\r\n            else {\r\n                return PersistencePromise.resolve(result);\r\n            }\r\n        }\r\n        catch (e) {\r\n            return PersistencePromise.reject(e);\r\n        }\r\n    }\r\n    wrapSuccess(nextFn, value) {\r\n        if (nextFn) {\r\n            return this.wrapUserFunction(() => nextFn(value));\r\n        }\r\n        else {\r\n            // If there's no nextFn, then R must be the same as T\r\n            return PersistencePromise.resolve(value);\r\n        }\r\n    }\r\n    wrapFailure(catchFn, error) {\r\n        if (catchFn) {\r\n            return this.wrapUserFunction(() => catchFn(error));\r\n        }\r\n        else {\r\n            return PersistencePromise.reject(error);\r\n        }\r\n    }\r\n    static resolve(result) {\r\n        return new PersistencePromise((resolve, reject) => {\r\n            resolve(result);\r\n        });\r\n    }\r\n    static reject(error) {\r\n        return new PersistencePromise((resolve, reject) => {\r\n            reject(error);\r\n        });\r\n    }\r\n    static waitFor(\r\n    // Accept all Promise types in waitFor().\r\n    // eslint-disable-next-line @typescript-eslint/no-explicit-any\r\n    all) {\r\n        return new PersistencePromise((resolve, reject) => {\r\n            let expectedCount = 0;\r\n            let resolvedCount = 0;\r\n            let done = false;\r\n            all.forEach(element => {\r\n                ++expectedCount;\r\n                element.next(() => {\r\n                    ++resolvedCount;\r\n                    if (done && resolvedCount === expectedCount) {\r\n                        resolve();\r\n                    }\r\n                }, err => reject(err));\r\n            });\r\n            done = true;\r\n            if (resolvedCount === expectedCount) {\r\n                resolve();\r\n            }\r\n        });\r\n    }\r\n    /**\r\n     * Given an array of predicate functions that asynchronously evaluate to a\r\n     * boolean, implements a short-circuiting `or` between the results. Predicates\r\n     * will be evaluated until one of them returns `true`, then stop. The final\r\n     * result will be whether any of them returned `true`.\r\n     */\r\n    static or(predicates) {\r\n        let p = PersistencePromise.resolve(false);\r\n        for (const predicate of predicates) {\r\n            p = p.next(isTrue => {\r\n                if (isTrue) {\r\n                    return PersistencePromise.resolve(isTrue);\r\n                }\r\n                else {\r\n                    return predicate();\r\n                }\r\n            });\r\n        }\r\n        return p;\r\n    }\r\n    static forEach(collection, f) {\r\n        const promises = [];\r\n        collection.forEach((r, s) => {\r\n            promises.push(f.call(this, r, s));\r\n        });\r\n        return this.waitFor(promises);\r\n    }\r\n}\n\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\n/** Verifies whether `e` is an IndexedDbTransactionError. */\r\nfunction isIndexedDbTransactionError(e) {\r\n    // Use name equality, as instanceof checks on errors don't work with errors\r\n    // that wrap other errors.\r\n    return e.name === 'IndexedDbTransactionError';\r\n}\n\n/**\r\n * @license\r\n * Copyright 2020 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\n/**\r\n * Generates `nBytes` of random bytes.\r\n *\r\n * If `nBytes < 0` , an error will be thrown.\r\n */\r\nfunction randomBytes(nBytes) {\r\n    return randomBytes$1(nBytes);\r\n}\n\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\nclass AutoId {\r\n    static newId() {\r\n        // Alphanumeric characters\r\n        const chars = 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789';\r\n        // The largest byte value that is a multiple of `char.length`.\r\n        const maxMultiple = Math.floor(256 / chars.length) * chars.length;\r\n        let autoId = '';\r\n        const targetLength = 20;\r\n        while (autoId.length < targetLength) {\r\n            const bytes = randomBytes(40);\r\n            for (let i = 0; i < bytes.length; ++i) {\r\n                // Only accept values that are [0, maxMultiple), this ensures they can\r\n                // be evenly mapped to indices of `chars` via a modulo operation.\r\n                if (autoId.length < targetLength && bytes[i] < maxMultiple) {\r\n                    autoId += chars.charAt(bytes[i] % chars.length);\r\n                }\r\n            }\r\n        }\r\n        return autoId;\r\n    }\r\n}\r\nfunction primitiveComparator(left, right) {\r\n    if (left < right) {\r\n        return -1;\r\n    }\r\n    if (left > right) {\r\n        return 1;\r\n    }\r\n    return 0;\r\n}\r\n/** Helper to compare arrays using isEqual(). */\r\nfunction arrayEquals(left, right, comparator) {\r\n    if (left.length !== right.length) {\r\n        return false;\r\n    }\r\n    return left.every((value, index) => comparator(value, right[index]));\r\n}\n\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\n// The earliest date supported by Firestore timestamps (0001-01-01T00:00:00Z).\r\nconst MIN_SECONDS = -62135596800;\r\n// Number of nanoseconds in a millisecond.\r\nconst MS_TO_NANOS = 1e6;\r\n/**\r\n * A `Timestamp` represents a point in time independent of any time zone or\r\n * calendar, represented as seconds and fractions of seconds at nanosecond\r\n * resolution in UTC Epoch time.\r\n *\r\n * It is encoded using the Proleptic Gregorian Calendar which extends the\r\n * Gregorian calendar backwards to year one. It is encoded assuming all minutes\r\n * are 60 seconds long, i.e. leap seconds are \"smeared\" so that no leap second\r\n * table is needed for interpretation. Range is from 0001-01-01T00:00:00Z to\r\n * 9999-12-31T23:59:59.999999999Z.\r\n *\r\n * For examples and further specifications, refer to the\r\n * {@link https://github.com/google/protobuf/blob/master/src/google/protobuf/timestamp.proto | Timestamp definition}.\r\n */\r\nclass Timestamp {\r\n    /**\r\n     * Creates a new timestamp.\r\n     *\r\n     * @param seconds - The number of seconds of UTC time since Unix epoch\r\n     *     1970-01-01T00:00:00Z. Must be from 0001-01-01T00:00:00Z to\r\n     *     9999-12-31T23:59:59Z inclusive.\r\n     * @param nanoseconds - The non-negative fractions of a second at nanosecond\r\n     *     resolution. Negative second values with fractions must still have\r\n     *     non-negative nanoseconds values that count forward in time. Must be\r\n     *     from 0 to 999,999,999 inclusive.\r\n     */\r\n    constructor(\r\n    /**\r\n     * The number of seconds of UTC time since Unix epoch 1970-01-01T00:00:00Z.\r\n     */\r\n    seconds, \r\n    /**\r\n     * The fractions of a second at nanosecond resolution.*\r\n     */\r\n    nanoseconds) {\r\n        this.seconds = seconds;\r\n        this.nanoseconds = nanoseconds;\r\n        if (nanoseconds < 0) {\r\n            throw new FirestoreError(Code.INVALID_ARGUMENT, 'Timestamp nanoseconds out of range: ' + nanoseconds);\r\n        }\r\n        if (nanoseconds >= 1e9) {\r\n            throw new FirestoreError(Code.INVALID_ARGUMENT, 'Timestamp nanoseconds out of range: ' + nanoseconds);\r\n        }\r\n        if (seconds < MIN_SECONDS) {\r\n            throw new FirestoreError(Code.INVALID_ARGUMENT, 'Timestamp seconds out of range: ' + seconds);\r\n        }\r\n        // This will break in the year 10,000.\r\n        if (seconds >= 253402300800) {\r\n            throw new FirestoreError(Code.INVALID_ARGUMENT, 'Timestamp seconds out of range: ' + seconds);\r\n        }\r\n    }\r\n    /**\r\n     * Creates a new timestamp with the current date, with millisecond precision.\r\n     *\r\n     * @returns a new timestamp representing the current date.\r\n     */\r\n    static now() {\r\n        return Timestamp.fromMillis(Date.now());\r\n    }\r\n    /**\r\n     * Creates a new timestamp from the given date.\r\n     *\r\n     * @param date - The date to initialize the `Timestamp` from.\r\n     * @returns A new `Timestamp` representing the same point in time as the given\r\n     *     date.\r\n     */\r\n    static fromDate(date) {\r\n        return Timestamp.fromMillis(date.getTime());\r\n    }\r\n    /**\r\n     * Creates a new timestamp from the given number of milliseconds.\r\n     *\r\n     * @param milliseconds - Number of milliseconds since Unix epoch\r\n     *     1970-01-01T00:00:00Z.\r\n     * @returns A new `Timestamp` representing the same point in time as the given\r\n     *     number of milliseconds.\r\n     */\r\n    static fromMillis(milliseconds) {\r\n        const seconds = Math.floor(milliseconds / 1000);\r\n        const nanos = Math.floor((milliseconds - seconds * 1000) * MS_TO_NANOS);\r\n        return new Timestamp(seconds, nanos);\r\n    }\r\n    /**\r\n     * Converts a `Timestamp` to a JavaScript `Date` object. This conversion\r\n     * causes a loss of precision since `Date` objects only support millisecond\r\n     * precision.\r\n     *\r\n     * @returns JavaScript `Date` object representing the same point in time as\r\n     *     this `Timestamp`, with millisecond precision.\r\n     */\r\n    toDate() {\r\n        return new Date(this.toMillis());\r\n    }\r\n    /**\r\n     * Converts a `Timestamp` to a numeric timestamp (in milliseconds since\r\n     * epoch). This operation causes a loss of precision.\r\n     *\r\n     * @returns The point in time corresponding to this timestamp, represented as\r\n     *     the number of milliseconds since Unix epoch 1970-01-01T00:00:00Z.\r\n     */\r\n    toMillis() {\r\n        return this.seconds * 1000 + this.nanoseconds / MS_TO_NANOS;\r\n    }\r\n    _compareTo(other) {\r\n        if (this.seconds === other.seconds) {\r\n            return primitiveComparator(this.nanoseconds, other.nanoseconds);\r\n        }\r\n        return primitiveComparator(this.seconds, other.seconds);\r\n    }\r\n    /**\r\n     * Returns true if this `Timestamp` is equal to the provided one.\r\n     *\r\n     * @param other - The `Timestamp` to compare against.\r\n     * @returns true if this `Timestamp` is equal to the provided one.\r\n     */\r\n    isEqual(other) {\r\n        return (other.seconds === this.seconds && other.nanoseconds === this.nanoseconds);\r\n    }\r\n    /** Returns a textual representation of this Timestamp. */\r\n    toString() {\r\n        return ('Timestamp(seconds=' +\r\n            this.seconds +\r\n            ', nanoseconds=' +\r\n            this.nanoseconds +\r\n            ')');\r\n    }\r\n    /** Returns a JSON-serializable representation of this Timestamp. */\r\n    toJSON() {\r\n        return { seconds: this.seconds, nanoseconds: this.nanoseconds };\r\n    }\r\n    /**\r\n     * Converts this object to a primitive string, which allows Timestamp objects\r\n     * to be compared using the `>`, `<=`, `>=` and `>` operators.\r\n     */\r\n    valueOf() {\r\n        // This method returns a string of the form <seconds>.<nanoseconds> where\r\n        // <seconds> is translated to have a non-negative value and both <seconds>\r\n        // and <nanoseconds> are left-padded with zeroes to be a consistent length.\r\n        // Strings with this format then have a lexiographical ordering that matches\r\n        // the expected ordering. The <seconds> translation is done to avoid having\r\n        // a leading negative sign (i.e. a leading '-' character) in its string\r\n        // representation, which would affect its lexiographical ordering.\r\n        const adjustedSeconds = this.seconds - MIN_SECONDS;\r\n        // Note: Up to 12 decimal digits are required to represent all valid\r\n        // 'seconds' values.\r\n        const formattedSeconds = String(adjustedSeconds).padStart(12, '0');\r\n        const formattedNanoseconds = String(this.nanoseconds).padStart(9, '0');\r\n        return formattedSeconds + '.' + formattedNanoseconds;\r\n    }\r\n}\n\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\n/**\r\n * A version of a document in Firestore. This corresponds to the version\r\n * timestamp, such as update_time or read_time.\r\n */\r\nclass SnapshotVersion {\r\n    constructor(timestamp) {\r\n        this.timestamp = timestamp;\r\n    }\r\n    static fromTimestamp(value) {\r\n        return new SnapshotVersion(value);\r\n    }\r\n    static min() {\r\n        return new SnapshotVersion(new Timestamp(0, 0));\r\n    }\r\n    compareTo(other) {\r\n        return this.timestamp._compareTo(other.timestamp);\r\n    }\r\n    isEqual(other) {\r\n        return this.timestamp.isEqual(other.timestamp);\r\n    }\r\n    /** Returns a number representation of the version for use in spec tests. */\r\n    toMicroseconds() {\r\n        // Convert to microseconds.\r\n        return this.timestamp.seconds * 1e6 + this.timestamp.nanoseconds / 1000;\r\n    }\r\n    toString() {\r\n        return 'SnapshotVersion(' + this.timestamp.toString() + ')';\r\n    }\r\n    toTimestamp() {\r\n        return this.timestamp;\r\n    }\r\n}\n\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\nfunction objectSize(obj) {\r\n    let count = 0;\r\n    for (const key in obj) {\r\n        if (Object.prototype.hasOwnProperty.call(obj, key)) {\r\n            count++;\r\n        }\r\n    }\r\n    return count;\r\n}\r\nfunction forEach(obj, fn) {\r\n    for (const key in obj) {\r\n        if (Object.prototype.hasOwnProperty.call(obj, key)) {\r\n            fn(key, obj[key]);\r\n        }\r\n    }\r\n}\r\nfunction isEmpty(obj) {\r\n    for (const key in obj) {\r\n        if (Object.prototype.hasOwnProperty.call(obj, key)) {\r\n            return false;\r\n        }\r\n    }\r\n    return true;\r\n}\n\n/**\r\n * @license\r\n * Copyright 2020 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\n/**\r\n * Provides a set of fields that can be used to partially patch a document.\r\n * FieldMask is used in conjunction with ObjectValue.\r\n * Examples:\r\n *   foo - Overwrites foo entirely with the provided value. If foo is not\r\n *         present in the companion ObjectValue, the field is deleted.\r\n *   foo.bar - Overwrites only the field bar of the object foo.\r\n *             If foo is not an object, foo is replaced with an object\r\n *             containing foo\r\n */\r\nclass FieldMask {\r\n    constructor(fields) {\r\n        this.fields = fields;\r\n        // TODO(dimond): validation of FieldMask\r\n        // Sort the field mask to support `FieldMask.isEqual()` and assert below.\r\n        fields.sort(FieldPath.comparator);\r\n    }\r\n    /**\r\n     * Verifies that `fieldPath` is included by at least one field in this field\r\n     * mask.\r\n     *\r\n     * This is an O(n) operation, where `n` is the size of the field mask.\r\n     */\r\n    covers(fieldPath) {\r\n        for (const fieldMaskPath of this.fields) {\r\n            if (fieldMaskPath.isPrefixOf(fieldPath)) {\r\n                return true;\r\n            }\r\n        }\r\n        return false;\r\n    }\r\n    isEqual(other) {\r\n        return arrayEquals(this.fields, other.fields, (l, r) => l.isEqual(r));\r\n    }\r\n}\n\n/**\r\n * @license\r\n * Copyright 2020 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\nfunction decodeBase64(encoded) {\r\n    // Node actually doesn't validate base64 strings.\r\n    // A quick sanity check that is not a fool-proof validation\r\n    if (/[^-A-Za-z0-9+/=]/.test(encoded)) {\r\n        throw new FirestoreError(Code.INVALID_ARGUMENT, 'Not a valid Base64 string: ' + encoded);\r\n    }\r\n    return new Buffer(encoded, 'base64').toString('binary');\r\n}\r\n/** Converts a binary string to a Base64 encoded string. */\r\nfunction encodeBase64(raw) {\r\n    return new Buffer(raw, 'binary').toString('base64');\r\n}\n\n/**\r\n * @license\r\n * Copyright 2020 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\n/**\r\n * Immutable class that represents a \"proto\" byte string.\r\n *\r\n * Proto byte strings can either be Base64-encoded strings or Uint8Arrays when\r\n * sent on the wire. This class abstracts away this differentiation by holding\r\n * the proto byte string in a common class that must be converted into a string\r\n * before being sent as a proto.\r\n */\r\nclass ByteString {\r\n    constructor(binaryString) {\r\n        this.binaryString = binaryString;\r\n    }\r\n    static fromBase64String(base64) {\r\n        const binaryString = decodeBase64(base64);\r\n        return new ByteString(binaryString);\r\n    }\r\n    static fromUint8Array(array) {\r\n        const binaryString = binaryStringFromUint8Array(array);\r\n        return new ByteString(binaryString);\r\n    }\r\n    toBase64() {\r\n        return encodeBase64(this.binaryString);\r\n    }\r\n    toUint8Array() {\r\n        return uint8ArrayFromBinaryString(this.binaryString);\r\n    }\r\n    approximateByteSize() {\r\n        return this.binaryString.length * 2;\r\n    }\r\n    compareTo(other) {\r\n        return primitiveComparator(this.binaryString, other.binaryString);\r\n    }\r\n    isEqual(other) {\r\n        return this.binaryString === other.binaryString;\r\n    }\r\n}\r\nByteString.EMPTY_BYTE_STRING = new ByteString('');\r\n/**\r\n * Helper function to convert an Uint8array to a binary string.\r\n */\r\nfunction binaryStringFromUint8Array(array) {\r\n    let binaryString = '';\r\n    for (let i = 0; i < array.length; ++i) {\r\n        binaryString += String.fromCharCode(array[i]);\r\n    }\r\n    return binaryString;\r\n}\r\n/**\r\n * Helper function to convert a binary string to an Uint8Array.\r\n */\r\nfunction uint8ArrayFromBinaryString(binaryString) {\r\n    const buffer = new Uint8Array(binaryString.length);\r\n    for (let i = 0; i < binaryString.length; i++) {\r\n        buffer[i] = binaryString.charCodeAt(i);\r\n    }\r\n    return buffer;\r\n}\n\n/**\r\n * @license\r\n * Copyright 2020 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\n// A RegExp matching ISO 8601 UTC timestamps with optional fraction.\r\nconst ISO_TIMESTAMP_REG_EXP = new RegExp(/^\\d{4}-\\d\\d-\\d\\dT\\d\\d:\\d\\d:\\d\\d(?:\\.(\\d+))?Z$/);\r\n/**\r\n * Converts the possible Proto values for a timestamp value into a \"seconds and\r\n * nanos\" representation.\r\n */\r\nfunction normalizeTimestamp(date) {\r\n    hardAssert(!!date);\r\n    // The json interface (for the browser) will return an iso timestamp string,\r\n    // while the proto js library (for node) will return a\r\n    // google.protobuf.Timestamp instance.\r\n    if (typeof date === 'string') {\r\n        // The date string can have higher precision (nanos) than the Date class\r\n        // (millis), so we do some custom parsing here.\r\n        // Parse the nanos right out of the string.\r\n        let nanos = 0;\r\n        const fraction = ISO_TIMESTAMP_REG_EXP.exec(date);\r\n        hardAssert(!!fraction);\r\n        if (fraction[1]) {\r\n            // Pad the fraction out to 9 digits (nanos).\r\n            let nanoStr = fraction[1];\r\n            nanoStr = (nanoStr + '000000000').substr(0, 9);\r\n            nanos = Number(nanoStr);\r\n        }\r\n        // Parse the date to get the seconds.\r\n        const parsedDate = new Date(date);\r\n        const seconds = Math.floor(parsedDate.getTime() / 1000);\r\n        return { seconds, nanos };\r\n    }\r\n    else {\r\n        // TODO(b/37282237): Use strings for Proto3 timestamps\r\n        // assert(!this.options.useProto3Json,\r\n        //   'The timestamp instance format requires Proto JS.');\r\n        const seconds = normalizeNumber(date.seconds);\r\n        const nanos = normalizeNumber(date.nanos);\r\n        return { seconds, nanos };\r\n    }\r\n}\r\n/**\r\n * Converts the possible Proto types for numbers into a JavaScript number.\r\n * Returns 0 if the value is not numeric.\r\n */\r\nfunction normalizeNumber(value) {\r\n    // TODO(bjornick): Handle int64 greater than 53 bits.\r\n    if (typeof value === 'number') {\r\n        return value;\r\n    }\r\n    else if (typeof value === 'string') {\r\n        return Number(value);\r\n    }\r\n    else {\r\n        return 0;\r\n    }\r\n}\r\n/** Converts the possible Proto types for Blobs into a ByteString. */\r\nfunction normalizeByteString(blob) {\r\n    if (typeof blob === 'string') {\r\n        return ByteString.fromBase64String(blob);\r\n    }\r\n    else {\r\n        return ByteString.fromUint8Array(blob);\r\n    }\r\n}\n\n/**\r\n * @license\r\n * Copyright 2020 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\n/**\r\n * Represents a locally-applied ServerTimestamp.\r\n *\r\n * Server Timestamps are backed by MapValues that contain an internal field\r\n * `__type__` with a value of `server_timestamp`. The previous value and local\r\n * write time are stored in its `__previous_value__` and `__local_write_time__`\r\n * fields respectively.\r\n *\r\n * Notes:\r\n * - ServerTimestampValue instances are created as the result of applying a\r\n *   transform. They can only exist in the local view of a document. Therefore\r\n *   they do not need to be parsed or serialized.\r\n * - When evaluated locally (e.g. for snapshot.data()), they by default\r\n *   evaluate to `null`. This behavior can be configured by passing custom\r\n *   FieldValueOptions to value().\r\n * - With respect to other ServerTimestampValues, they sort by their\r\n *   localWriteTime.\r\n */\r\nconst SERVER_TIMESTAMP_SENTINEL = 'server_timestamp';\r\nconst TYPE_KEY = '__type__';\r\nconst PREVIOUS_VALUE_KEY = '__previous_value__';\r\nconst LOCAL_WRITE_TIME_KEY = '__local_write_time__';\r\nfunction isServerTimestamp(value) {\r\n    var _a, _b;\r\n    const type = (_b = (((_a = value === null || value === void 0 ? void 0 : value.mapValue) === null || _a === void 0 ? void 0 : _a.fields) || {})[TYPE_KEY]) === null || _b === void 0 ? void 0 : _b.stringValue;\r\n    return type === SERVER_TIMESTAMP_SENTINEL;\r\n}\r\n/**\r\n * Creates a new ServerTimestamp proto value (using the internal format).\r\n */\r\nfunction serverTimestamp(localWriteTime, previousValue) {\r\n    const mapValue = {\r\n        fields: {\r\n            [TYPE_KEY]: {\r\n                stringValue: SERVER_TIMESTAMP_SENTINEL\r\n            },\r\n            [LOCAL_WRITE_TIME_KEY]: {\r\n                timestampValue: {\r\n                    seconds: localWriteTime.seconds,\r\n                    nanos: localWriteTime.nanoseconds\r\n                }\r\n            }\r\n        }\r\n    };\r\n    if (previousValue) {\r\n        mapValue.fields[PREVIOUS_VALUE_KEY] = previousValue;\r\n    }\r\n    return { mapValue };\r\n}\r\n/**\r\n * Returns the value of the field before this ServerTimestamp was set.\r\n *\r\n * Preserving the previous values allows the user to display the last resoled\r\n * value until the backend responds with the timestamp.\r\n */\r\nfunction getPreviousValue(value) {\r\n    const previousValue = value.mapValue.fields[PREVIOUS_VALUE_KEY];\r\n    if (isServerTimestamp(previousValue)) {\r\n        return getPreviousValue(previousValue);\r\n    }\r\n    return previousValue;\r\n}\r\n/**\r\n * Returns the local time at which this timestamp was first set.\r\n */\r\nfunction getLocalWriteTime(value) {\r\n    const localWriteTime = normalizeTimestamp(value.mapValue.fields[LOCAL_WRITE_TIME_KEY].timestampValue);\r\n    return new Timestamp(localWriteTime.seconds, localWriteTime.nanos);\r\n}\n\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\n/** Sentinel value that sorts before any Mutation Batch ID. */\r\nconst BATCHID_UNKNOWN = -1;\r\n/**\r\n * Returns whether a variable is either undefined or null.\r\n */\r\nfunction isNullOrUndefined(value) {\r\n    return value === null || value === undefined;\r\n}\r\n/** Returns whether the value represents -0. */\r\nfunction isNegativeZero(value) {\r\n    // Detect if the value is -0.0. Based on polyfill from\r\n    // https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Object/is\r\n    return value === 0 && 1 / value === 1 / -0;\r\n}\r\n/**\r\n * Returns whether a value is an integer and in the safe integer range\r\n * @param value - The value to test for being an integer and in the safe range\r\n */\r\nfunction isSafeInteger(value) {\r\n    return (typeof value === 'number' &&\r\n        Number.isInteger(value) &&\r\n        !isNegativeZero(value) &&\r\n        value <= Number.MAX_SAFE_INTEGER &&\r\n        value >= Number.MIN_SAFE_INTEGER);\r\n}\n\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\nclass DocumentKey {\r\n    constructor(path) {\r\n        this.path = path;\r\n    }\r\n    static fromPath(path) {\r\n        return new DocumentKey(ResourcePath.fromString(path));\r\n    }\r\n    static fromName(name) {\r\n        return new DocumentKey(ResourcePath.fromString(name).popFirst(5));\r\n    }\r\n    /** Returns true if the document is in the specified collectionId. */\r\n    hasCollectionId(collectionId) {\r\n        return (this.path.length >= 2 &&\r\n            this.path.get(this.path.length - 2) === collectionId);\r\n    }\r\n    isEqual(other) {\r\n        return (other !== null && ResourcePath.comparator(this.path, other.path) === 0);\r\n    }\r\n    toString() {\r\n        return this.path.toString();\r\n    }\r\n    static comparator(k1, k2) {\r\n        return ResourcePath.comparator(k1.path, k2.path);\r\n    }\r\n    static isDocumentKey(path) {\r\n        return path.length % 2 === 0;\r\n    }\r\n    /**\r\n     * Creates and returns a new document key with the given segments.\r\n     *\r\n     * @param segments - The segments of the path to the document\r\n     * @returns A new instance of DocumentKey\r\n     */\r\n    static fromSegments(segments) {\r\n        return new DocumentKey(new ResourcePath(segments.slice()));\r\n    }\r\n}\n\n/**\r\n * @license\r\n * Copyright 2020 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\n/** Extracts the backend's type order for the provided value. */\r\nfunction typeOrder(value) {\r\n    if ('nullValue' in value) {\r\n        return 0 /* NullValue */;\r\n    }\r\n    else if ('booleanValue' in value) {\r\n        return 1 /* BooleanValue */;\r\n    }\r\n    else if ('integerValue' in value || 'doubleValue' in value) {\r\n        return 2 /* NumberValue */;\r\n    }\r\n    else if ('timestampValue' in value) {\r\n        return 3 /* TimestampValue */;\r\n    }\r\n    else if ('stringValue' in value) {\r\n        return 5 /* StringValue */;\r\n    }\r\n    else if ('bytesValue' in value) {\r\n        return 6 /* BlobValue */;\r\n    }\r\n    else if ('referenceValue' in value) {\r\n        return 7 /* RefValue */;\r\n    }\r\n    else if ('geoPointValue' in value) {\r\n        return 8 /* GeoPointValue */;\r\n    }\r\n    else if ('arrayValue' in value) {\r\n        return 9 /* ArrayValue */;\r\n    }\r\n    else if ('mapValue' in value) {\r\n        if (isServerTimestamp(value)) {\r\n            return 4 /* ServerTimestampValue */;\r\n        }\r\n        return 10 /* ObjectValue */;\r\n    }\r\n    else {\r\n        return fail();\r\n    }\r\n}\r\n/** Tests `left` and `right` for equality based on the backend semantics. */\r\nfunction valueEquals(left, right) {\r\n    const leftType = typeOrder(left);\r\n    const rightType = typeOrder(right);\r\n    if (leftType !== rightType) {\r\n        return false;\r\n    }\r\n    switch (leftType) {\r\n        case 0 /* NullValue */:\r\n            return true;\r\n        case 1 /* BooleanValue */:\r\n            return left.booleanValue === right.booleanValue;\r\n        case 4 /* ServerTimestampValue */:\r\n            return getLocalWriteTime(left).isEqual(getLocalWriteTime(right));\r\n        case 3 /* TimestampValue */:\r\n            return timestampEquals(left, right);\r\n        case 5 /* StringValue */:\r\n            return left.stringValue === right.stringValue;\r\n        case 6 /* BlobValue */:\r\n            return blobEquals(left, right);\r\n        case 7 /* RefValue */:\r\n            return left.referenceValue === right.referenceValue;\r\n        case 8 /* GeoPointValue */:\r\n            return geoPointEquals(left, right);\r\n        case 2 /* NumberValue */:\r\n            return numberEquals(left, right);\r\n        case 9 /* ArrayValue */:\r\n            return arrayEquals(left.arrayValue.values || [], right.arrayValue.values || [], valueEquals);\r\n        case 10 /* ObjectValue */:\r\n            return objectEquals(left, right);\r\n        default:\r\n            return fail();\r\n    }\r\n}\r\nfunction timestampEquals(left, right) {\r\n    if (typeof left.timestampValue === 'string' &&\r\n        typeof right.timestampValue === 'string' &&\r\n        left.timestampValue.length === right.timestampValue.length) {\r\n        // Use string equality for ISO 8601 timestamps\r\n        return left.timestampValue === right.timestampValue;\r\n    }\r\n    const leftTimestamp = normalizeTimestamp(left.timestampValue);\r\n    const rightTimestamp = normalizeTimestamp(right.timestampValue);\r\n    return (leftTimestamp.seconds === rightTimestamp.seconds &&\r\n        leftTimestamp.nanos === rightTimestamp.nanos);\r\n}\r\nfunction geoPointEquals(left, right) {\r\n    return (normalizeNumber(left.geoPointValue.latitude) ===\r\n        normalizeNumber(right.geoPointValue.latitude) &&\r\n        normalizeNumber(left.geoPointValue.longitude) ===\r\n            normalizeNumber(right.geoPointValue.longitude));\r\n}\r\nfunction blobEquals(left, right) {\r\n    return normalizeByteString(left.bytesValue).isEqual(normalizeByteString(right.bytesValue));\r\n}\r\nfunction numberEquals(left, right) {\r\n    if ('integerValue' in left && 'integerValue' in right) {\r\n        return (normalizeNumber(left.integerValue) === normalizeNumber(right.integerValue));\r\n    }\r\n    else if ('doubleValue' in left && 'doubleValue' in right) {\r\n        const n1 = normalizeNumber(left.doubleValue);\r\n        const n2 = normalizeNumber(right.doubleValue);\r\n        if (n1 === n2) {\r\n            return isNegativeZero(n1) === isNegativeZero(n2);\r\n        }\r\n        else {\r\n            return isNaN(n1) && isNaN(n2);\r\n        }\r\n    }\r\n    return false;\r\n}\r\nfunction objectEquals(left, right) {\r\n    const leftMap = left.mapValue.fields || {};\r\n    const rightMap = right.mapValue.fields || {};\r\n    if (objectSize(leftMap) !== objectSize(rightMap)) {\r\n        return false;\r\n    }\r\n    for (const key in leftMap) {\r\n        if (leftMap.hasOwnProperty(key)) {\r\n            if (rightMap[key] === undefined ||\r\n                !valueEquals(leftMap[key], rightMap[key])) {\r\n                return false;\r\n            }\r\n        }\r\n    }\r\n    return true;\r\n}\r\n/** Returns true if the ArrayValue contains the specified element. */\r\nfunction arrayValueContains(haystack, needle) {\r\n    return ((haystack.values || []).find(v => valueEquals(v, needle)) !== undefined);\r\n}\r\nfunction valueCompare(left, right) {\r\n    const leftType = typeOrder(left);\r\n    const rightType = typeOrder(right);\r\n    if (leftType !== rightType) {\r\n        return primitiveComparator(leftType, rightType);\r\n    }\r\n    switch (leftType) {\r\n        case 0 /* NullValue */:\r\n            return 0;\r\n        case 1 /* BooleanValue */:\r\n            return primitiveComparator(left.booleanValue, right.booleanValue);\r\n        case 2 /* NumberValue */:\r\n            return compareNumbers(left, right);\r\n        case 3 /* TimestampValue */:\r\n            return compareTimestamps(left.timestampValue, right.timestampValue);\r\n        case 4 /* ServerTimestampValue */:\r\n            return compareTimestamps(getLocalWriteTime(left), getLocalWriteTime(right));\r\n        case 5 /* StringValue */:\r\n            return primitiveComparator(left.stringValue, right.stringValue);\r\n        case 6 /* BlobValue */:\r\n            return compareBlobs(left.bytesValue, right.bytesValue);\r\n        case 7 /* RefValue */:\r\n            return compareReferences(left.referenceValue, right.referenceValue);\r\n        case 8 /* GeoPointValue */:\r\n            return compareGeoPoints(left.geoPointValue, right.geoPointValue);\r\n        case 9 /* ArrayValue */:\r\n            return compareArrays(left.arrayValue, right.arrayValue);\r\n        case 10 /* ObjectValue */:\r\n            return compareMaps(left.mapValue, right.mapValue);\r\n        default:\r\n            throw fail();\r\n    }\r\n}\r\nfunction compareNumbers(left, right) {\r\n    const leftNumber = normalizeNumber(left.integerValue || left.doubleValue);\r\n    const rightNumber = normalizeNumber(right.integerValue || right.doubleValue);\r\n    if (leftNumber < rightNumber) {\r\n        return -1;\r\n    }\r\n    else if (leftNumber > rightNumber) {\r\n        return 1;\r\n    }\r\n    else if (leftNumber === rightNumber) {\r\n        return 0;\r\n    }\r\n    else {\r\n        // one or both are NaN.\r\n        if (isNaN(leftNumber)) {\r\n            return isNaN(rightNumber) ? 0 : -1;\r\n        }\r\n        else {\r\n            return 1;\r\n        }\r\n    }\r\n}\r\nfunction compareTimestamps(left, right) {\r\n    if (typeof left === 'string' &&\r\n        typeof right === 'string' &&\r\n        left.length === right.length) {\r\n        return primitiveComparator(left, right);\r\n    }\r\n    const leftTimestamp = normalizeTimestamp(left);\r\n    const rightTimestamp = normalizeTimestamp(right);\r\n    const comparison = primitiveComparator(leftTimestamp.seconds, rightTimestamp.seconds);\r\n    if (comparison !== 0) {\r\n        return comparison;\r\n    }\r\n    return primitiveComparator(leftTimestamp.nanos, rightTimestamp.nanos);\r\n}\r\nfunction compareReferences(leftPath, rightPath) {\r\n    const leftSegments = leftPath.split('/');\r\n    const rightSegments = rightPath.split('/');\r\n    for (let i = 0; i < leftSegments.length && i < rightSegments.length; i++) {\r\n        const comparison = primitiveComparator(leftSegments[i], rightSegments[i]);\r\n        if (comparison !== 0) {\r\n            return comparison;\r\n        }\r\n    }\r\n    return primitiveComparator(leftSegments.length, rightSegments.length);\r\n}\r\nfunction compareGeoPoints(left, right) {\r\n    const comparison = primitiveComparator(normalizeNumber(left.latitude), normalizeNumber(right.latitude));\r\n    if (comparison !== 0) {\r\n        return comparison;\r\n    }\r\n    return primitiveComparator(normalizeNumber(left.longitude), normalizeNumber(right.longitude));\r\n}\r\nfunction compareBlobs(left, right) {\r\n    const leftBytes = normalizeByteString(left);\r\n    const rightBytes = normalizeByteString(right);\r\n    return leftBytes.compareTo(rightBytes);\r\n}\r\nfunction compareArrays(left, right) {\r\n    const leftArray = left.values || [];\r\n    const rightArray = right.values || [];\r\n    for (let i = 0; i < leftArray.length && i < rightArray.length; ++i) {\r\n        const compare = valueCompare(leftArray[i], rightArray[i]);\r\n        if (compare) {\r\n            return compare;\r\n        }\r\n    }\r\n    return primitiveComparator(leftArray.length, rightArray.length);\r\n}\r\nfunction compareMaps(left, right) {\r\n    const leftMap = left.fields || {};\r\n    const leftKeys = Object.keys(leftMap);\r\n    const rightMap = right.fields || {};\r\n    const rightKeys = Object.keys(rightMap);\r\n    // Even though MapValues are likely sorted correctly based on their insertion\r\n    // order (e.g. when received from the backend), local modifications can bring\r\n    // elements out of order. We need to re-sort the elements to ensure that\r\n    // canonical IDs are independent of insertion order.\r\n    leftKeys.sort();\r\n    rightKeys.sort();\r\n    for (let i = 0; i < leftKeys.length && i < rightKeys.length; ++i) {\r\n        const keyCompare = primitiveComparator(leftKeys[i], rightKeys[i]);\r\n        if (keyCompare !== 0) {\r\n            return keyCompare;\r\n        }\r\n        const compare = valueCompare(leftMap[leftKeys[i]], rightMap[rightKeys[i]]);\r\n        if (compare !== 0) {\r\n            return compare;\r\n        }\r\n    }\r\n    return primitiveComparator(leftKeys.length, rightKeys.length);\r\n}\r\n/**\r\n * Generates the canonical ID for the provided field value (as used in Target\r\n * serialization).\r\n */\r\nfunction canonicalId(value) {\r\n    return canonifyValue(value);\r\n}\r\nfunction canonifyValue(value) {\r\n    if ('nullValue' in value) {\r\n        return 'null';\r\n    }\r\n    else if ('booleanValue' in value) {\r\n        return '' + value.booleanValue;\r\n    }\r\n    else if ('integerValue' in value) {\r\n        return '' + value.integerValue;\r\n    }\r\n    else if ('doubleValue' in value) {\r\n        return '' + value.doubleValue;\r\n    }\r\n    else if ('timestampValue' in value) {\r\n        return canonifyTimestamp(value.timestampValue);\r\n    }\r\n    else if ('stringValue' in value) {\r\n        return value.stringValue;\r\n    }\r\n    else if ('bytesValue' in value) {\r\n        return canonifyByteString(value.bytesValue);\r\n    }\r\n    else if ('referenceValue' in value) {\r\n        return canonifyReference(value.referenceValue);\r\n    }\r\n    else if ('geoPointValue' in value) {\r\n        return canonifyGeoPoint(value.geoPointValue);\r\n    }\r\n    else if ('arrayValue' in value) {\r\n        return canonifyArray(value.arrayValue);\r\n    }\r\n    else if ('mapValue' in value) {\r\n        return canonifyMap(value.mapValue);\r\n    }\r\n    else {\r\n        return fail();\r\n    }\r\n}\r\nfunction canonifyByteString(byteString) {\r\n    return normalizeByteString(byteString).toBase64();\r\n}\r\nfunction canonifyTimestamp(timestamp) {\r\n    const normalizedTimestamp = normalizeTimestamp(timestamp);\r\n    return `time(${normalizedTimestamp.seconds},${normalizedTimestamp.nanos})`;\r\n}\r\nfunction canonifyGeoPoint(geoPoint) {\r\n    return `geo(${geoPoint.latitude},${geoPoint.longitude})`;\r\n}\r\nfunction canonifyReference(referenceValue) {\r\n    return DocumentKey.fromName(referenceValue).toString();\r\n}\r\nfunction canonifyMap(mapValue) {\r\n    // Iteration order in JavaScript is not guaranteed. To ensure that we generate\r\n    // matching canonical IDs for identical maps, we need to sort the keys.\r\n    const sortedKeys = Object.keys(mapValue.fields || {}).sort();\r\n    let result = '{';\r\n    let first = true;\r\n    for (const key of sortedKeys) {\r\n        if (!first) {\r\n            result += ',';\r\n        }\r\n        else {\r\n            first = false;\r\n        }\r\n        result += `${key}:${canonifyValue(mapValue.fields[key])}`;\r\n    }\r\n    return result + '}';\r\n}\r\nfunction canonifyArray(arrayValue) {\r\n    let result = '[';\r\n    let first = true;\r\n    for (const value of arrayValue.values || []) {\r\n        if (!first) {\r\n            result += ',';\r\n        }\r\n        else {\r\n            first = false;\r\n        }\r\n        result += canonifyValue(value);\r\n    }\r\n    return result + ']';\r\n}\r\n/** Returns a reference value for the provided database and key. */\r\nfunction refValue(databaseId, key) {\r\n    return {\r\n        referenceValue: `projects/${databaseId.projectId}/databases/${databaseId.database}/documents/${key.path.canonicalString()}`\r\n    };\r\n}\r\n/** Returns true if `value` is an IntegerValue . */\r\nfunction isInteger(value) {\r\n    return !!value && 'integerValue' in value;\r\n}\r\n/** Returns true if `value` is a DoubleValue. */\r\nfunction isDouble(value) {\r\n    return !!value && 'doubleValue' in value;\r\n}\r\n/** Returns true if `value` is either an IntegerValue or a DoubleValue. */\r\nfunction isNumber(value) {\r\n    return isInteger(value) || isDouble(value);\r\n}\r\n/** Returns true if `value` is an ArrayValue. */\r\nfunction isArray(value) {\r\n    return !!value && 'arrayValue' in value;\r\n}\r\n/** Returns true if `value` is a NullValue. */\r\nfunction isNullValue(value) {\r\n    return !!value && 'nullValue' in value;\r\n}\r\n/** Returns true if `value` is NaN. */\r\nfunction isNanValue(value) {\r\n    return !!value && 'doubleValue' in value && isNaN(Number(value.doubleValue));\r\n}\r\n/** Returns true if `value` is a MapValue. */\r\nfunction isMapValue(value) {\r\n    return !!value && 'mapValue' in value;\r\n}\n\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\n/**\r\n * An ObjectValue represents a MapValue in the Firestore Proto and offers the\r\n * ability to add and remove fields (via the ObjectValueBuilder).\r\n */\r\nclass ObjectValue {\r\n    constructor(proto) {\r\n        /**\r\n         * A nested map that contains the accumulated changes that haven't yet been\r\n         * applied to `partialValue`. Values can either be `Value` protos, Map<String,\r\n         * Object> values (to represent additional nesting) or `null` (to represent\r\n         * field deletes).\r\n         */\r\n        this.overlayMap = new Map();\r\n        this.partialValue = proto;\r\n    }\r\n    static empty() {\r\n        return new ObjectValue({ mapValue: {} });\r\n    }\r\n    /**\r\n     * Returns the value at the given path or null.\r\n     *\r\n     * @param path - the path to search\r\n     * @returns The value at the path or null if the path is not set.\r\n     */\r\n    field(path) {\r\n        return ObjectValue.extractNestedValue(this.buildProto(), path);\r\n    }\r\n    /** Returns the full protobuf representation. */\r\n    toProto() {\r\n        return this.field(FieldPath.emptyPath());\r\n    }\r\n    /**\r\n     * Sets the field to the provided value.\r\n     *\r\n     * @param path - The field path to set.\r\n     * @param value - The value to set.\r\n     */\r\n    set(path, value) {\r\n        this.setOverlay(path, value);\r\n    }\r\n    /**\r\n     * Sets the provided fields to the provided values.\r\n     *\r\n     * @param data - A map of fields to values (or null for deletes).\r\n     */\r\n    setAll(data) {\r\n        data.forEach((value, fieldPath) => {\r\n            if (value) {\r\n                this.set(fieldPath, value);\r\n            }\r\n            else {\r\n                this.delete(fieldPath);\r\n            }\r\n        });\r\n    }\r\n    /**\r\n     * Removes the field at the specified path. If there is no field at the\r\n     * specified path, nothing is changed.\r\n     *\r\n     * @param path - The field path to remove.\r\n     */\r\n    delete(path) {\r\n        this.setOverlay(path, null);\r\n    }\r\n    isEqual(other) {\r\n        return valueEquals(this.buildProto(), other.buildProto());\r\n    }\r\n    /**\r\n     * Adds `value` to the overlay map at `path`. Creates nested map entries if\r\n     * needed.\r\n     */\r\n    setOverlay(path, value) {\r\n        let currentLevel = this.overlayMap;\r\n        for (let i = 0; i < path.length - 1; ++i) {\r\n            const currentSegment = path.get(i);\r\n            let currentValue = currentLevel.get(currentSegment);\r\n            if (currentValue instanceof Map) {\r\n                // Re-use a previously created map\r\n                currentLevel = currentValue;\r\n            }\r\n            else if (currentValue &&\r\n                typeOrder(currentValue) === 10 /* ObjectValue */) {\r\n                // Convert the existing Protobuf MapValue into a map\r\n                currentValue = new Map(Object.entries(currentValue.mapValue.fields || {}));\r\n                currentLevel.set(currentSegment, currentValue);\r\n                currentLevel = currentValue;\r\n            }\r\n            else {\r\n                // Create an empty map to represent the current nesting level\r\n                currentValue = new Map();\r\n                currentLevel.set(currentSegment, currentValue);\r\n                currentLevel = currentValue;\r\n            }\r\n        }\r\n        currentLevel.set(path.lastSegment(), value);\r\n    }\r\n    /**\r\n     * Applies any overlays from `currentOverlays` that exist at `currentPath`\r\n     * and returns the merged data at `currentPath` (or null if there were no\r\n     * changes).\r\n     *\r\n     * @param currentPath - The path at the current nesting level. Can be set to\r\n     * FieldValue.emptyPath() to represent the root.\r\n     * @param currentOverlays - The overlays at the current nesting level in the\r\n     * same format as `overlayMap`.\r\n     * @returns The merged data at `currentPath` or null if no modifications\r\n     * were applied.\r\n     */\r\n    applyOverlay(currentPath, currentOverlays) {\r\n        let modified = false;\r\n        const existingValue = ObjectValue.extractNestedValue(this.partialValue, currentPath);\r\n        const resultAtPath = isMapValue(existingValue)\r\n            ? // If there is already data at the current path, base our\r\n             Object.assign({}, existingValue.mapValue.fields) : {};\r\n        currentOverlays.forEach((value, pathSegment) => {\r\n            if (value instanceof Map) {\r\n                const nested = this.applyOverlay(currentPath.child(pathSegment), value);\r\n                if (nested != null) {\r\n                    resultAtPath[pathSegment] = nested;\r\n                    modified = true;\r\n                }\r\n            }\r\n            else if (value !== null) {\r\n                resultAtPath[pathSegment] = value;\r\n                modified = true;\r\n            }\r\n            else if (resultAtPath.hasOwnProperty(pathSegment)) {\r\n                delete resultAtPath[pathSegment];\r\n                modified = true;\r\n            }\r\n        });\r\n        return modified ? { mapValue: { fields: resultAtPath } } : null;\r\n    }\r\n    /**\r\n     * Builds the Protobuf that backs this ObjectValue.\r\n     *\r\n     * This method applies any outstanding modifications and memoizes the result.\r\n     * Further invocations are based on this memoized result.\r\n     */\r\n    buildProto() {\r\n        const mergedResult = this.applyOverlay(FieldPath.emptyPath(), this.overlayMap);\r\n        if (mergedResult != null) {\r\n            this.partialValue = mergedResult;\r\n            this.overlayMap.clear();\r\n        }\r\n        return this.partialValue;\r\n    }\r\n    static extractNestedValue(proto, path) {\r\n        if (path.isEmpty()) {\r\n            return proto;\r\n        }\r\n        else {\r\n            let value = proto;\r\n            for (let i = 0; i < path.length - 1; ++i) {\r\n                if (!value.mapValue.fields) {\r\n                    return null;\r\n                }\r\n                value = value.mapValue.fields[path.get(i)];\r\n                if (!isMapValue(value)) {\r\n                    return null;\r\n                }\r\n            }\r\n            value = (value.mapValue.fields || {})[path.lastSegment()];\r\n            return value || null;\r\n        }\r\n    }\r\n    clone() {\r\n        return new ObjectValue(this.buildProto());\r\n    }\r\n}\r\n/**\r\n * Returns a FieldMask built from all fields in a MapValue.\r\n */\r\nfunction extractFieldMask(value) {\r\n    const fields = [];\r\n    forEach(value.fields || {}, (key, value) => {\r\n        const currentPath = new FieldPath([key]);\r\n        if (isMapValue(value)) {\r\n            const nestedMask = extractFieldMask(value.mapValue);\r\n            const nestedFields = nestedMask.fields;\r\n            if (nestedFields.length === 0) {\r\n                // Preserve the empty map by adding it to the FieldMask.\r\n                fields.push(currentPath);\r\n            }\r\n            else {\r\n                // For nested and non-empty ObjectValues, add the FieldPath of the\r\n                // leaf nodes.\r\n                for (const nestedPath of nestedFields) {\r\n                    fields.push(currentPath.child(nestedPath));\r\n                }\r\n            }\r\n        }\r\n        else {\r\n            // For nested and non-empty ObjectValues, add the FieldPath of the leaf\r\n            // nodes.\r\n            fields.push(currentPath);\r\n        }\r\n    });\r\n    return new FieldMask(fields);\r\n}\n\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\n/**\r\n * Represents a document in Firestore with a key, version, data and whether it\r\n * has local mutations applied to it.\r\n *\r\n * Documents can transition between states via `convertToFoundDocument()`,\r\n * `convertToNoDocument()` and `convertToUnknownDocument()`. If a document does\r\n * not transition to one of these states even after all mutations have been\r\n * applied, `isValidDocument()` returns false and the document should be removed\r\n * from all views.\r\n */\r\nclass MutableDocument {\r\n    constructor(key, documentType, version, data, documentState) {\r\n        this.key = key;\r\n        this.documentType = documentType;\r\n        this.version = version;\r\n        this.data = data;\r\n        this.documentState = documentState;\r\n    }\r\n    /**\r\n     * Creates a document with no known version or data, but which can serve as\r\n     * base document for mutations.\r\n     */\r\n    static newInvalidDocument(documentKey) {\r\n        return new MutableDocument(documentKey, 0 /* INVALID */, SnapshotVersion.min(), ObjectValue.empty(), 0 /* SYNCED */);\r\n    }\r\n    /**\r\n     * Creates a new document that is known to exist with the given data at the\r\n     * given version.\r\n     */\r\n    static newFoundDocument(documentKey, version, value) {\r\n        return new MutableDocument(documentKey, 1 /* FOUND_DOCUMENT */, version, value, 0 /* SYNCED */);\r\n    }\r\n    /** Creates a new document that is known to not exist at the given version. */\r\n    static newNoDocument(documentKey, version) {\r\n        return new MutableDocument(documentKey, 2 /* NO_DOCUMENT */, version, ObjectValue.empty(), 0 /* SYNCED */);\r\n    }\r\n    /**\r\n     * Creates a new document that is known to exist at the given version but\r\n     * whose data is not known (e.g. a document that was updated without a known\r\n     * base document).\r\n     */\r\n    static newUnknownDocument(documentKey, version) {\r\n        return new MutableDocument(documentKey, 3 /* UNKNOWN_DOCUMENT */, version, ObjectValue.empty(), 2 /* HAS_COMMITTED_MUTATIONS */);\r\n    }\r\n    /**\r\n     * Changes the document type to indicate that it exists and that its version\r\n     * and data are known.\r\n     */\r\n    convertToFoundDocument(version, value) {\r\n        this.version = version;\r\n        this.documentType = 1 /* FOUND_DOCUMENT */;\r\n        this.data = value;\r\n        this.documentState = 0 /* SYNCED */;\r\n        return this;\r\n    }\r\n    /**\r\n     * Changes the document type to indicate that it doesn't exist at the given\r\n     * version.\r\n     */\r\n    convertToNoDocument(version) {\r\n        this.version = version;\r\n        this.documentType = 2 /* NO_DOCUMENT */;\r\n        this.data = ObjectValue.empty();\r\n        this.documentState = 0 /* SYNCED */;\r\n        return this;\r\n    }\r\n    /**\r\n     * Changes the document type to indicate that it exists at a given version but\r\n     * that its data is not known (e.g. a document that was updated without a known\r\n     * base document).\r\n     */\r\n    convertToUnknownDocument(version) {\r\n        this.version = version;\r\n        this.documentType = 3 /* UNKNOWN_DOCUMENT */;\r\n        this.data = ObjectValue.empty();\r\n        this.documentState = 2 /* HAS_COMMITTED_MUTATIONS */;\r\n        return this;\r\n    }\r\n    setHasCommittedMutations() {\r\n        this.documentState = 2 /* HAS_COMMITTED_MUTATIONS */;\r\n        return this;\r\n    }\r\n    setHasLocalMutations() {\r\n        this.documentState = 1 /* HAS_LOCAL_MUTATIONS */;\r\n        return this;\r\n    }\r\n    get hasLocalMutations() {\r\n        return this.documentState === 1 /* HAS_LOCAL_MUTATIONS */;\r\n    }\r\n    get hasCommittedMutations() {\r\n        return this.documentState === 2 /* HAS_COMMITTED_MUTATIONS */;\r\n    }\r\n    get hasPendingWrites() {\r\n        return this.hasLocalMutations || this.hasCommittedMutations;\r\n    }\r\n    isValidDocument() {\r\n        return this.documentType !== 0 /* INVALID */;\r\n    }\r\n    isFoundDocument() {\r\n        return this.documentType === 1 /* FOUND_DOCUMENT */;\r\n    }\r\n    isNoDocument() {\r\n        return this.documentType === 2 /* NO_DOCUMENT */;\r\n    }\r\n    isUnknownDocument() {\r\n        return this.documentType === 3 /* UNKNOWN_DOCUMENT */;\r\n    }\r\n    isEqual(other) {\r\n        return (other instanceof MutableDocument &&\r\n            this.key.isEqual(other.key) &&\r\n            this.version.isEqual(other.version) &&\r\n            this.documentType === other.documentType &&\r\n            this.documentState === other.documentState &&\r\n            this.data.isEqual(other.data));\r\n    }\r\n    clone() {\r\n        return new MutableDocument(this.key, this.documentType, this.version, this.data.clone(), this.documentState);\r\n    }\r\n    toString() {\r\n        return (`Document(${this.key}, ${this.version}, ${JSON.stringify(this.data.toProto())}, ` +\r\n            `{documentType: ${this.documentType}}), ` +\r\n            `{documentState: ${this.documentState}})`);\r\n    }\r\n}\r\n/**\r\n * Compares the value for field `field` in the provided documents. Throws if\r\n * the field does not exist in both documents.\r\n */\r\nfunction compareDocumentsByField(field, d1, d2) {\r\n    const v1 = d1.data.field(field);\r\n    const v2 = d2.data.field(field);\r\n    if (v1 !== null && v2 !== null) {\r\n        return valueCompare(v1, v2);\r\n    }\r\n    else {\r\n        return fail();\r\n    }\r\n}\n\n/**\r\n * @license\r\n * Copyright 2019 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\n// Visible for testing\r\nclass TargetImpl {\r\n    constructor(path, collectionGroup = null, orderBy = [], filters = [], limit = null, startAt = null, endAt = null) {\r\n        this.path = path;\r\n        this.collectionGroup = collectionGroup;\r\n        this.orderBy = orderBy;\r\n        this.filters = filters;\r\n        this.limit = limit;\r\n        this.startAt = startAt;\r\n        this.endAt = endAt;\r\n        this.memoizedCanonicalId = null;\r\n    }\r\n}\r\n/**\r\n * Initializes a Target with a path and optional additional query constraints.\r\n * Path must currently be empty if this is a collection group query.\r\n *\r\n * NOTE: you should always construct `Target` from `Query.toTarget` instead of\r\n * using this factory method, because `Query` provides an implicit `orderBy`\r\n * property.\r\n */\r\nfunction newTarget(path, collectionGroup = null, orderBy = [], filters = [], limit = null, startAt = null, endAt = null) {\r\n    return new TargetImpl(path, collectionGroup, orderBy, filters, limit, startAt, endAt);\r\n}\r\nfunction canonifyTarget(target) {\r\n    const targetImpl = debugCast(target);\r\n    if (targetImpl.memoizedCanonicalId === null) {\r\n        let canonicalId = targetImpl.path.canonicalString();\r\n        if (targetImpl.collectionGroup !== null) {\r\n            canonicalId += '|cg:' + targetImpl.collectionGroup;\r\n        }\r\n        canonicalId += '|f:';\r\n        canonicalId += targetImpl.filters.map(f => canonifyFilter(f)).join(',');\r\n        canonicalId += '|ob:';\r\n        canonicalId += targetImpl.orderBy.map(o => canonifyOrderBy(o)).join(',');\r\n        if (!isNullOrUndefined(targetImpl.limit)) {\r\n            canonicalId += '|l:';\r\n            canonicalId += targetImpl.limit;\r\n        }\r\n        if (targetImpl.startAt) {\r\n            canonicalId += '|lb:';\r\n            canonicalId += canonifyBound(targetImpl.startAt);\r\n        }\r\n        if (targetImpl.endAt) {\r\n            canonicalId += '|ub:';\r\n            canonicalId += canonifyBound(targetImpl.endAt);\r\n        }\r\n        targetImpl.memoizedCanonicalId = canonicalId;\r\n    }\r\n    return targetImpl.memoizedCanonicalId;\r\n}\r\nfunction stringifyTarget(target) {\r\n    let str = target.path.canonicalString();\r\n    if (target.collectionGroup !== null) {\r\n        str += ' collectionGroup=' + target.collectionGroup;\r\n    }\r\n    if (target.filters.length > 0) {\r\n        str += `, filters: [${target.filters\r\n            .map(f => stringifyFilter(f))\r\n            .join(', ')}]`;\r\n    }\r\n    if (!isNullOrUndefined(target.limit)) {\r\n        str += ', limit: ' + target.limit;\r\n    }\r\n    if (target.orderBy.length > 0) {\r\n        str += `, orderBy: [${target.orderBy\r\n            .map(o => stringifyOrderBy(o))\r\n            .join(', ')}]`;\r\n    }\r\n    if (target.startAt) {\r\n        str += ', startAt: ' + canonifyBound(target.startAt);\r\n    }\r\n    if (target.endAt) {\r\n        str += ', endAt: ' + canonifyBound(target.endAt);\r\n    }\r\n    return `Target(${str})`;\r\n}\r\nfunction targetEquals(left, right) {\r\n    if (left.limit !== right.limit) {\r\n        return false;\r\n    }\r\n    if (left.orderBy.length !== right.orderBy.length) {\r\n        return false;\r\n    }\r\n    for (let i = 0; i < left.orderBy.length; i++) {\r\n        if (!orderByEquals(left.orderBy[i], right.orderBy[i])) {\r\n            return false;\r\n        }\r\n    }\r\n    if (left.filters.length !== right.filters.length) {\r\n        return false;\r\n    }\r\n    for (let i = 0; i < left.filters.length; i++) {\r\n        if (!filterEquals(left.filters[i], right.filters[i])) {\r\n            return false;\r\n        }\r\n    }\r\n    if (left.collectionGroup !== right.collectionGroup) {\r\n        return false;\r\n    }\r\n    if (!left.path.isEqual(right.path)) {\r\n        return false;\r\n    }\r\n    if (!boundEquals(left.startAt, right.startAt)) {\r\n        return false;\r\n    }\r\n    return boundEquals(left.endAt, right.endAt);\r\n}\r\nfunction isDocumentTarget(target) {\r\n    return (DocumentKey.isDocumentKey(target.path) &&\r\n        target.collectionGroup === null &&\r\n        target.filters.length === 0);\r\n}\r\nclass Filter {\r\n}\r\nclass FieldFilter extends Filter {\r\n    constructor(field, op, value) {\r\n        super();\r\n        this.field = field;\r\n        this.op = op;\r\n        this.value = value;\r\n    }\r\n    /**\r\n     * Creates a filter based on the provided arguments.\r\n     */\r\n    static create(field, op, value) {\r\n        if (field.isKeyField()) {\r\n            if (op === \"in\" /* IN */ || op === \"not-in\" /* NOT_IN */) {\r\n                return this.createKeyFieldInFilter(field, op, value);\r\n            }\r\n            else {\r\n                return new KeyFieldFilter(field, op, value);\r\n            }\r\n        }\r\n        else if (op === \"array-contains\" /* ARRAY_CONTAINS */) {\r\n            return new ArrayContainsFilter(field, value);\r\n        }\r\n        else if (op === \"in\" /* IN */) {\r\n            return new InFilter(field, value);\r\n        }\r\n        else if (op === \"not-in\" /* NOT_IN */) {\r\n            return new NotInFilter(field, value);\r\n        }\r\n        else if (op === \"array-contains-any\" /* ARRAY_CONTAINS_ANY */) {\r\n            return new ArrayContainsAnyFilter(field, value);\r\n        }\r\n        else {\r\n            return new FieldFilter(field, op, value);\r\n        }\r\n    }\r\n    static createKeyFieldInFilter(field, op, value) {\r\n        return op === \"in\" /* IN */\r\n            ? new KeyFieldInFilter(field, value)\r\n            : new KeyFieldNotInFilter(field, value);\r\n    }\r\n    matches(doc) {\r\n        const other = doc.data.field(this.field);\r\n        // Types do not have to match in NOT_EQUAL filters.\r\n        if (this.op === \"!=\" /* NOT_EQUAL */) {\r\n            return (other !== null &&\r\n                this.matchesComparison(valueCompare(other, this.value)));\r\n        }\r\n        // Only compare types with matching backend order (such as double and int).\r\n        return (other !== null &&\r\n            typeOrder(this.value) === typeOrder(other) &&\r\n            this.matchesComparison(valueCompare(other, this.value)));\r\n    }\r\n    matchesComparison(comparison) {\r\n        switch (this.op) {\r\n            case \"<\" /* LESS_THAN */:\r\n                return comparison < 0;\r\n            case \"<=\" /* LESS_THAN_OR_EQUAL */:\r\n                return comparison <= 0;\r\n            case \"==\" /* EQUAL */:\r\n                return comparison === 0;\r\n            case \"!=\" /* NOT_EQUAL */:\r\n                return comparison !== 0;\r\n            case \">\" /* GREATER_THAN */:\r\n                return comparison > 0;\r\n            case \">=\" /* GREATER_THAN_OR_EQUAL */:\r\n                return comparison >= 0;\r\n            default:\r\n                return fail();\r\n        }\r\n    }\r\n    isInequality() {\r\n        return ([\r\n            \"<\" /* LESS_THAN */,\r\n            \"<=\" /* LESS_THAN_OR_EQUAL */,\r\n            \">\" /* GREATER_THAN */,\r\n            \">=\" /* GREATER_THAN_OR_EQUAL */,\r\n            \"!=\" /* NOT_EQUAL */,\r\n            \"not-in\" /* NOT_IN */\r\n        ].indexOf(this.op) >= 0);\r\n    }\r\n}\r\nfunction canonifyFilter(filter) {\r\n    // TODO(b/29183165): Technically, this won't be unique if two values have\r\n    // the same description, such as the int 3 and the string \"3\". So we should\r\n    // add the types in here somehow, too.\r\n    return (filter.field.canonicalString() +\r\n        filter.op.toString() +\r\n        canonicalId(filter.value));\r\n}\r\nfunction filterEquals(f1, f2) {\r\n    return (f1.op === f2.op &&\r\n        f1.field.isEqual(f2.field) &&\r\n        valueEquals(f1.value, f2.value));\r\n}\r\n/** Returns a debug description for `filter`. */\r\nfunction stringifyFilter(filter) {\r\n    return `${filter.field.canonicalString()} ${filter.op} ${canonicalId(filter.value)}`;\r\n}\r\n/** Filter that matches on key fields (i.e. '__name__'). */\r\nclass KeyFieldFilter extends FieldFilter {\r\n    constructor(field, op, value) {\r\n        super(field, op, value);\r\n        this.key = DocumentKey.fromName(value.referenceValue);\r\n    }\r\n    matches(doc) {\r\n        const comparison = DocumentKey.comparator(doc.key, this.key);\r\n        return this.matchesComparison(comparison);\r\n    }\r\n}\r\n/** Filter that matches on key fields within an array. */\r\nclass KeyFieldInFilter extends FieldFilter {\r\n    constructor(field, value) {\r\n        super(field, \"in\" /* IN */, value);\r\n        this.keys = extractDocumentKeysFromArrayValue(\"in\" /* IN */, value);\r\n    }\r\n    matches(doc) {\r\n        return this.keys.some(key => key.isEqual(doc.key));\r\n    }\r\n}\r\n/** Filter that matches on key fields not present within an array. */\r\nclass KeyFieldNotInFilter extends FieldFilter {\r\n    constructor(field, value) {\r\n        super(field, \"not-in\" /* NOT_IN */, value);\r\n        this.keys = extractDocumentKeysFromArrayValue(\"not-in\" /* NOT_IN */, value);\r\n    }\r\n    matches(doc) {\r\n        return !this.keys.some(key => key.isEqual(doc.key));\r\n    }\r\n}\r\nfunction extractDocumentKeysFromArrayValue(op, value) {\r\n    var _a;\r\n    return (((_a = value.arrayValue) === null || _a === void 0 ? void 0 : _a.values) || []).map(v => {\r\n        return DocumentKey.fromName(v.referenceValue);\r\n    });\r\n}\r\n/** A Filter that implements the array-contains operator. */\r\nclass ArrayContainsFilter extends FieldFilter {\r\n    constructor(field, value) {\r\n        super(field, \"array-contains\" /* ARRAY_CONTAINS */, value);\r\n    }\r\n    matches(doc) {\r\n        const other = doc.data.field(this.field);\r\n        return isArray(other) && arrayValueContains(other.arrayValue, this.value);\r\n    }\r\n}\r\n/** A Filter that implements the IN operator. */\r\nclass InFilter extends FieldFilter {\r\n    constructor(field, value) {\r\n        super(field, \"in\" /* IN */, value);\r\n    }\r\n    matches(doc) {\r\n        const other = doc.data.field(this.field);\r\n        return other !== null && arrayValueContains(this.value.arrayValue, other);\r\n    }\r\n}\r\n/** A Filter that implements the not-in operator. */\r\nclass NotInFilter extends FieldFilter {\r\n    constructor(field, value) {\r\n        super(field, \"not-in\" /* NOT_IN */, value);\r\n    }\r\n    matches(doc) {\r\n        if (arrayValueContains(this.value.arrayValue, { nullValue: 'NULL_VALUE' })) {\r\n            return false;\r\n        }\r\n        const other = doc.data.field(this.field);\r\n        return other !== null && !arrayValueContains(this.value.arrayValue, other);\r\n    }\r\n}\r\n/** A Filter that implements the array-contains-any operator. */\r\nclass ArrayContainsAnyFilter extends FieldFilter {\r\n    constructor(field, value) {\r\n        super(field, \"array-contains-any\" /* ARRAY_CONTAINS_ANY */, value);\r\n    }\r\n    matches(doc) {\r\n        const other = doc.data.field(this.field);\r\n        if (!isArray(other) || !other.arrayValue.values) {\r\n            return false;\r\n        }\r\n        return other.arrayValue.values.some(val => arrayValueContains(this.value.arrayValue, val));\r\n    }\r\n}\r\n/**\r\n * Represents a bound of a query.\r\n *\r\n * The bound is specified with the given components representing a position and\r\n * whether it's just before or just after the position (relative to whatever the\r\n * query order is).\r\n *\r\n * The position represents a logical index position for a query. It's a prefix\r\n * of values for the (potentially implicit) order by clauses of a query.\r\n *\r\n * Bound provides a function to determine whether a document comes before or\r\n * after a bound. This is influenced by whether the position is just before or\r\n * just after the provided values.\r\n */\r\nclass Bound {\r\n    constructor(position, before) {\r\n        this.position = position;\r\n        this.before = before;\r\n    }\r\n}\r\nfunction canonifyBound(bound) {\r\n    // TODO(b/29183165): Make this collision robust.\r\n    return `${bound.before ? 'b' : 'a'}:${bound.position\r\n        .map(p => canonicalId(p))\r\n        .join(',')}`;\r\n}\r\n/**\r\n * An ordering on a field, in some Direction. Direction defaults to ASCENDING.\r\n */\r\nclass OrderBy {\r\n    constructor(field, dir = \"asc\" /* ASCENDING */) {\r\n        this.field = field;\r\n        this.dir = dir;\r\n    }\r\n}\r\nfunction canonifyOrderBy(orderBy) {\r\n    // TODO(b/29183165): Make this collision robust.\r\n    return orderBy.field.canonicalString() + orderBy.dir;\r\n}\r\nfunction stringifyOrderBy(orderBy) {\r\n    return `${orderBy.field.canonicalString()} (${orderBy.dir})`;\r\n}\r\nfunction orderByEquals(left, right) {\r\n    return left.dir === right.dir && left.field.isEqual(right.field);\r\n}\r\n/**\r\n * Returns true if a document sorts before a bound using the provided sort\r\n * order.\r\n */\r\nfunction sortsBeforeDocument(bound, orderBy, doc) {\r\n    let comparison = 0;\r\n    for (let i = 0; i < bound.position.length; i++) {\r\n        const orderByComponent = orderBy[i];\r\n        const component = bound.position[i];\r\n        if (orderByComponent.field.isKeyField()) {\r\n            comparison = DocumentKey.comparator(DocumentKey.fromName(component.referenceValue), doc.key);\r\n        }\r\n        else {\r\n            const docValue = doc.data.field(orderByComponent.field);\r\n            comparison = valueCompare(component, docValue);\r\n        }\r\n        if (orderByComponent.dir === \"desc\" /* DESCENDING */) {\r\n            comparison = comparison * -1;\r\n        }\r\n        if (comparison !== 0) {\r\n            break;\r\n        }\r\n    }\r\n    return bound.before ? comparison <= 0 : comparison < 0;\r\n}\r\nfunction boundEquals(left, right) {\r\n    if (left === null) {\r\n        return right === null;\r\n    }\r\n    else if (right === null) {\r\n        return false;\r\n    }\r\n    if (left.before !== right.before ||\r\n        left.position.length !== right.position.length) {\r\n        return false;\r\n    }\r\n    for (let i = 0; i < left.position.length; i++) {\r\n        const leftPosition = left.position[i];\r\n        const rightPosition = right.position[i];\r\n        if (!valueEquals(leftPosition, rightPosition)) {\r\n            return false;\r\n        }\r\n    }\r\n    return true;\r\n}\n\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\n/**\r\n * Query encapsulates all the query attributes we support in the SDK. It can\r\n * be run against the LocalStore, as well as be converted to a `Target` to\r\n * query the RemoteStore results.\r\n *\r\n * Visible for testing.\r\n */\r\nclass QueryImpl {\r\n    /**\r\n     * Initializes a Query with a path and optional additional query constraints.\r\n     * Path must currently be empty if this is a collection group query.\r\n     */\r\n    constructor(path, collectionGroup = null, explicitOrderBy = [], filters = [], limit = null, limitType = \"F\" /* First */, startAt = null, endAt = null) {\r\n        this.path = path;\r\n        this.collectionGroup = collectionGroup;\r\n        this.explicitOrderBy = explicitOrderBy;\r\n        this.filters = filters;\r\n        this.limit = limit;\r\n        this.limitType = limitType;\r\n        this.startAt = startAt;\r\n        this.endAt = endAt;\r\n        this.memoizedOrderBy = null;\r\n        // The corresponding `Target` of this `Query` instance.\r\n        this.memoizedTarget = null;\r\n        if (this.startAt) ;\r\n        if (this.endAt) ;\r\n    }\r\n}\r\n/** Creates a new Query instance with the options provided. */\r\nfunction newQuery(path, collectionGroup, explicitOrderBy, filters, limit, limitType, startAt, endAt) {\r\n    return new QueryImpl(path, collectionGroup, explicitOrderBy, filters, limit, limitType, startAt, endAt);\r\n}\r\n/** Creates a new Query for a query that matches all documents at `path` */\r\nfunction newQueryForPath(path) {\r\n    return new QueryImpl(path);\r\n}\r\n/**\r\n * Helper to convert a collection group query into a collection query at a\r\n * specific path. This is used when executing collection group queries, since\r\n * we have to split the query into a set of collection queries at multiple\r\n * paths.\r\n */\r\nfunction asCollectionQueryAtPath(query, path) {\r\n    return new QueryImpl(path, \r\n    /*collectionGroup=*/ null, query.explicitOrderBy.slice(), query.filters.slice(), query.limit, query.limitType, query.startAt, query.endAt);\r\n}\r\n/**\r\n * Returns true if this query does not specify any query constraints that\r\n * could remove results.\r\n */\r\nfunction matchesAllDocuments(query) {\r\n    return (query.filters.length === 0 &&\r\n        query.limit === null &&\r\n        query.startAt == null &&\r\n        query.endAt == null &&\r\n        (query.explicitOrderBy.length === 0 ||\r\n            (query.explicitOrderBy.length === 1 &&\r\n                query.explicitOrderBy[0].field.isKeyField())));\r\n}\r\nfunction hasLimitToFirst(query) {\r\n    return !isNullOrUndefined(query.limit) && query.limitType === \"F\" /* First */;\r\n}\r\nfunction hasLimitToLast(query) {\r\n    return !isNullOrUndefined(query.limit) && query.limitType === \"L\" /* Last */;\r\n}\r\nfunction getFirstOrderByField(query) {\r\n    return query.explicitOrderBy.length > 0\r\n        ? query.explicitOrderBy[0].field\r\n        : null;\r\n}\r\nfunction getInequalityFilterField(query) {\r\n    for (const filter of query.filters) {\r\n        if (filter.isInequality()) {\r\n            return filter.field;\r\n        }\r\n    }\r\n    return null;\r\n}\r\n/**\r\n * Checks if any of the provided Operators are included in the query and\r\n * returns the first one that is, or null if none are.\r\n */\r\nfunction findFilterOperator(query, operators) {\r\n    for (const filter of query.filters) {\r\n        if (operators.indexOf(filter.op) >= 0) {\r\n            return filter.op;\r\n        }\r\n    }\r\n    return null;\r\n}\r\n/**\r\n * Creates a new Query for a collection group query that matches all documents\r\n * within the provided collection group.\r\n */\r\nfunction newQueryForCollectionGroup(collectionId) {\r\n    return new QueryImpl(ResourcePath.emptyPath(), collectionId);\r\n}\r\n/**\r\n * Returns whether the query matches a single document by path (rather than a\r\n * collection).\r\n */\r\nfunction isDocumentQuery(query) {\r\n    return (DocumentKey.isDocumentKey(query.path) &&\r\n        query.collectionGroup === null &&\r\n        query.filters.length === 0);\r\n}\r\n/**\r\n * Returns whether the query matches a collection group rather than a specific\r\n * collection.\r\n */\r\nfunction isCollectionGroupQuery(query) {\r\n    return query.collectionGroup !== null;\r\n}\r\n/**\r\n * Returns the implicit order by constraint that is used to execute the Query,\r\n * which can be different from the order by constraints the user provided (e.g.\r\n * the SDK and backend always orders by `__name__`).\r\n */\r\nfunction queryOrderBy(query) {\r\n    const queryImpl = debugCast(query);\r\n    if (queryImpl.memoizedOrderBy === null) {\r\n        queryImpl.memoizedOrderBy = [];\r\n        const inequalityField = getInequalityFilterField(queryImpl);\r\n        const firstOrderByField = getFirstOrderByField(queryImpl);\r\n        if (inequalityField !== null && firstOrderByField === null) {\r\n            // In order to implicitly add key ordering, we must also add the\r\n            // inequality filter field for it to be a valid query.\r\n            // Note that the default inequality field and key ordering is ascending.\r\n            if (!inequalityField.isKeyField()) {\r\n                queryImpl.memoizedOrderBy.push(new OrderBy(inequalityField));\r\n            }\r\n            queryImpl.memoizedOrderBy.push(new OrderBy(FieldPath.keyField(), \"asc\" /* ASCENDING */));\r\n        }\r\n        else {\r\n            let foundKeyOrdering = false;\r\n            for (const orderBy of queryImpl.explicitOrderBy) {\r\n                queryImpl.memoizedOrderBy.push(orderBy);\r\n                if (orderBy.field.isKeyField()) {\r\n                    foundKeyOrdering = true;\r\n                }\r\n            }\r\n            if (!foundKeyOrdering) {\r\n                // The order of the implicit key ordering always matches the last\r\n                // explicit order by\r\n                const lastDirection = queryImpl.explicitOrderBy.length > 0\r\n                    ? queryImpl.explicitOrderBy[queryImpl.explicitOrderBy.length - 1]\r\n                        .dir\r\n                    : \"asc\" /* ASCENDING */;\r\n                queryImpl.memoizedOrderBy.push(new OrderBy(FieldPath.keyField(), lastDirection));\r\n            }\r\n        }\r\n    }\r\n    return queryImpl.memoizedOrderBy;\r\n}\r\n/**\r\n * Converts this `Query` instance to it's corresponding `Target` representation.\r\n */\r\nfunction queryToTarget(query) {\r\n    const queryImpl = debugCast(query);\r\n    if (!queryImpl.memoizedTarget) {\r\n        if (queryImpl.limitType === \"F\" /* First */) {\r\n            queryImpl.memoizedTarget = newTarget(queryImpl.path, queryImpl.collectionGroup, queryOrderBy(queryImpl), queryImpl.filters, queryImpl.limit, queryImpl.startAt, queryImpl.endAt);\r\n        }\r\n        else {\r\n            // Flip the orderBy directions since we want the last results\r\n            const orderBys = [];\r\n            for (const orderBy of queryOrderBy(queryImpl)) {\r\n                const dir = orderBy.dir === \"desc\" /* DESCENDING */\r\n                    ? \"asc\" /* ASCENDING */\r\n                    : \"desc\" /* DESCENDING */;\r\n                orderBys.push(new OrderBy(orderBy.field, dir));\r\n            }\r\n            // We need to swap the cursors to match the now-flipped query ordering.\r\n            const startAt = queryImpl.endAt\r\n                ? new Bound(queryImpl.endAt.position, !queryImpl.endAt.before)\r\n                : null;\r\n            const endAt = queryImpl.startAt\r\n                ? new Bound(queryImpl.startAt.position, !queryImpl.startAt.before)\r\n                : null;\r\n            // Now return as a LimitType.First query.\r\n            queryImpl.memoizedTarget = newTarget(queryImpl.path, queryImpl.collectionGroup, orderBys, queryImpl.filters, queryImpl.limit, startAt, endAt);\r\n        }\r\n    }\r\n    return queryImpl.memoizedTarget;\r\n}\r\nfunction queryWithAddedFilter(query, filter) {\r\n    const newFilters = query.filters.concat([filter]);\r\n    return new QueryImpl(query.path, query.collectionGroup, query.explicitOrderBy.slice(), newFilters, query.limit, query.limitType, query.startAt, query.endAt);\r\n}\r\nfunction queryWithAddedOrderBy(query, orderBy) {\r\n    // TODO(dimond): validate that orderBy does not list the same key twice.\r\n    const newOrderBy = query.explicitOrderBy.concat([orderBy]);\r\n    return new QueryImpl(query.path, query.collectionGroup, newOrderBy, query.filters.slice(), query.limit, query.limitType, query.startAt, query.endAt);\r\n}\r\nfunction queryWithLimit(query, limit, limitType) {\r\n    return new QueryImpl(query.path, query.collectionGroup, query.explicitOrderBy.slice(), query.filters.slice(), limit, limitType, query.startAt, query.endAt);\r\n}\r\nfunction queryWithStartAt(query, bound) {\r\n    return new QueryImpl(query.path, query.collectionGroup, query.explicitOrderBy.slice(), query.filters.slice(), query.limit, query.limitType, bound, query.endAt);\r\n}\r\nfunction queryWithEndAt(query, bound) {\r\n    return new QueryImpl(query.path, query.collectionGroup, query.explicitOrderBy.slice(), query.filters.slice(), query.limit, query.limitType, query.startAt, bound);\r\n}\r\nfunction queryEquals(left, right) {\r\n    return (targetEquals(queryToTarget(left), queryToTarget(right)) &&\r\n        left.limitType === right.limitType);\r\n}\r\n// TODO(b/29183165): This is used to get a unique string from a query to, for\r\n// example, use as a dictionary key, but the implementation is subject to\r\n// collisions. Make it collision-free.\r\nfunction canonifyQuery(query) {\r\n    return `${canonifyTarget(queryToTarget(query))}|lt:${query.limitType}`;\r\n}\r\nfunction stringifyQuery(query) {\r\n    return `Query(target=${stringifyTarget(queryToTarget(query))}; limitType=${query.limitType})`;\r\n}\r\n/** Returns whether `doc` matches the constraints of `query`. */\r\nfunction queryMatches(query, doc) {\r\n    return (doc.isFoundDocument() &&\r\n        queryMatchesPathAndCollectionGroup(query, doc) &&\r\n        queryMatchesOrderBy(query, doc) &&\r\n        queryMatchesFilters(query, doc) &&\r\n        queryMatchesBounds(query, doc));\r\n}\r\nfunction queryMatchesPathAndCollectionGroup(query, doc) {\r\n    const docPath = doc.key.path;\r\n    if (query.collectionGroup !== null) {\r\n        // NOTE: this.path is currently always empty since we don't expose Collection\r\n        // Group queries rooted at a document path yet.\r\n        return (doc.key.hasCollectionId(query.collectionGroup) &&\r\n            query.path.isPrefixOf(docPath));\r\n    }\r\n    else if (DocumentKey.isDocumentKey(query.path)) {\r\n        // exact match for document queries\r\n        return query.path.isEqual(docPath);\r\n    }\r\n    else {\r\n        // shallow ancestor queries by default\r\n        return query.path.isImmediateParentOf(docPath);\r\n    }\r\n}\r\n/**\r\n * A document must have a value for every ordering clause in order to show up\r\n * in the results.\r\n */\r\nfunction queryMatchesOrderBy(query, doc) {\r\n    for (const orderBy of query.explicitOrderBy) {\r\n        // order by key always matches\r\n        if (!orderBy.field.isKeyField() && doc.data.field(orderBy.field) === null) {\r\n            return false;\r\n        }\r\n    }\r\n    return true;\r\n}\r\nfunction queryMatchesFilters(query, doc) {\r\n    for (const filter of query.filters) {\r\n        if (!filter.matches(doc)) {\r\n            return false;\r\n        }\r\n    }\r\n    return true;\r\n}\r\n/** Makes sure a document is within the bounds, if provided. */\r\nfunction queryMatchesBounds(query, doc) {\r\n    if (query.startAt &&\r\n        !sortsBeforeDocument(query.startAt, queryOrderBy(query), doc)) {\r\n        return false;\r\n    }\r\n    if (query.endAt &&\r\n        sortsBeforeDocument(query.endAt, queryOrderBy(query), doc)) {\r\n        return false;\r\n    }\r\n    return true;\r\n}\r\n/**\r\n * Returns a new comparator function that can be used to compare two documents\r\n * based on the Query's ordering constraint.\r\n */\r\nfunction newQueryComparator(query) {\r\n    return (d1, d2) => {\r\n        let comparedOnKeyField = false;\r\n        for (const orderBy of queryOrderBy(query)) {\r\n            const comp = compareDocs(orderBy, d1, d2);\r\n            if (comp !== 0) {\r\n                return comp;\r\n            }\r\n            comparedOnKeyField = comparedOnKeyField || orderBy.field.isKeyField();\r\n        }\r\n        return 0;\r\n    };\r\n}\r\nfunction compareDocs(orderBy, d1, d2) {\r\n    const comparison = orderBy.field.isKeyField()\r\n        ? DocumentKey.comparator(d1.key, d2.key)\r\n        : compareDocumentsByField(orderBy.field, d1, d2);\r\n    switch (orderBy.dir) {\r\n        case \"asc\" /* ASCENDING */:\r\n            return comparison;\r\n        case \"desc\" /* DESCENDING */:\r\n            return -1 * comparison;\r\n        default:\r\n            return fail();\r\n    }\r\n}\n\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\n// An immutable sorted map implementation, based on a Left-leaning Red-Black\r\n// tree.\r\nclass SortedMap {\r\n    constructor(comparator, root) {\r\n        this.comparator = comparator;\r\n        this.root = root ? root : LLRBNode.EMPTY;\r\n    }\r\n    // Returns a copy of the map, with the specified key/value added or replaced.\r\n    insert(key, value) {\r\n        return new SortedMap(this.comparator, this.root\r\n            .insert(key, value, this.comparator)\r\n            .copy(null, null, LLRBNode.BLACK, null, null));\r\n    }\r\n    // Returns a copy of the map, with the specified key removed.\r\n    remove(key) {\r\n        return new SortedMap(this.comparator, this.root\r\n            .remove(key, this.comparator)\r\n            .copy(null, null, LLRBNode.BLACK, null, null));\r\n    }\r\n    // Returns the value of the node with the given key, or null.\r\n    get(key) {\r\n        let node = this.root;\r\n        while (!node.isEmpty()) {\r\n            const cmp = this.comparator(key, node.key);\r\n            if (cmp === 0) {\r\n                return node.value;\r\n            }\r\n            else if (cmp < 0) {\r\n                node = node.left;\r\n            }\r\n            else if (cmp > 0) {\r\n                node = node.right;\r\n            }\r\n        }\r\n        return null;\r\n    }\r\n    // Returns the index of the element in this sorted map, or -1 if it doesn't\r\n    // exist.\r\n    indexOf(key) {\r\n        // Number of nodes that were pruned when descending right\r\n        let prunedNodes = 0;\r\n        let node = this.root;\r\n        while (!node.isEmpty()) {\r\n            const cmp = this.comparator(key, node.key);\r\n            if (cmp === 0) {\r\n                return prunedNodes + node.left.size;\r\n            }\r\n            else if (cmp < 0) {\r\n                node = node.left;\r\n            }\r\n            else {\r\n                // Count all nodes left of the node plus the node itself\r\n                prunedNodes += node.left.size + 1;\r\n                node = node.right;\r\n            }\r\n        }\r\n        // Node not found\r\n        return -1;\r\n    }\r\n    isEmpty() {\r\n        return this.root.isEmpty();\r\n    }\r\n    // Returns the total number of nodes in the map.\r\n    get size() {\r\n        return this.root.size;\r\n    }\r\n    // Returns the minimum key in the map.\r\n    minKey() {\r\n        return this.root.minKey();\r\n    }\r\n    // Returns the maximum key in the map.\r\n    maxKey() {\r\n        return this.root.maxKey();\r\n    }\r\n    // Traverses the map in key order and calls the specified action function\r\n    // for each key/value pair. If action returns true, traversal is aborted.\r\n    // Returns the first truthy value returned by action, or the last falsey\r\n    // value returned by action.\r\n    inorderTraversal(action) {\r\n        return this.root.inorderTraversal(action);\r\n    }\r\n    forEach(fn) {\r\n        this.inorderTraversal((k, v) => {\r\n            fn(k, v);\r\n            return false;\r\n        });\r\n    }\r\n    toString() {\r\n        const descriptions = [];\r\n        this.inorderTraversal((k, v) => {\r\n            descriptions.push(`${k}:${v}`);\r\n            return false;\r\n        });\r\n        return `{${descriptions.join(', ')}}`;\r\n    }\r\n    // Traverses the map in reverse key order and calls the specified action\r\n    // function for each key/value pair. If action returns true, traversal is\r\n    // aborted.\r\n    // Returns the first truthy value returned by action, or the last falsey\r\n    // value returned by action.\r\n    reverseTraversal(action) {\r\n        return this.root.reverseTraversal(action);\r\n    }\r\n    // Returns an iterator over the SortedMap.\r\n    getIterator() {\r\n        return new SortedMapIterator(this.root, null, this.comparator, false);\r\n    }\r\n    getIteratorFrom(key) {\r\n        return new SortedMapIterator(this.root, key, this.comparator, false);\r\n    }\r\n    getReverseIterator() {\r\n        return new SortedMapIterator(this.root, null, this.comparator, true);\r\n    }\r\n    getReverseIteratorFrom(key) {\r\n        return new SortedMapIterator(this.root, key, this.comparator, true);\r\n    }\r\n} // end SortedMap\r\n// An iterator over an LLRBNode.\r\nclass SortedMapIterator {\r\n    constructor(node, startKey, comparator, isReverse) {\r\n        this.isReverse = isReverse;\r\n        this.nodeStack = [];\r\n        let cmp = 1;\r\n        while (!node.isEmpty()) {\r\n            cmp = startKey ? comparator(node.key, startKey) : 1;\r\n            // flip the comparison if we're going in reverse\r\n            if (isReverse) {\r\n                cmp *= -1;\r\n            }\r\n            if (cmp < 0) {\r\n                // This node is less than our start key. ignore it\r\n                if (this.isReverse) {\r\n                    node = node.left;\r\n                }\r\n                else {\r\n                    node = node.right;\r\n                }\r\n            }\r\n            else if (cmp === 0) {\r\n                // This node is exactly equal to our start key. Push it on the stack,\r\n                // but stop iterating;\r\n                this.nodeStack.push(node);\r\n                break;\r\n            }\r\n            else {\r\n                // This node is greater than our start key, add it to the stack and move\r\n                // to the next one\r\n                this.nodeStack.push(node);\r\n                if (this.isReverse) {\r\n                    node = node.right;\r\n                }\r\n                else {\r\n                    node = node.left;\r\n                }\r\n            }\r\n        }\r\n    }\r\n    getNext() {\r\n        let node = this.nodeStack.pop();\r\n        const result = { key: node.key, value: node.value };\r\n        if (this.isReverse) {\r\n            node = node.left;\r\n            while (!node.isEmpty()) {\r\n                this.nodeStack.push(node);\r\n                node = node.right;\r\n            }\r\n        }\r\n        else {\r\n            node = node.right;\r\n            while (!node.isEmpty()) {\r\n                this.nodeStack.push(node);\r\n                node = node.left;\r\n            }\r\n        }\r\n        return result;\r\n    }\r\n    hasNext() {\r\n        return this.nodeStack.length > 0;\r\n    }\r\n    peek() {\r\n        if (this.nodeStack.length === 0) {\r\n            return null;\r\n        }\r\n        const node = this.nodeStack[this.nodeStack.length - 1];\r\n        return { key: node.key, value: node.value };\r\n    }\r\n} // end SortedMapIterator\r\n// Represents a node in a Left-leaning Red-Black tree.\r\nclass LLRBNode {\r\n    constructor(key, value, color, left, right) {\r\n        this.key = key;\r\n        this.value = value;\r\n        this.color = color != null ? color : LLRBNode.RED;\r\n        this.left = left != null ? left : LLRBNode.EMPTY;\r\n        this.right = right != null ? right : LLRBNode.EMPTY;\r\n        this.size = this.left.size + 1 + this.right.size;\r\n    }\r\n    // Returns a copy of the current node, optionally replacing pieces of it.\r\n    copy(key, value, color, left, right) {\r\n        return new LLRBNode(key != null ? key : this.key, value != null ? value : this.value, color != null ? color : this.color, left != null ? left : this.left, right != null ? right : this.right);\r\n    }\r\n    isEmpty() {\r\n        return false;\r\n    }\r\n    // Traverses the tree in key order and calls the specified action function\r\n    // for each node. If action returns true, traversal is aborted.\r\n    // Returns the first truthy value returned by action, or the last falsey\r\n    // value returned by action.\r\n    inorderTraversal(action) {\r\n        return (this.left.inorderTraversal(action) ||\r\n            action(this.key, this.value) ||\r\n            this.right.inorderTraversal(action));\r\n    }\r\n    // Traverses the tree in reverse key order and calls the specified action\r\n    // function for each node. If action returns true, traversal is aborted.\r\n    // Returns the first truthy value returned by action, or the last falsey\r\n    // value returned by action.\r\n    reverseTraversal(action) {\r\n        return (this.right.reverseTraversal(action) ||\r\n            action(this.key, this.value) ||\r\n            this.left.reverseTraversal(action));\r\n    }\r\n    // Returns the minimum node in the tree.\r\n    min() {\r\n        if (this.left.isEmpty()) {\r\n            return this;\r\n        }\r\n        else {\r\n            return this.left.min();\r\n        }\r\n    }\r\n    // Returns the maximum key in the tree.\r\n    minKey() {\r\n        return this.min().key;\r\n    }\r\n    // Returns the maximum key in the tree.\r\n    maxKey() {\r\n        if (this.right.isEmpty()) {\r\n            return this.key;\r\n        }\r\n        else {\r\n            return this.right.maxKey();\r\n        }\r\n    }\r\n    // Returns new tree, with the key/value added.\r\n    insert(key, value, comparator) {\r\n        let n = this;\r\n        const cmp = comparator(key, n.key);\r\n        if (cmp < 0) {\r\n            n = n.copy(null, null, null, n.left.insert(key, value, comparator), null);\r\n        }\r\n        else if (cmp === 0) {\r\n            n = n.copy(null, value, null, null, null);\r\n        }\r\n        else {\r\n            n = n.copy(null, null, null, null, n.right.insert(key, value, comparator));\r\n        }\r\n        return n.fixUp();\r\n    }\r\n    removeMin() {\r\n        if (this.left.isEmpty()) {\r\n            return LLRBNode.EMPTY;\r\n        }\r\n        let n = this;\r\n        if (!n.left.isRed() && !n.left.left.isRed()) {\r\n            n = n.moveRedLeft();\r\n        }\r\n        n = n.copy(null, null, null, n.left.removeMin(), null);\r\n        return n.fixUp();\r\n    }\r\n    // Returns new tree, with the specified item removed.\r\n    remove(key, comparator) {\r\n        let smallest;\r\n        let n = this;\r\n        if (comparator(key, n.key) < 0) {\r\n            if (!n.left.isEmpty() && !n.left.isRed() && !n.left.left.isRed()) {\r\n                n = n.moveRedLeft();\r\n            }\r\n            n = n.copy(null, null, null, n.left.remove(key, comparator), null);\r\n        }\r\n        else {\r\n            if (n.left.isRed()) {\r\n                n = n.rotateRight();\r\n            }\r\n            if (!n.right.isEmpty() && !n.right.isRed() && !n.right.left.isRed()) {\r\n                n = n.moveRedRight();\r\n            }\r\n            if (comparator(key, n.key) === 0) {\r\n                if (n.right.isEmpty()) {\r\n                    return LLRBNode.EMPTY;\r\n                }\r\n                else {\r\n                    smallest = n.right.min();\r\n                    n = n.copy(smallest.key, smallest.value, null, null, n.right.removeMin());\r\n                }\r\n            }\r\n            n = n.copy(null, null, null, null, n.right.remove(key, comparator));\r\n        }\r\n        return n.fixUp();\r\n    }\r\n    isRed() {\r\n        return this.color;\r\n    }\r\n    // Returns new tree after performing any needed rotations.\r\n    fixUp() {\r\n        let n = this;\r\n        if (n.right.isRed() && !n.left.isRed()) {\r\n            n = n.rotateLeft();\r\n        }\r\n        if (n.left.isRed() && n.left.left.isRed()) {\r\n            n = n.rotateRight();\r\n        }\r\n        if (n.left.isRed() && n.right.isRed()) {\r\n            n = n.colorFlip();\r\n        }\r\n        return n;\r\n    }\r\n    moveRedLeft() {\r\n        let n = this.colorFlip();\r\n        if (n.right.left.isRed()) {\r\n            n = n.copy(null, null, null, null, n.right.rotateRight());\r\n            n = n.rotateLeft();\r\n            n = n.colorFlip();\r\n        }\r\n        return n;\r\n    }\r\n    moveRedRight() {\r\n        let n = this.colorFlip();\r\n        if (n.left.left.isRed()) {\r\n            n = n.rotateRight();\r\n            n = n.colorFlip();\r\n        }\r\n        return n;\r\n    }\r\n    rotateLeft() {\r\n        const nl = this.copy(null, null, LLRBNode.RED, null, this.right.left);\r\n        return this.right.copy(null, null, this.color, nl, null);\r\n    }\r\n    rotateRight() {\r\n        const nr = this.copy(null, null, LLRBNode.RED, this.left.right, null);\r\n        return this.left.copy(null, null, this.color, null, nr);\r\n    }\r\n    colorFlip() {\r\n        const left = this.left.copy(null, null, !this.left.color, null, null);\r\n        const right = this.right.copy(null, null, !this.right.color, null, null);\r\n        return this.copy(null, null, !this.color, left, right);\r\n    }\r\n    // For testing.\r\n    checkMaxDepth() {\r\n        const blackDepth = this.check();\r\n        if (Math.pow(2.0, blackDepth) <= this.size + 1) {\r\n            return true;\r\n        }\r\n        else {\r\n            return false;\r\n        }\r\n    }\r\n    // In a balanced RB tree, the black-depth (number of black nodes) from root to\r\n    // leaves is equal on both sides.  This function verifies that or asserts.\r\n    check() {\r\n        if (this.isRed() && this.left.isRed()) {\r\n            throw fail();\r\n        }\r\n        if (this.right.isRed()) {\r\n            throw fail();\r\n        }\r\n        const blackDepth = this.left.check();\r\n        if (blackDepth !== this.right.check()) {\r\n            throw fail();\r\n        }\r\n        else {\r\n            return blackDepth + (this.isRed() ? 0 : 1);\r\n        }\r\n    }\r\n} // end LLRBNode\r\n// Empty node is shared between all LLRB trees.\r\n// eslint-disable-next-line @typescript-eslint/no-explicit-any\r\nLLRBNode.EMPTY = null;\r\nLLRBNode.RED = true;\r\nLLRBNode.BLACK = false;\r\n// Represents an empty node (a leaf node in the Red-Black Tree).\r\nclass LLRBEmptyNode {\r\n    constructor() {\r\n        this.size = 0;\r\n    }\r\n    get key() {\r\n        throw fail();\r\n    }\r\n    get value() {\r\n        throw fail();\r\n    }\r\n    get color() {\r\n        throw fail();\r\n    }\r\n    get left() {\r\n        throw fail();\r\n    }\r\n    get right() {\r\n        throw fail();\r\n    }\r\n    // Returns a copy of the current node.\r\n    copy(key, value, color, left, right) {\r\n        return this;\r\n    }\r\n    // Returns a copy of the tree, with the specified key/value added.\r\n    insert(key, value, comparator) {\r\n        return new LLRBNode(key, value);\r\n    }\r\n    // Returns a copy of the tree, with the specified key removed.\r\n    remove(key, comparator) {\r\n        return this;\r\n    }\r\n    isEmpty() {\r\n        return true;\r\n    }\r\n    inorderTraversal(action) {\r\n        return false;\r\n    }\r\n    reverseTraversal(action) {\r\n        return false;\r\n    }\r\n    minKey() {\r\n        return null;\r\n    }\r\n    maxKey() {\r\n        return null;\r\n    }\r\n    isRed() {\r\n        return false;\r\n    }\r\n    // For testing.\r\n    checkMaxDepth() {\r\n        return true;\r\n    }\r\n    check() {\r\n        return 0;\r\n    }\r\n} // end LLRBEmptyNode\r\nLLRBNode.EMPTY = new LLRBEmptyNode();\n\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\n/**\r\n * SortedSet is an immutable (copy-on-write) collection that holds elements\r\n * in order specified by the provided comparator.\r\n *\r\n * NOTE: if provided comparator returns 0 for two elements, we consider them to\r\n * be equal!\r\n */\r\nclass SortedSet {\r\n    constructor(comparator) {\r\n        this.comparator = comparator;\r\n        this.data = new SortedMap(this.comparator);\r\n    }\r\n    has(elem) {\r\n        return this.data.get(elem) !== null;\r\n    }\r\n    first() {\r\n        return this.data.minKey();\r\n    }\r\n    last() {\r\n        return this.data.maxKey();\r\n    }\r\n    get size() {\r\n        return this.data.size;\r\n    }\r\n    indexOf(elem) {\r\n        return this.data.indexOf(elem);\r\n    }\r\n    /** Iterates elements in order defined by \"comparator\" */\r\n    forEach(cb) {\r\n        this.data.inorderTraversal((k, v) => {\r\n            cb(k);\r\n            return false;\r\n        });\r\n    }\r\n    /** Iterates over `elem`s such that: range[0] &lt;= elem &lt; range[1]. */\r\n    forEachInRange(range, cb) {\r\n        const iter = this.data.getIteratorFrom(range[0]);\r\n        while (iter.hasNext()) {\r\n            const elem = iter.getNext();\r\n            if (this.comparator(elem.key, range[1]) >= 0) {\r\n                return;\r\n            }\r\n            cb(elem.key);\r\n        }\r\n    }\r\n    /**\r\n     * Iterates over `elem`s such that: start &lt;= elem until false is returned.\r\n     */\r\n    forEachWhile(cb, start) {\r\n        let iter;\r\n        if (start !== undefined) {\r\n            iter = this.data.getIteratorFrom(start);\r\n        }\r\n        else {\r\n            iter = this.data.getIterator();\r\n        }\r\n        while (iter.hasNext()) {\r\n            const elem = iter.getNext();\r\n            const result = cb(elem.key);\r\n            if (!result) {\r\n                return;\r\n            }\r\n        }\r\n    }\r\n    /** Finds the least element greater than or equal to `elem`. */\r\n    firstAfterOrEqual(elem) {\r\n        const iter = this.data.getIteratorFrom(elem);\r\n        return iter.hasNext() ? iter.getNext().key : null;\r\n    }\r\n    getIterator() {\r\n        return new SortedSetIterator(this.data.getIterator());\r\n    }\r\n    getIteratorFrom(key) {\r\n        return new SortedSetIterator(this.data.getIteratorFrom(key));\r\n    }\r\n    /** Inserts or updates an element */\r\n    add(elem) {\r\n        return this.copy(this.data.remove(elem).insert(elem, true));\r\n    }\r\n    /** Deletes an element */\r\n    delete(elem) {\r\n        if (!this.has(elem)) {\r\n            return this;\r\n        }\r\n        return this.copy(this.data.remove(elem));\r\n    }\r\n    isEmpty() {\r\n        return this.data.isEmpty();\r\n    }\r\n    unionWith(other) {\r\n        let result = this;\r\n        // Make sure `result` always refers to the larger one of the two sets.\r\n        if (result.size < other.size) {\r\n            result = other;\r\n            other = this;\r\n        }\r\n        other.forEach(elem => {\r\n            result = result.add(elem);\r\n        });\r\n        return result;\r\n    }\r\n    isEqual(other) {\r\n        if (!(other instanceof SortedSet)) {\r\n            return false;\r\n        }\r\n        if (this.size !== other.size) {\r\n            return false;\r\n        }\r\n        const thisIt = this.data.getIterator();\r\n        const otherIt = other.data.getIterator();\r\n        while (thisIt.hasNext()) {\r\n            const thisElem = thisIt.getNext().key;\r\n            const otherElem = otherIt.getNext().key;\r\n            if (this.comparator(thisElem, otherElem) !== 0) {\r\n                return false;\r\n            }\r\n        }\r\n        return true;\r\n    }\r\n    toArray() {\r\n        const res = [];\r\n        this.forEach(targetId => {\r\n            res.push(targetId);\r\n        });\r\n        return res;\r\n    }\r\n    toString() {\r\n        const result = [];\r\n        this.forEach(elem => result.push(elem));\r\n        return 'SortedSet(' + result.toString() + ')';\r\n    }\r\n    copy(data) {\r\n        const result = new SortedSet(this.comparator);\r\n        result.data = data;\r\n        return result;\r\n    }\r\n}\r\nclass SortedSetIterator {\r\n    constructor(iter) {\r\n        this.iter = iter;\r\n    }\r\n    getNext() {\r\n        return this.iter.getNext().key;\r\n    }\r\n    hasNext() {\r\n        return this.iter.hasNext();\r\n    }\r\n}\n\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\nconst EMPTY_MUTABLE_DOCUMENT_MAP = new SortedMap(DocumentKey.comparator);\r\nfunction mutableDocumentMap() {\r\n    return EMPTY_MUTABLE_DOCUMENT_MAP;\r\n}\r\nconst EMPTY_DOCUMENT_MAP = new SortedMap(DocumentKey.comparator);\r\nfunction documentMap() {\r\n    return EMPTY_DOCUMENT_MAP;\r\n}\r\nconst EMPTY_DOCUMENT_VERSION_MAP = new SortedMap(DocumentKey.comparator);\r\nfunction documentVersionMap() {\r\n    return EMPTY_DOCUMENT_VERSION_MAP;\r\n}\r\nconst EMPTY_DOCUMENT_KEY_SET = new SortedSet(DocumentKey.comparator);\r\nfunction documentKeySet(...keys) {\r\n    let set = EMPTY_DOCUMENT_KEY_SET;\r\n    for (const key of keys) {\r\n        set = set.add(key);\r\n    }\r\n    return set;\r\n}\r\nconst EMPTY_TARGET_ID_SET = new SortedSet(primitiveComparator);\r\nfunction targetIdSet() {\r\n    return EMPTY_TARGET_ID_SET;\r\n}\n\n/**\r\n * @license\r\n * Copyright 2020 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\n/**\r\n * Returns an DoubleValue for `value` that is encoded based the serializer's\r\n * `useProto3Json` setting.\r\n */\r\nfunction toDouble(serializer, value) {\r\n    if (serializer.useProto3Json) {\r\n        if (isNaN(value)) {\r\n            return { doubleValue: 'NaN' };\r\n        }\r\n        else if (value === Infinity) {\r\n            return { doubleValue: 'Infinity' };\r\n        }\r\n        else if (value === -Infinity) {\r\n            return { doubleValue: '-Infinity' };\r\n        }\r\n    }\r\n    return { doubleValue: isNegativeZero(value) ? '-0' : value };\r\n}\r\n/**\r\n * Returns an IntegerValue for `value`.\r\n */\r\nfunction toInteger(value) {\r\n    return { integerValue: '' + value };\r\n}\r\n/**\r\n * Returns a value for a number that's appropriate to put into a proto.\r\n * The return value is an IntegerValue if it can safely represent the value,\r\n * otherwise a DoubleValue is returned.\r\n */\r\nfunction toNumber(serializer, value) {\r\n    return isSafeInteger(value) ? toInteger(value) : toDouble(serializer, value);\r\n}\n\n/**\r\n * @license\r\n * Copyright 2018 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\n/** Used to represent a field transform on a mutation. */\r\nclass TransformOperation {\r\n    constructor() {\r\n        // Make sure that the structural type of `TransformOperation` is unique.\r\n        // See https://github.com/microsoft/TypeScript/issues/5451\r\n        this._ = undefined;\r\n    }\r\n}\r\n/**\r\n * Computes the local transform result against the provided `previousValue`,\r\n * optionally using the provided localWriteTime.\r\n */\r\nfunction applyTransformOperationToLocalView(transform, previousValue, localWriteTime) {\r\n    if (transform instanceof ServerTimestampTransform) {\r\n        return serverTimestamp(localWriteTime, previousValue);\r\n    }\r\n    else if (transform instanceof ArrayUnionTransformOperation) {\r\n        return applyArrayUnionTransformOperation(transform, previousValue);\r\n    }\r\n    else if (transform instanceof ArrayRemoveTransformOperation) {\r\n        return applyArrayRemoveTransformOperation(transform, previousValue);\r\n    }\r\n    else {\r\n        return applyNumericIncrementTransformOperationToLocalView(transform, previousValue);\r\n    }\r\n}\r\n/**\r\n * Computes a final transform result after the transform has been acknowledged\r\n * by the server, potentially using the server-provided transformResult.\r\n */\r\nfunction applyTransformOperationToRemoteDocument(transform, previousValue, transformResult) {\r\n    // The server just sends null as the transform result for array operations,\r\n    // so we have to calculate a result the same as we do for local\r\n    // applications.\r\n    if (transform instanceof ArrayUnionTransformOperation) {\r\n        return applyArrayUnionTransformOperation(transform, previousValue);\r\n    }\r\n    else if (transform instanceof ArrayRemoveTransformOperation) {\r\n        return applyArrayRemoveTransformOperation(transform, previousValue);\r\n    }\r\n    return transformResult;\r\n}\r\n/**\r\n * If this transform operation is not idempotent, returns the base value to\r\n * persist for this transform. If a base value is returned, the transform\r\n * operation is always applied to this base value, even if document has\r\n * already been updated.\r\n *\r\n * Base values provide consistent behavior for non-idempotent transforms and\r\n * allow us to return the same latency-compensated value even if the backend\r\n * has already applied the transform operation. The base value is null for\r\n * idempotent transforms, as they can be re-played even if the backend has\r\n * already applied them.\r\n *\r\n * @returns a base value to store along with the mutation, or null for\r\n * idempotent transforms.\r\n */\r\nfunction computeTransformOperationBaseValue(transform, previousValue) {\r\n    if (transform instanceof NumericIncrementTransformOperation) {\r\n        return isNumber(previousValue) ? previousValue : { integerValue: 0 };\r\n    }\r\n    return null;\r\n}\r\nfunction transformOperationEquals(left, right) {\r\n    if (left instanceof ArrayUnionTransformOperation &&\r\n        right instanceof ArrayUnionTransformOperation) {\r\n        return arrayEquals(left.elements, right.elements, valueEquals);\r\n    }\r\n    else if (left instanceof ArrayRemoveTransformOperation &&\r\n        right instanceof ArrayRemoveTransformOperation) {\r\n        return arrayEquals(left.elements, right.elements, valueEquals);\r\n    }\r\n    else if (left instanceof NumericIncrementTransformOperation &&\r\n        right instanceof NumericIncrementTransformOperation) {\r\n        return valueEquals(left.operand, right.operand);\r\n    }\r\n    return (left instanceof ServerTimestampTransform &&\r\n        right instanceof ServerTimestampTransform);\r\n}\r\n/** Transforms a value into a server-generated timestamp. */\r\nclass ServerTimestampTransform extends TransformOperation {\r\n}\r\n/** Transforms an array value via a union operation. */\r\nclass ArrayUnionTransformOperation extends TransformOperation {\r\n    constructor(elements) {\r\n        super();\r\n        this.elements = elements;\r\n    }\r\n}\r\nfunction applyArrayUnionTransformOperation(transform, previousValue) {\r\n    const values = coercedFieldValuesArray(previousValue);\r\n    for (const toUnion of transform.elements) {\r\n        if (!values.some(element => valueEquals(element, toUnion))) {\r\n            values.push(toUnion);\r\n        }\r\n    }\r\n    return { arrayValue: { values } };\r\n}\r\n/** Transforms an array value via a remove operation. */\r\nclass ArrayRemoveTransformOperation extends TransformOperation {\r\n    constructor(elements) {\r\n        super();\r\n        this.elements = elements;\r\n    }\r\n}\r\nfunction applyArrayRemoveTransformOperation(transform, previousValue) {\r\n    let values = coercedFieldValuesArray(previousValue);\r\n    for (const toRemove of transform.elements) {\r\n        values = values.filter(element => !valueEquals(element, toRemove));\r\n    }\r\n    return { arrayValue: { values } };\r\n}\r\n/**\r\n * Implements the backend semantics for locally computed NUMERIC_ADD (increment)\r\n * transforms. Converts all field values to integers or doubles, but unlike the\r\n * backend does not cap integer values at 2^63. Instead, JavaScript number\r\n * arithmetic is used and precision loss can occur for values greater than 2^53.\r\n */\r\nclass NumericIncrementTransformOperation extends TransformOperation {\r\n    constructor(serializer, operand) {\r\n        super();\r\n        this.serializer = serializer;\r\n        this.operand = operand;\r\n    }\r\n}\r\nfunction applyNumericIncrementTransformOperationToLocalView(transform, previousValue) {\r\n    // PORTING NOTE: Since JavaScript's integer arithmetic is limited to 53 bit\r\n    // precision and resolves overflows by reducing precision, we do not\r\n    // manually cap overflows at 2^63.\r\n    const baseValue = computeTransformOperationBaseValue(transform, previousValue);\r\n    const sum = asNumber(baseValue) + asNumber(transform.operand);\r\n    if (isInteger(baseValue) && isInteger(transform.operand)) {\r\n        return toInteger(sum);\r\n    }\r\n    else {\r\n        return toDouble(transform.serializer, sum);\r\n    }\r\n}\r\nfunction asNumber(value) {\r\n    return normalizeNumber(value.integerValue || value.doubleValue);\r\n}\r\nfunction coercedFieldValuesArray(value) {\r\n    return isArray(value) && value.arrayValue.values\r\n        ? value.arrayValue.values.slice()\r\n        : [];\r\n}\n\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\n/** A field path and the TransformOperation to perform upon it. */\r\nclass FieldTransform {\r\n    constructor(field, transform) {\r\n        this.field = field;\r\n        this.transform = transform;\r\n    }\r\n}\r\nfunction fieldTransformEquals(left, right) {\r\n    return (left.field.isEqual(right.field) &&\r\n        transformOperationEquals(left.transform, right.transform));\r\n}\r\nfunction fieldTransformsAreEqual(left, right) {\r\n    if (left === undefined && right === undefined) {\r\n        return true;\r\n    }\r\n    if (left && right) {\r\n        return arrayEquals(left, right, (l, r) => fieldTransformEquals(l, r));\r\n    }\r\n    return false;\r\n}\r\n/** The result of successfully applying a mutation to the backend. */\r\nclass MutationResult {\r\n    constructor(\r\n    /**\r\n     * The version at which the mutation was committed:\r\n     *\r\n     * - For most operations, this is the updateTime in the WriteResult.\r\n     * - For deletes, the commitTime of the WriteResponse (because deletes are\r\n     *   not stored and have no updateTime).\r\n     *\r\n     * Note that these versions can be different: No-op writes will not change\r\n     * the updateTime even though the commitTime advances.\r\n     */\r\n    version, \r\n    /**\r\n     * The resulting fields returned from the backend after a mutation\r\n     * containing field transforms has been committed. Contains one FieldValue\r\n     * for each FieldTransform that was in the mutation.\r\n     *\r\n     * Will be empty if the mutation did not contain any field transforms.\r\n     */\r\n    transformResults) {\r\n        this.version = version;\r\n        this.transformResults = transformResults;\r\n    }\r\n}\r\n/**\r\n * Encodes a precondition for a mutation. This follows the model that the\r\n * backend accepts with the special case of an explicit \"empty\" precondition\r\n * (meaning no precondition).\r\n */\r\nclass Precondition {\r\n    constructor(updateTime, exists) {\r\n        this.updateTime = updateTime;\r\n        this.exists = exists;\r\n    }\r\n    /** Creates a new empty Precondition. */\r\n    static none() {\r\n        return new Precondition();\r\n    }\r\n    /** Creates a new Precondition with an exists flag. */\r\n    static exists(exists) {\r\n        return new Precondition(undefined, exists);\r\n    }\r\n    /** Creates a new Precondition based on a version a document exists at. */\r\n    static updateTime(version) {\r\n        return new Precondition(version);\r\n    }\r\n    /** Returns whether this Precondition is empty. */\r\n    get isNone() {\r\n        return this.updateTime === undefined && this.exists === undefined;\r\n    }\r\n    isEqual(other) {\r\n        return (this.exists === other.exists &&\r\n            (this.updateTime\r\n                ? !!other.updateTime && this.updateTime.isEqual(other.updateTime)\r\n                : !other.updateTime));\r\n    }\r\n}\r\n/** Returns true if the preconditions is valid for the given document. */\r\nfunction preconditionIsValidForDocument(precondition, document) {\r\n    if (precondition.updateTime !== undefined) {\r\n        return (document.isFoundDocument() &&\r\n            document.version.isEqual(precondition.updateTime));\r\n    }\r\n    else if (precondition.exists !== undefined) {\r\n        return precondition.exists === document.isFoundDocument();\r\n    }\r\n    else {\r\n        return true;\r\n    }\r\n}\r\n/**\r\n * A mutation describes a self-contained change to a document. Mutations can\r\n * create, replace, delete, and update subsets of documents.\r\n *\r\n * Mutations not only act on the value of the document but also its version.\r\n *\r\n * For local mutations (mutations that haven't been committed yet), we preserve\r\n * the existing version for Set and Patch mutations. For Delete mutations, we\r\n * reset the version to 0.\r\n *\r\n * Here's the expected transition table.\r\n *\r\n * MUTATION           APPLIED TO            RESULTS IN\r\n *\r\n * SetMutation        Document(v3)          Document(v3)\r\n * SetMutation        NoDocument(v3)        Document(v0)\r\n * SetMutation        InvalidDocument(v0)   Document(v0)\r\n * PatchMutation      Document(v3)          Document(v3)\r\n * PatchMutation      NoDocument(v3)        NoDocument(v3)\r\n * PatchMutation      InvalidDocument(v0)   UnknownDocument(v3)\r\n * DeleteMutation     Document(v3)          NoDocument(v0)\r\n * DeleteMutation     NoDocument(v3)        NoDocument(v0)\r\n * DeleteMutation     InvalidDocument(v0)   NoDocument(v0)\r\n *\r\n * For acknowledged mutations, we use the updateTime of the WriteResponse as\r\n * the resulting version for Set and Patch mutations. As deletes have no\r\n * explicit update time, we use the commitTime of the WriteResponse for\r\n * Delete mutations.\r\n *\r\n * If a mutation is acknowledged by the backend but fails the precondition check\r\n * locally, we transition to an `UnknownDocument` and rely on Watch to send us\r\n * the updated version.\r\n *\r\n * Field transforms are used only with Patch and Set Mutations. We use the\r\n * `updateTransforms` message to store transforms, rather than the `transforms`s\r\n * messages.\r\n *\r\n * ## Subclassing Notes\r\n *\r\n * Every type of mutation needs to implement its own applyToRemoteDocument() and\r\n * applyToLocalView() to implement the actual behavior of applying the mutation\r\n * to some source document (see `applySetMutationToRemoteDocument()` for an\r\n * example).\r\n */\r\nclass Mutation {\r\n}\r\n/**\r\n * Applies this mutation to the given document for the purposes of computing a\r\n * new remote document. If the input document doesn't match the expected state\r\n * (e.g. it is invalid or outdated), the document type may transition to\r\n * unknown.\r\n *\r\n * @param mutation - The mutation to apply.\r\n * @param document - The document to mutate. The input document can be an\r\n *     invalid document if the client has no knowledge of the pre-mutation state\r\n *     of the document.\r\n * @param mutationResult - The result of applying the mutation from the backend.\r\n */\r\nfunction applyMutationToRemoteDocument(mutation, document, mutationResult) {\r\n    if (mutation instanceof SetMutation) {\r\n        applySetMutationToRemoteDocument(mutation, document, mutationResult);\r\n    }\r\n    else if (mutation instanceof PatchMutation) {\r\n        applyPatchMutationToRemoteDocument(mutation, document, mutationResult);\r\n    }\r\n    else {\r\n        applyDeleteMutationToRemoteDocument(mutation, document, mutationResult);\r\n    }\r\n}\r\n/**\r\n * Applies this mutation to the given document for the purposes of computing\r\n * the new local view of a document. If the input document doesn't match the\r\n * expected state, the document is not modified.\r\n *\r\n * @param mutation - The mutation to apply.\r\n * @param document - The document to mutate. The input document can be an\r\n *     invalid document if the client has no knowledge of the pre-mutation state\r\n *     of the document.\r\n * @param localWriteTime - A timestamp indicating the local write time of the\r\n *     batch this mutation is a part of.\r\n */\r\nfunction applyMutationToLocalView(mutation, document, localWriteTime) {\r\n    if (mutation instanceof SetMutation) {\r\n        applySetMutationToLocalView(mutation, document, localWriteTime);\r\n    }\r\n    else if (mutation instanceof PatchMutation) {\r\n        applyPatchMutationToLocalView(mutation, document, localWriteTime);\r\n    }\r\n    else {\r\n        applyDeleteMutationToLocalView(mutation, document);\r\n    }\r\n}\r\n/**\r\n * If this mutation is not idempotent, returns the base value to persist with\r\n * this mutation. If a base value is returned, the mutation is always applied\r\n * to this base value, even if document has already been updated.\r\n *\r\n * The base value is a sparse object that consists of only the document\r\n * fields for which this mutation contains a non-idempotent transformation\r\n * (e.g. a numeric increment). The provided value guarantees consistent\r\n * behavior for non-idempotent transforms and allow us to return the same\r\n * latency-compensated value even if the backend has already applied the\r\n * mutation. The base value is null for idempotent mutations, as they can be\r\n * re-played even if the backend has already applied them.\r\n *\r\n * @returns a base value to store along with the mutation, or null for\r\n * idempotent mutations.\r\n */\r\nfunction extractMutationBaseValue(mutation, document) {\r\n    let baseObject = null;\r\n    for (const fieldTransform of mutation.fieldTransforms) {\r\n        const existingValue = document.data.field(fieldTransform.field);\r\n        const coercedValue = computeTransformOperationBaseValue(fieldTransform.transform, existingValue || null);\r\n        if (coercedValue != null) {\r\n            if (baseObject == null) {\r\n                baseObject = ObjectValue.empty();\r\n            }\r\n            baseObject.set(fieldTransform.field, coercedValue);\r\n        }\r\n    }\r\n    return baseObject ? baseObject : null;\r\n}\r\nfunction mutationEquals(left, right) {\r\n    if (left.type !== right.type) {\r\n        return false;\r\n    }\r\n    if (!left.key.isEqual(right.key)) {\r\n        return false;\r\n    }\r\n    if (!left.precondition.isEqual(right.precondition)) {\r\n        return false;\r\n    }\r\n    if (!fieldTransformsAreEqual(left.fieldTransforms, right.fieldTransforms)) {\r\n        return false;\r\n    }\r\n    if (left.type === 0 /* Set */) {\r\n        return left.value.isEqual(right.value);\r\n    }\r\n    if (left.type === 1 /* Patch */) {\r\n        return (left.data.isEqual(right.data) &&\r\n            left.fieldMask.isEqual(right.fieldMask));\r\n    }\r\n    return true;\r\n}\r\n/**\r\n * Returns the version from the given document for use as the result of a\r\n * mutation. Mutations are defined to return the version of the base document\r\n * only if it is an existing document. Deleted and unknown documents have a\r\n * post-mutation version of SnapshotVersion.min().\r\n */\r\nfunction getPostMutationVersion(document) {\r\n    return document.isFoundDocument() ? document.version : SnapshotVersion.min();\r\n}\r\n/**\r\n * A mutation that creates or replaces the document at the given key with the\r\n * object value contents.\r\n */\r\nclass SetMutation extends Mutation {\r\n    constructor(key, value, precondition, fieldTransforms = []) {\r\n        super();\r\n        this.key = key;\r\n        this.value = value;\r\n        this.precondition = precondition;\r\n        this.fieldTransforms = fieldTransforms;\r\n        this.type = 0 /* Set */;\r\n    }\r\n}\r\nfunction applySetMutationToRemoteDocument(mutation, document, mutationResult) {\r\n    // Unlike applySetMutationToLocalView, if we're applying a mutation to a\r\n    // remote document the server has accepted the mutation so the precondition\r\n    // must have held.\r\n    const newData = mutation.value.clone();\r\n    const transformResults = serverTransformResults(mutation.fieldTransforms, document, mutationResult.transformResults);\r\n    newData.setAll(transformResults);\r\n    document\r\n        .convertToFoundDocument(mutationResult.version, newData)\r\n        .setHasCommittedMutations();\r\n}\r\nfunction applySetMutationToLocalView(mutation, document, localWriteTime) {\r\n    if (!preconditionIsValidForDocument(mutation.precondition, document)) {\r\n        // The mutation failed to apply (e.g. a document ID created with add()\r\n        // caused a name collision).\r\n        return;\r\n    }\r\n    const newData = mutation.value.clone();\r\n    const transformResults = localTransformResults(mutation.fieldTransforms, localWriteTime, document);\r\n    newData.setAll(transformResults);\r\n    document\r\n        .convertToFoundDocument(getPostMutationVersion(document), newData)\r\n        .setHasLocalMutations();\r\n}\r\n/**\r\n * A mutation that modifies fields of the document at the given key with the\r\n * given values. The values are applied through a field mask:\r\n *\r\n *  * When a field is in both the mask and the values, the corresponding field\r\n *    is updated.\r\n *  * When a field is in neither the mask nor the values, the corresponding\r\n *    field is unmodified.\r\n *  * When a field is in the mask but not in the values, the corresponding field\r\n *    is deleted.\r\n *  * When a field is not in the mask but is in the values, the values map is\r\n *    ignored.\r\n */\r\nclass PatchMutation extends Mutation {\r\n    constructor(key, data, fieldMask, precondition, fieldTransforms = []) {\r\n        super();\r\n        this.key = key;\r\n        this.data = data;\r\n        this.fieldMask = fieldMask;\r\n        this.precondition = precondition;\r\n        this.fieldTransforms = fieldTransforms;\r\n        this.type = 1 /* Patch */;\r\n    }\r\n}\r\nfunction applyPatchMutationToRemoteDocument(mutation, document, mutationResult) {\r\n    if (!preconditionIsValidForDocument(mutation.precondition, document)) {\r\n        // Since the mutation was not rejected, we know that the precondition\r\n        // matched on the backend. We therefore must not have the expected version\r\n        // of the document in our cache and convert to an UnknownDocument with a\r\n        // known updateTime.\r\n        document.convertToUnknownDocument(mutationResult.version);\r\n        return;\r\n    }\r\n    const transformResults = serverTransformResults(mutation.fieldTransforms, document, mutationResult.transformResults);\r\n    const newData = document.data;\r\n    newData.setAll(getPatch(mutation));\r\n    newData.setAll(transformResults);\r\n    document\r\n        .convertToFoundDocument(mutationResult.version, newData)\r\n        .setHasCommittedMutations();\r\n}\r\nfunction applyPatchMutationToLocalView(mutation, document, localWriteTime) {\r\n    if (!preconditionIsValidForDocument(mutation.precondition, document)) {\r\n        return;\r\n    }\r\n    const transformResults = localTransformResults(mutation.fieldTransforms, localWriteTime, document);\r\n    const newData = document.data;\r\n    newData.setAll(getPatch(mutation));\r\n    newData.setAll(transformResults);\r\n    document\r\n        .convertToFoundDocument(getPostMutationVersion(document), newData)\r\n        .setHasLocalMutations();\r\n}\r\n/**\r\n * Returns a FieldPath/Value map with the content of the PatchMutation.\r\n */\r\nfunction getPatch(mutation) {\r\n    const result = new Map();\r\n    mutation.fieldMask.fields.forEach(fieldPath => {\r\n        if (!fieldPath.isEmpty()) {\r\n            const newValue = mutation.data.field(fieldPath);\r\n            result.set(fieldPath, newValue);\r\n        }\r\n    });\r\n    return result;\r\n}\r\n/**\r\n * Creates a list of \"transform results\" (a transform result is a field value\r\n * representing the result of applying a transform) for use after a mutation\r\n * containing transforms has been acknowledged by the server.\r\n *\r\n * @param fieldTransforms - The field transforms to apply the result to.\r\n * @param mutableDocument - The current state of the document after applying all\r\n * previous mutations.\r\n * @param serverTransformResults - The transform results received by the server.\r\n * @returns The transform results list.\r\n */\r\nfunction serverTransformResults(fieldTransforms, mutableDocument, serverTransformResults) {\r\n    const transformResults = new Map();\r\n    hardAssert(fieldTransforms.length === serverTransformResults.length);\r\n    for (let i = 0; i < serverTransformResults.length; i++) {\r\n        const fieldTransform = fieldTransforms[i];\r\n        const transform = fieldTransform.transform;\r\n        const previousValue = mutableDocument.data.field(fieldTransform.field);\r\n        transformResults.set(fieldTransform.field, applyTransformOperationToRemoteDocument(transform, previousValue, serverTransformResults[i]));\r\n    }\r\n    return transformResults;\r\n}\r\n/**\r\n * Creates a list of \"transform results\" (a transform result is a field value\r\n * representing the result of applying a transform) for use when applying a\r\n * transform locally.\r\n *\r\n * @param fieldTransforms - The field transforms to apply the result to.\r\n * @param localWriteTime - The local time of the mutation (used to\r\n *     generate ServerTimestampValues).\r\n * @param mutableDocument - The current state of the document after applying all\r\n *     previous mutations.\r\n * @returns The transform results list.\r\n */\r\nfunction localTransformResults(fieldTransforms, localWriteTime, mutableDocument) {\r\n    const transformResults = new Map();\r\n    for (const fieldTransform of fieldTransforms) {\r\n        const transform = fieldTransform.transform;\r\n        const previousValue = mutableDocument.data.field(fieldTransform.field);\r\n        transformResults.set(fieldTransform.field, applyTransformOperationToLocalView(transform, previousValue, localWriteTime));\r\n    }\r\n    return transformResults;\r\n}\r\n/** A mutation that deletes the document at the given key. */\r\nclass DeleteMutation extends Mutation {\r\n    constructor(key, precondition) {\r\n        super();\r\n        this.key = key;\r\n        this.precondition = precondition;\r\n        this.type = 2 /* Delete */;\r\n        this.fieldTransforms = [];\r\n    }\r\n}\r\nfunction applyDeleteMutationToRemoteDocument(mutation, document, mutationResult) {\r\n    // Unlike applyToLocalView, if we're applying a mutation to a remote\r\n    // document the server has accepted the mutation so the precondition must\r\n    // have held.\r\n    document\r\n        .convertToNoDocument(mutationResult.version)\r\n        .setHasCommittedMutations();\r\n}\r\nfunction applyDeleteMutationToLocalView(mutation, document) {\r\n    if (preconditionIsValidForDocument(mutation.precondition, document)) {\r\n        // We don't call `setHasLocalMutations()` since we want to be backwards\r\n        // compatible with the existing SDK behavior.\r\n        document.convertToNoDocument(SnapshotVersion.min());\r\n    }\r\n}\r\n/**\r\n * A mutation that verifies the existence of the document at the given key with\r\n * the provided precondition.\r\n *\r\n * The `verify` operation is only used in Transactions, and this class serves\r\n * primarily to facilitate serialization into protos.\r\n */\r\nclass VerifyMutation extends Mutation {\r\n    constructor(key, precondition) {\r\n        super();\r\n        this.key = key;\r\n        this.precondition = precondition;\r\n        this.type = 3 /* Verify */;\r\n        this.fieldTransforms = [];\r\n    }\r\n}\n\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\n/**\r\n * A batch of mutations that will be sent as one unit to the backend.\r\n */\r\nclass MutationBatch {\r\n    /**\r\n     * @param batchId - The unique ID of this mutation batch.\r\n     * @param localWriteTime - The original write time of this mutation.\r\n     * @param baseMutations - Mutations that are used to populate the base\r\n     * values when this mutation is applied locally. This can be used to locally\r\n     * overwrite values that are persisted in the remote document cache. Base\r\n     * mutations are never sent to the backend.\r\n     * @param mutations - The user-provided mutations in this mutation batch.\r\n     * User-provided mutations are applied both locally and remotely on the\r\n     * backend.\r\n     */\r\n    constructor(batchId, localWriteTime, baseMutations, mutations) {\r\n        this.batchId = batchId;\r\n        this.localWriteTime = localWriteTime;\r\n        this.baseMutations = baseMutations;\r\n        this.mutations = mutations;\r\n    }\r\n    /**\r\n     * Applies all the mutations in this MutationBatch to the specified document\r\n     * to compute the state of the remote document\r\n     *\r\n     * @param document - The document to apply mutations to.\r\n     * @param batchResult - The result of applying the MutationBatch to the\r\n     * backend.\r\n     */\r\n    applyToRemoteDocument(document, batchResult) {\r\n        const mutationResults = batchResult.mutationResults;\r\n        for (let i = 0; i < this.mutations.length; i++) {\r\n            const mutation = this.mutations[i];\r\n            if (mutation.key.isEqual(document.key)) {\r\n                const mutationResult = mutationResults[i];\r\n                applyMutationToRemoteDocument(mutation, document, mutationResult);\r\n            }\r\n        }\r\n    }\r\n    /**\r\n     * Computes the local view of a document given all the mutations in this\r\n     * batch.\r\n     *\r\n     * @param document - The document to apply mutations to.\r\n     */\r\n    applyToLocalView(document) {\r\n        // First, apply the base state. This allows us to apply non-idempotent\r\n        // transform against a consistent set of values.\r\n        for (const mutation of this.baseMutations) {\r\n            if (mutation.key.isEqual(document.key)) {\r\n                applyMutationToLocalView(mutation, document, this.localWriteTime);\r\n            }\r\n        }\r\n        // Second, apply all user-provided mutations.\r\n        for (const mutation of this.mutations) {\r\n            if (mutation.key.isEqual(document.key)) {\r\n                applyMutationToLocalView(mutation, document, this.localWriteTime);\r\n            }\r\n        }\r\n    }\r\n    /**\r\n     * Computes the local view for all provided documents given the mutations in\r\n     * this batch.\r\n     */\r\n    applyToLocalDocumentSet(documentMap) {\r\n        // TODO(mrschmidt): This implementation is O(n^2). If we apply the mutations\r\n        // directly (as done in `applyToLocalView()`), we can reduce the complexity\r\n        // to O(n).\r\n        this.mutations.forEach(m => {\r\n            const document = documentMap.get(m.key);\r\n            // TODO(mutabledocuments): This method should take a MutableDocumentMap\r\n            // and we should remove this cast.\r\n            const mutableDocument = document;\r\n            this.applyToLocalView(mutableDocument);\r\n            if (!document.isValidDocument()) {\r\n                mutableDocument.convertToNoDocument(SnapshotVersion.min());\r\n            }\r\n        });\r\n    }\r\n    keys() {\r\n        return this.mutations.reduce((keys, m) => keys.add(m.key), documentKeySet());\r\n    }\r\n    isEqual(other) {\r\n        return (this.batchId === other.batchId &&\r\n            arrayEquals(this.mutations, other.mutations, (l, r) => mutationEquals(l, r)) &&\r\n            arrayEquals(this.baseMutations, other.baseMutations, (l, r) => mutationEquals(l, r)));\r\n    }\r\n}\r\n/** The result of applying a mutation batch to the backend. */\r\nclass MutationBatchResult {\r\n    constructor(batch, commitVersion, mutationResults, \r\n    /**\r\n     * A pre-computed mapping from each mutated document to the resulting\r\n     * version.\r\n     */\r\n    docVersions) {\r\n        this.batch = batch;\r\n        this.commitVersion = commitVersion;\r\n        this.mutationResults = mutationResults;\r\n        this.docVersions = docVersions;\r\n    }\r\n    /**\r\n     * Creates a new MutationBatchResult for the given batch and results. There\r\n     * must be one result for each mutation in the batch. This static factory\r\n     * caches a document=&gt;version mapping (docVersions).\r\n     */\r\n    static from(batch, commitVersion, results) {\r\n        hardAssert(batch.mutations.length === results.length);\r\n        let versionMap = documentVersionMap();\r\n        const mutations = batch.mutations;\r\n        for (let i = 0; i < mutations.length; i++) {\r\n            versionMap = versionMap.insert(mutations[i].key, results[i].version);\r\n        }\r\n        return new MutationBatchResult(batch, commitVersion, results, versionMap);\r\n    }\r\n}\n\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\nclass ExistenceFilter {\r\n    // TODO(b/33078163): just use simplest form of existence filter for now\r\n    constructor(count) {\r\n        this.count = count;\r\n    }\r\n}\n\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\n/**\r\n * Error Codes describing the different ways GRPC can fail. These are copied\r\n * directly from GRPC's sources here:\r\n *\r\n * https://github.com/grpc/grpc/blob/bceec94ea4fc5f0085d81235d8e1c06798dc341a/include/grpc%2B%2B/impl/codegen/status_code_enum.h\r\n *\r\n * Important! The names of these identifiers matter because the string forms\r\n * are used for reverse lookups from the webchannel stream. Do NOT change the\r\n * names of these identifiers or change this into a const enum.\r\n */\r\nvar RpcCode;\r\n(function (RpcCode) {\r\n    RpcCode[RpcCode[\"OK\"] = 0] = \"OK\";\r\n    RpcCode[RpcCode[\"CANCELLED\"] = 1] = \"CANCELLED\";\r\n    RpcCode[RpcCode[\"UNKNOWN\"] = 2] = \"UNKNOWN\";\r\n    RpcCode[RpcCode[\"INVALID_ARGUMENT\"] = 3] = \"INVALID_ARGUMENT\";\r\n    RpcCode[RpcCode[\"DEADLINE_EXCEEDED\"] = 4] = \"DEADLINE_EXCEEDED\";\r\n    RpcCode[RpcCode[\"NOT_FOUND\"] = 5] = \"NOT_FOUND\";\r\n    RpcCode[RpcCode[\"ALREADY_EXISTS\"] = 6] = \"ALREADY_EXISTS\";\r\n    RpcCode[RpcCode[\"PERMISSION_DENIED\"] = 7] = \"PERMISSION_DENIED\";\r\n    RpcCode[RpcCode[\"UNAUTHENTICATED\"] = 16] = \"UNAUTHENTICATED\";\r\n    RpcCode[RpcCode[\"RESOURCE_EXHAUSTED\"] = 8] = \"RESOURCE_EXHAUSTED\";\r\n    RpcCode[RpcCode[\"FAILED_PRECONDITION\"] = 9] = \"FAILED_PRECONDITION\";\r\n    RpcCode[RpcCode[\"ABORTED\"] = 10] = \"ABORTED\";\r\n    RpcCode[RpcCode[\"OUT_OF_RANGE\"] = 11] = \"OUT_OF_RANGE\";\r\n    RpcCode[RpcCode[\"UNIMPLEMENTED\"] = 12] = \"UNIMPLEMENTED\";\r\n    RpcCode[RpcCode[\"INTERNAL\"] = 13] = \"INTERNAL\";\r\n    RpcCode[RpcCode[\"UNAVAILABLE\"] = 14] = \"UNAVAILABLE\";\r\n    RpcCode[RpcCode[\"DATA_LOSS\"] = 15] = \"DATA_LOSS\";\r\n})(RpcCode || (RpcCode = {}));\r\n/**\r\n * Determines whether an error code represents a permanent error when received\r\n * in response to a non-write operation.\r\n *\r\n * See isPermanentWriteError for classifying write errors.\r\n */\r\nfunction isPermanentError(code) {\r\n    switch (code) {\r\n        case Code.OK:\r\n            return fail();\r\n        case Code.CANCELLED:\r\n        case Code.UNKNOWN:\r\n        case Code.DEADLINE_EXCEEDED:\r\n        case Code.RESOURCE_EXHAUSTED:\r\n        case Code.INTERNAL:\r\n        case Code.UNAVAILABLE:\r\n        // Unauthenticated means something went wrong with our token and we need\r\n        // to retry with new credentials which will happen automatically.\r\n        case Code.UNAUTHENTICATED:\r\n            return false;\r\n        case Code.INVALID_ARGUMENT:\r\n        case Code.NOT_FOUND:\r\n        case Code.ALREADY_EXISTS:\r\n        case Code.PERMISSION_DENIED:\r\n        case Code.FAILED_PRECONDITION:\r\n        // Aborted might be retried in some scenarios, but that is dependant on\r\n        // the context and should handled individually by the calling code.\r\n        // See https://cloud.google.com/apis/design/errors.\r\n        case Code.ABORTED:\r\n        case Code.OUT_OF_RANGE:\r\n        case Code.UNIMPLEMENTED:\r\n        case Code.DATA_LOSS:\r\n            return true;\r\n        default:\r\n            return fail();\r\n    }\r\n}\r\n/**\r\n * Determines whether an error code represents a permanent error when received\r\n * in response to a write operation.\r\n *\r\n * Write operations must be handled specially because as of b/119437764, ABORTED\r\n * errors on the write stream should be retried too (even though ABORTED errors\r\n * are not generally retryable).\r\n *\r\n * Note that during the initial handshake on the write stream an ABORTED error\r\n * signals that we should discard our stream token (i.e. it is permanent). This\r\n * means a handshake error should be classified with isPermanentError, above.\r\n */\r\nfunction isPermanentWriteError(code) {\r\n    return isPermanentError(code) && code !== Code.ABORTED;\r\n}\r\n/**\r\n * Maps an error Code from GRPC status code number, like 0, 1, or 14. These\r\n * are not the same as HTTP status codes.\r\n *\r\n * @returns The Code equivalent to the given GRPC status code. Fails if there\r\n *     is no match.\r\n */\r\nfunction mapCodeFromRpcCode(code) {\r\n    if (code === undefined) {\r\n        // This shouldn't normally happen, but in certain error cases (like trying\r\n        // to send invalid proto messages) we may get an error with no GRPC code.\r\n        logError('GRPC error has no .code');\r\n        return Code.UNKNOWN;\r\n    }\r\n    switch (code) {\r\n        case RpcCode.OK:\r\n            return Code.OK;\r\n        case RpcCode.CANCELLED:\r\n            return Code.CANCELLED;\r\n        case RpcCode.UNKNOWN:\r\n            return Code.UNKNOWN;\r\n        case RpcCode.DEADLINE_EXCEEDED:\r\n            return Code.DEADLINE_EXCEEDED;\r\n        case RpcCode.RESOURCE_EXHAUSTED:\r\n            return Code.RESOURCE_EXHAUSTED;\r\n        case RpcCode.INTERNAL:\r\n            return Code.INTERNAL;\r\n        case RpcCode.UNAVAILABLE:\r\n            return Code.UNAVAILABLE;\r\n        case RpcCode.UNAUTHENTICATED:\r\n            return Code.UNAUTHENTICATED;\r\n        case RpcCode.INVALID_ARGUMENT:\r\n            return Code.INVALID_ARGUMENT;\r\n        case RpcCode.NOT_FOUND:\r\n            return Code.NOT_FOUND;\r\n        case RpcCode.ALREADY_EXISTS:\r\n            return Code.ALREADY_EXISTS;\r\n        case RpcCode.PERMISSION_DENIED:\r\n            return Code.PERMISSION_DENIED;\r\n        case RpcCode.FAILED_PRECONDITION:\r\n            return Code.FAILED_PRECONDITION;\r\n        case RpcCode.ABORTED:\r\n            return Code.ABORTED;\r\n        case RpcCode.OUT_OF_RANGE:\r\n            return Code.OUT_OF_RANGE;\r\n        case RpcCode.UNIMPLEMENTED:\r\n            return Code.UNIMPLEMENTED;\r\n        case RpcCode.DATA_LOSS:\r\n            return Code.DATA_LOSS;\r\n        default:\r\n            return fail();\r\n    }\r\n}\n\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\n/**\r\n * An event from the RemoteStore. It is split into targetChanges (changes to the\r\n * state or the set of documents in our watched targets) and documentUpdates\r\n * (changes to the actual documents).\r\n */\r\nclass RemoteEvent {\r\n    constructor(\r\n    /**\r\n     * The snapshot version this event brings us up to, or MIN if not set.\r\n     */\r\n    snapshotVersion, \r\n    /**\r\n     * A map from target to changes to the target. See TargetChange.\r\n     */\r\n    targetChanges, \r\n    /**\r\n     * A set of targets that is known to be inconsistent. Listens for these\r\n     * targets should be re-established without resume tokens.\r\n     */\r\n    targetMismatches, \r\n    /**\r\n     * A set of which documents have changed or been deleted, along with the\r\n     * doc's new values (if not deleted).\r\n     */\r\n    documentUpdates, \r\n    /**\r\n     * A set of which document updates are due only to limbo resolution targets.\r\n     */\r\n    resolvedLimboDocuments) {\r\n        this.snapshotVersion = snapshotVersion;\r\n        this.targetChanges = targetChanges;\r\n        this.targetMismatches = targetMismatches;\r\n        this.documentUpdates = documentUpdates;\r\n        this.resolvedLimboDocuments = resolvedLimboDocuments;\r\n    }\r\n    /**\r\n     * HACK: Views require RemoteEvents in order to determine whether the view is\r\n     * CURRENT, but secondary tabs don't receive remote events. So this method is\r\n     * used to create a synthesized RemoteEvent that can be used to apply a\r\n     * CURRENT status change to a View, for queries executed in a different tab.\r\n     */\r\n    // PORTING NOTE: Multi-tab only\r\n    static createSynthesizedRemoteEventForCurrentChange(targetId, current) {\r\n        const targetChanges = new Map();\r\n        targetChanges.set(targetId, TargetChange.createSynthesizedTargetChangeForCurrentChange(targetId, current));\r\n        return new RemoteEvent(SnapshotVersion.min(), targetChanges, targetIdSet(), mutableDocumentMap(), documentKeySet());\r\n    }\r\n}\r\n/**\r\n * A TargetChange specifies the set of changes for a specific target as part of\r\n * a RemoteEvent. These changes track which documents are added, modified or\r\n * removed, as well as the target's resume token and whether the target is\r\n * marked CURRENT.\r\n * The actual changes *to* documents are not part of the TargetChange since\r\n * documents may be part of multiple targets.\r\n */\r\nclass TargetChange {\r\n    constructor(\r\n    /**\r\n     * An opaque, server-assigned token that allows watching a query to be resumed\r\n     * after disconnecting without retransmitting all the data that matches the\r\n     * query. The resume token essentially identifies a point in time from which\r\n     * the server should resume sending results.\r\n     */\r\n    resumeToken, \r\n    /**\r\n     * The \"current\" (synced) status of this target. Note that \"current\"\r\n     * has special meaning in the RPC protocol that implies that a target is\r\n     * both up-to-date and consistent with the rest of the watch stream.\r\n     */\r\n    current, \r\n    /**\r\n     * The set of documents that were newly assigned to this target as part of\r\n     * this remote event.\r\n     */\r\n    addedDocuments, \r\n    /**\r\n     * The set of documents that were already assigned to this target but received\r\n     * an update during this remote event.\r\n     */\r\n    modifiedDocuments, \r\n    /**\r\n     * The set of documents that were removed from this target as part of this\r\n     * remote event.\r\n     */\r\n    removedDocuments) {\r\n        this.resumeToken = resumeToken;\r\n        this.current = current;\r\n        this.addedDocuments = addedDocuments;\r\n        this.modifiedDocuments = modifiedDocuments;\r\n        this.removedDocuments = removedDocuments;\r\n    }\r\n    /**\r\n     * This method is used to create a synthesized TargetChanges that can be used to\r\n     * apply a CURRENT status change to a View (for queries executed in a different\r\n     * tab) or for new queries (to raise snapshots with correct CURRENT status).\r\n     */\r\n    static createSynthesizedTargetChangeForCurrentChange(targetId, current) {\r\n        return new TargetChange(ByteString.EMPTY_BYTE_STRING, current, documentKeySet(), documentKeySet(), documentKeySet());\r\n    }\r\n}\n\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\n/**\r\n * Represents a changed document and a list of target ids to which this change\r\n * applies.\r\n *\r\n * If document has been deleted NoDocument will be provided.\r\n */\r\nclass DocumentWatchChange {\r\n    constructor(\r\n    /** The new document applies to all of these targets. */\r\n    updatedTargetIds, \r\n    /** The new document is removed from all of these targets. */\r\n    removedTargetIds, \r\n    /** The key of the document for this change. */\r\n    key, \r\n    /**\r\n     * The new document or NoDocument if it was deleted. Is null if the\r\n     * document went out of view without the server sending a new document.\r\n     */\r\n    newDoc) {\r\n        this.updatedTargetIds = updatedTargetIds;\r\n        this.removedTargetIds = removedTargetIds;\r\n        this.key = key;\r\n        this.newDoc = newDoc;\r\n    }\r\n}\r\nclass ExistenceFilterChange {\r\n    constructor(targetId, existenceFilter) {\r\n        this.targetId = targetId;\r\n        this.existenceFilter = existenceFilter;\r\n    }\r\n}\r\nclass WatchTargetChange {\r\n    constructor(\r\n    /** What kind of change occurred to the watch target. */\r\n    state, \r\n    /** The target IDs that were added/removed/set. */\r\n    targetIds, \r\n    /**\r\n     * An opaque, server-assigned token that allows watching a target to be\r\n     * resumed after disconnecting without retransmitting all the data that\r\n     * matches the target. The resume token essentially identifies a point in\r\n     * time from which the server should resume sending results.\r\n     */\r\n    resumeToken = ByteString.EMPTY_BYTE_STRING, \r\n    /** An RPC error indicating why the watch failed. */\r\n    cause = null) {\r\n        this.state = state;\r\n        this.targetIds = targetIds;\r\n        this.resumeToken = resumeToken;\r\n        this.cause = cause;\r\n    }\r\n}\r\n/** Tracks the internal state of a Watch target. */\r\nclass TargetState {\r\n    constructor() {\r\n        /**\r\n         * The number of pending responses (adds or removes) that we are waiting on.\r\n         * We only consider targets active that have no pending responses.\r\n         */\r\n        this.pendingResponses = 0;\r\n        /**\r\n         * Keeps track of the document changes since the last raised snapshot.\r\n         *\r\n         * These changes are continuously updated as we receive document updates and\r\n         * always reflect the current set of changes against the last issued snapshot.\r\n         */\r\n        this.documentChanges = snapshotChangesMap();\r\n        /** See public getters for explanations of these fields. */\r\n        this._resumeToken = ByteString.EMPTY_BYTE_STRING;\r\n        this._current = false;\r\n        /**\r\n         * Whether this target state should be included in the next snapshot. We\r\n         * initialize to true so that newly-added targets are included in the next\r\n         * RemoteEvent.\r\n         */\r\n        this._hasPendingChanges = true;\r\n    }\r\n    /**\r\n     * Whether this target has been marked 'current'.\r\n     *\r\n     * 'Current' has special meaning in the RPC protocol: It implies that the\r\n     * Watch backend has sent us all changes up to the point at which the target\r\n     * was added and that the target is consistent with the rest of the watch\r\n     * stream.\r\n     */\r\n    get current() {\r\n        return this._current;\r\n    }\r\n    /** The last resume token sent to us for this target. */\r\n    get resumeToken() {\r\n        return this._resumeToken;\r\n    }\r\n    /** Whether this target has pending target adds or target removes. */\r\n    get isPending() {\r\n        return this.pendingResponses !== 0;\r\n    }\r\n    /** Whether we have modified any state that should trigger a snapshot. */\r\n    get hasPendingChanges() {\r\n        return this._hasPendingChanges;\r\n    }\r\n    /**\r\n     * Applies the resume token to the TargetChange, but only when it has a new\r\n     * value. Empty resumeTokens are discarded.\r\n     */\r\n    updateResumeToken(resumeToken) {\r\n        if (resumeToken.approximateByteSize() > 0) {\r\n            this._hasPendingChanges = true;\r\n            this._resumeToken = resumeToken;\r\n        }\r\n    }\r\n    /**\r\n     * Creates a target change from the current set of changes.\r\n     *\r\n     * To reset the document changes after raising this snapshot, call\r\n     * `clearPendingChanges()`.\r\n     */\r\n    toTargetChange() {\r\n        let addedDocuments = documentKeySet();\r\n        let modifiedDocuments = documentKeySet();\r\n        let removedDocuments = documentKeySet();\r\n        this.documentChanges.forEach((key, changeType) => {\r\n            switch (changeType) {\r\n                case 0 /* Added */:\r\n                    addedDocuments = addedDocuments.add(key);\r\n                    break;\r\n                case 2 /* Modified */:\r\n                    modifiedDocuments = modifiedDocuments.add(key);\r\n                    break;\r\n                case 1 /* Removed */:\r\n                    removedDocuments = removedDocuments.add(key);\r\n                    break;\r\n                default:\r\n                    fail();\r\n            }\r\n        });\r\n        return new TargetChange(this._resumeToken, this._current, addedDocuments, modifiedDocuments, removedDocuments);\r\n    }\r\n    /**\r\n     * Resets the document changes and sets `hasPendingChanges` to false.\r\n     */\r\n    clearPendingChanges() {\r\n        this._hasPendingChanges = false;\r\n        this.documentChanges = snapshotChangesMap();\r\n    }\r\n    addDocumentChange(key, changeType) {\r\n        this._hasPendingChanges = true;\r\n        this.documentChanges = this.documentChanges.insert(key, changeType);\r\n    }\r\n    removeDocumentChange(key) {\r\n        this._hasPendingChanges = true;\r\n        this.documentChanges = this.documentChanges.remove(key);\r\n    }\r\n    recordPendingTargetRequest() {\r\n        this.pendingResponses += 1;\r\n    }\r\n    recordTargetResponse() {\r\n        this.pendingResponses -= 1;\r\n    }\r\n    markCurrent() {\r\n        this._hasPendingChanges = true;\r\n        this._current = true;\r\n    }\r\n}\r\nconst LOG_TAG = 'WatchChangeAggregator';\r\n/**\r\n * A helper class to accumulate watch changes into a RemoteEvent.\r\n */\r\nclass WatchChangeAggregator {\r\n    constructor(metadataProvider) {\r\n        this.metadataProvider = metadataProvider;\r\n        /** The internal state of all tracked targets. */\r\n        this.targetStates = new Map();\r\n        /** Keeps track of the documents to update since the last raised snapshot. */\r\n        this.pendingDocumentUpdates = mutableDocumentMap();\r\n        /** A mapping of document keys to their set of target IDs. */\r\n        this.pendingDocumentTargetMapping = documentTargetMap();\r\n        /**\r\n         * A list of targets with existence filter mismatches. These targets are\r\n         * known to be inconsistent and their listens needs to be re-established by\r\n         * RemoteStore.\r\n         */\r\n        this.pendingTargetResets = new SortedSet(primitiveComparator);\r\n    }\r\n    /**\r\n     * Processes and adds the DocumentWatchChange to the current set of changes.\r\n     */\r\n    handleDocumentChange(docChange) {\r\n        for (const targetId of docChange.updatedTargetIds) {\r\n            if (docChange.newDoc && docChange.newDoc.isFoundDocument()) {\r\n                this.addDocumentToTarget(targetId, docChange.newDoc);\r\n            }\r\n            else {\r\n                this.removeDocumentFromTarget(targetId, docChange.key, docChange.newDoc);\r\n            }\r\n        }\r\n        for (const targetId of docChange.removedTargetIds) {\r\n            this.removeDocumentFromTarget(targetId, docChange.key, docChange.newDoc);\r\n        }\r\n    }\r\n    /** Processes and adds the WatchTargetChange to the current set of changes. */\r\n    handleTargetChange(targetChange) {\r\n        this.forEachTarget(targetChange, targetId => {\r\n            const targetState = this.ensureTargetState(targetId);\r\n            switch (targetChange.state) {\r\n                case 0 /* NoChange */:\r\n                    if (this.isActiveTarget(targetId)) {\r\n                        targetState.updateResumeToken(targetChange.resumeToken);\r\n                    }\r\n                    break;\r\n                case 1 /* Added */:\r\n                    // We need to decrement the number of pending acks needed from watch\r\n                    // for this targetId.\r\n                    targetState.recordTargetResponse();\r\n                    if (!targetState.isPending) {\r\n                        // We have a freshly added target, so we need to reset any state\r\n                        // that we had previously. This can happen e.g. when remove and add\r\n                        // back a target for existence filter mismatches.\r\n                        targetState.clearPendingChanges();\r\n                    }\r\n                    targetState.updateResumeToken(targetChange.resumeToken);\r\n                    break;\r\n                case 2 /* Removed */:\r\n                    // We need to keep track of removed targets to we can post-filter and\r\n                    // remove any target changes.\r\n                    // We need to decrement the number of pending acks needed from watch\r\n                    // for this targetId.\r\n                    targetState.recordTargetResponse();\r\n                    if (!targetState.isPending) {\r\n                        this.removeTarget(targetId);\r\n                    }\r\n                    break;\r\n                case 3 /* Current */:\r\n                    if (this.isActiveTarget(targetId)) {\r\n                        targetState.markCurrent();\r\n                        targetState.updateResumeToken(targetChange.resumeToken);\r\n                    }\r\n                    break;\r\n                case 4 /* Reset */:\r\n                    if (this.isActiveTarget(targetId)) {\r\n                        // Reset the target and synthesizes removes for all existing\r\n                        // documents. The backend will re-add any documents that still\r\n                        // match the target before it sends the next global snapshot.\r\n                        this.resetTarget(targetId);\r\n                        targetState.updateResumeToken(targetChange.resumeToken);\r\n                    }\r\n                    break;\r\n                default:\r\n                    fail();\r\n            }\r\n        });\r\n    }\r\n    /**\r\n     * Iterates over all targetIds that the watch change applies to: either the\r\n     * targetIds explicitly listed in the change or the targetIds of all currently\r\n     * active targets.\r\n     */\r\n    forEachTarget(targetChange, fn) {\r\n        if (targetChange.targetIds.length > 0) {\r\n            targetChange.targetIds.forEach(fn);\r\n        }\r\n        else {\r\n            this.targetStates.forEach((_, targetId) => {\r\n                if (this.isActiveTarget(targetId)) {\r\n                    fn(targetId);\r\n                }\r\n            });\r\n        }\r\n    }\r\n    /**\r\n     * Handles existence filters and synthesizes deletes for filter mismatches.\r\n     * Targets that are invalidated by filter mismatches are added to\r\n     * `pendingTargetResets`.\r\n     */\r\n    handleExistenceFilter(watchChange) {\r\n        const targetId = watchChange.targetId;\r\n        const expectedCount = watchChange.existenceFilter.count;\r\n        const targetData = this.targetDataForActiveTarget(targetId);\r\n        if (targetData) {\r\n            const target = targetData.target;\r\n            if (isDocumentTarget(target)) {\r\n                if (expectedCount === 0) {\r\n                    // The existence filter told us the document does not exist. We deduce\r\n                    // that this document does not exist and apply a deleted document to\r\n                    // our updates. Without applying this deleted document there might be\r\n                    // another query that will raise this document as part of a snapshot\r\n                    // until it is resolved, essentially exposing inconsistency between\r\n                    // queries.\r\n                    const key = new DocumentKey(target.path);\r\n                    this.removeDocumentFromTarget(targetId, key, MutableDocument.newNoDocument(key, SnapshotVersion.min()));\r\n                }\r\n                else {\r\n                    hardAssert(expectedCount === 1);\r\n                }\r\n            }\r\n            else {\r\n                const currentSize = this.getCurrentDocumentCountForTarget(targetId);\r\n                if (currentSize !== expectedCount) {\r\n                    // Existence filter mismatch: We reset the mapping and raise a new\r\n                    // snapshot with `isFromCache:true`.\r\n                    this.resetTarget(targetId);\r\n                    this.pendingTargetResets = this.pendingTargetResets.add(targetId);\r\n                }\r\n            }\r\n        }\r\n    }\r\n    /**\r\n     * Converts the currently accumulated state into a remote event at the\r\n     * provided snapshot version. Resets the accumulated changes before returning.\r\n     */\r\n    createRemoteEvent(snapshotVersion) {\r\n        const targetChanges = new Map();\r\n        this.targetStates.forEach((targetState, targetId) => {\r\n            const targetData = this.targetDataForActiveTarget(targetId);\r\n            if (targetData) {\r\n                if (targetState.current && isDocumentTarget(targetData.target)) {\r\n                    // Document queries for document that don't exist can produce an empty\r\n                    // result set. To update our local cache, we synthesize a document\r\n                    // delete if we have not previously received the document. This\r\n                    // resolves the limbo state of the document, removing it from\r\n                    // limboDocumentRefs.\r\n                    //\r\n                    // TODO(dimond): Ideally we would have an explicit lookup target\r\n                    // instead resulting in an explicit delete message and we could\r\n                    // remove this special logic.\r\n                    const key = new DocumentKey(targetData.target.path);\r\n                    if (this.pendingDocumentUpdates.get(key) === null &&\r\n                        !this.targetContainsDocument(targetId, key)) {\r\n                        this.removeDocumentFromTarget(targetId, key, MutableDocument.newNoDocument(key, snapshotVersion));\r\n                    }\r\n                }\r\n                if (targetState.hasPendingChanges) {\r\n                    targetChanges.set(targetId, targetState.toTargetChange());\r\n                    targetState.clearPendingChanges();\r\n                }\r\n            }\r\n        });\r\n        let resolvedLimboDocuments = documentKeySet();\r\n        // We extract the set of limbo-only document updates as the GC logic\r\n        // special-cases documents that do not appear in the target cache.\r\n        //\r\n        // TODO(gsoltis): Expand on this comment once GC is available in the JS\r\n        // client.\r\n        this.pendingDocumentTargetMapping.forEach((key, targets) => {\r\n            let isOnlyLimboTarget = true;\r\n            targets.forEachWhile(targetId => {\r\n                const targetData = this.targetDataForActiveTarget(targetId);\r\n                if (targetData &&\r\n                    targetData.purpose !== 2 /* LimboResolution */) {\r\n                    isOnlyLimboTarget = false;\r\n                    return false;\r\n                }\r\n                return true;\r\n            });\r\n            if (isOnlyLimboTarget) {\r\n                resolvedLimboDocuments = resolvedLimboDocuments.add(key);\r\n            }\r\n        });\r\n        const remoteEvent = new RemoteEvent(snapshotVersion, targetChanges, this.pendingTargetResets, this.pendingDocumentUpdates, resolvedLimboDocuments);\r\n        this.pendingDocumentUpdates = mutableDocumentMap();\r\n        this.pendingDocumentTargetMapping = documentTargetMap();\r\n        this.pendingTargetResets = new SortedSet(primitiveComparator);\r\n        return remoteEvent;\r\n    }\r\n    /**\r\n     * Adds the provided document to the internal list of document updates and\r\n     * its document key to the given target's mapping.\r\n     */\r\n    // Visible for testing.\r\n    addDocumentToTarget(targetId, document) {\r\n        if (!this.isActiveTarget(targetId)) {\r\n            return;\r\n        }\r\n        const changeType = this.targetContainsDocument(targetId, document.key)\r\n            ? 2 /* Modified */\r\n            : 0 /* Added */;\r\n        const targetState = this.ensureTargetState(targetId);\r\n        targetState.addDocumentChange(document.key, changeType);\r\n        this.pendingDocumentUpdates = this.pendingDocumentUpdates.insert(document.key, document);\r\n        this.pendingDocumentTargetMapping = this.pendingDocumentTargetMapping.insert(document.key, this.ensureDocumentTargetMapping(document.key).add(targetId));\r\n    }\r\n    /**\r\n     * Removes the provided document from the target mapping. If the\r\n     * document no longer matches the target, but the document's state is still\r\n     * known (e.g. we know that the document was deleted or we received the change\r\n     * that caused the filter mismatch), the new document can be provided\r\n     * to update the remote document cache.\r\n     */\r\n    // Visible for testing.\r\n    removeDocumentFromTarget(targetId, key, updatedDocument) {\r\n        if (!this.isActiveTarget(targetId)) {\r\n            return;\r\n        }\r\n        const targetState = this.ensureTargetState(targetId);\r\n        if (this.targetContainsDocument(targetId, key)) {\r\n            targetState.addDocumentChange(key, 1 /* Removed */);\r\n        }\r\n        else {\r\n            // The document may have entered and left the target before we raised a\r\n            // snapshot, so we can just ignore the change.\r\n            targetState.removeDocumentChange(key);\r\n        }\r\n        this.pendingDocumentTargetMapping = this.pendingDocumentTargetMapping.insert(key, this.ensureDocumentTargetMapping(key).delete(targetId));\r\n        if (updatedDocument) {\r\n            this.pendingDocumentUpdates = this.pendingDocumentUpdates.insert(key, updatedDocument);\r\n        }\r\n    }\r\n    removeTarget(targetId) {\r\n        this.targetStates.delete(targetId);\r\n    }\r\n    /**\r\n     * Returns the current count of documents in the target. This includes both\r\n     * the number of documents that the LocalStore considers to be part of the\r\n     * target as well as any accumulated changes.\r\n     */\r\n    getCurrentDocumentCountForTarget(targetId) {\r\n        const targetState = this.ensureTargetState(targetId);\r\n        const targetChange = targetState.toTargetChange();\r\n        return (this.metadataProvider.getRemoteKeysForTarget(targetId).size +\r\n            targetChange.addedDocuments.size -\r\n            targetChange.removedDocuments.size);\r\n    }\r\n    /**\r\n     * Increment the number of acks needed from watch before we can consider the\r\n     * server to be 'in-sync' with the client's active targets.\r\n     */\r\n    recordPendingTargetRequest(targetId) {\r\n        // For each request we get we need to record we need a response for it.\r\n        const targetState = this.ensureTargetState(targetId);\r\n        targetState.recordPendingTargetRequest();\r\n    }\r\n    ensureTargetState(targetId) {\r\n        let result = this.targetStates.get(targetId);\r\n        if (!result) {\r\n            result = new TargetState();\r\n            this.targetStates.set(targetId, result);\r\n        }\r\n        return result;\r\n    }\r\n    ensureDocumentTargetMapping(key) {\r\n        let targetMapping = this.pendingDocumentTargetMapping.get(key);\r\n        if (!targetMapping) {\r\n            targetMapping = new SortedSet(primitiveComparator);\r\n            this.pendingDocumentTargetMapping = this.pendingDocumentTargetMapping.insert(key, targetMapping);\r\n        }\r\n        return targetMapping;\r\n    }\r\n    /**\r\n     * Verifies that the user is still interested in this target (by calling\r\n     * `getTargetDataForTarget()`) and that we are not waiting for pending ADDs\r\n     * from watch.\r\n     */\r\n    isActiveTarget(targetId) {\r\n        const targetActive = this.targetDataForActiveTarget(targetId) !== null;\r\n        if (!targetActive) {\r\n            logDebug(LOG_TAG, 'Detected inactive target', targetId);\r\n        }\r\n        return targetActive;\r\n    }\r\n    /**\r\n     * Returns the TargetData for an active target (i.e. a target that the user\r\n     * is still interested in that has no outstanding target change requests).\r\n     */\r\n    targetDataForActiveTarget(targetId) {\r\n        const targetState = this.targetStates.get(targetId);\r\n        return targetState && targetState.isPending\r\n            ? null\r\n            : this.metadataProvider.getTargetDataForTarget(targetId);\r\n    }\r\n    /**\r\n     * Resets the state of a Watch target to its initial state (e.g. sets\r\n     * 'current' to false, clears the resume token and removes its target mapping\r\n     * from all documents).\r\n     */\r\n    resetTarget(targetId) {\r\n        this.targetStates.set(targetId, new TargetState());\r\n        // Trigger removal for any documents currently mapped to this target.\r\n        // These removals will be part of the initial snapshot if Watch does not\r\n        // resend these documents.\r\n        const existingKeys = this.metadataProvider.getRemoteKeysForTarget(targetId);\r\n        existingKeys.forEach(key => {\r\n            this.removeDocumentFromTarget(targetId, key, /*updatedDocument=*/ null);\r\n        });\r\n    }\r\n    /**\r\n     * Returns whether the LocalStore considers the document to be part of the\r\n     * specified target.\r\n     */\r\n    targetContainsDocument(targetId, key) {\r\n        const existingKeys = this.metadataProvider.getRemoteKeysForTarget(targetId);\r\n        return existingKeys.has(key);\r\n    }\r\n}\r\nfunction documentTargetMap() {\r\n    return new SortedMap(DocumentKey.comparator);\r\n}\r\nfunction snapshotChangesMap() {\r\n    return new SortedMap(DocumentKey.comparator);\r\n}\n\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\nconst DIRECTIONS = (() => {\r\n    const dirs = {};\r\n    dirs[\"asc\" /* ASCENDING */] = 'ASCENDING';\r\n    dirs[\"desc\" /* DESCENDING */] = 'DESCENDING';\r\n    return dirs;\r\n})();\r\nconst OPERATORS = (() => {\r\n    const ops = {};\r\n    ops[\"<\" /* LESS_THAN */] = 'LESS_THAN';\r\n    ops[\"<=\" /* LESS_THAN_OR_EQUAL */] = 'LESS_THAN_OR_EQUAL';\r\n    ops[\">\" /* GREATER_THAN */] = 'GREATER_THAN';\r\n    ops[\">=\" /* GREATER_THAN_OR_EQUAL */] = 'GREATER_THAN_OR_EQUAL';\r\n    ops[\"==\" /* EQUAL */] = 'EQUAL';\r\n    ops[\"!=\" /* NOT_EQUAL */] = 'NOT_EQUAL';\r\n    ops[\"array-contains\" /* ARRAY_CONTAINS */] = 'ARRAY_CONTAINS';\r\n    ops[\"in\" /* IN */] = 'IN';\r\n    ops[\"not-in\" /* NOT_IN */] = 'NOT_IN';\r\n    ops[\"array-contains-any\" /* ARRAY_CONTAINS_ANY */] = 'ARRAY_CONTAINS_ANY';\r\n    return ops;\r\n})();\r\nfunction assertPresent(value, description) {\r\n}\r\n/**\r\n * This class generates JsonObject values for the Datastore API suitable for\r\n * sending to either GRPC stub methods or via the JSON/HTTP REST API.\r\n *\r\n * The serializer supports both Protobuf.js and Proto3 JSON formats. By\r\n * setting `useProto3Json` to true, the serializer will use the Proto3 JSON\r\n * format.\r\n *\r\n * For a description of the Proto3 JSON format check\r\n * https://developers.google.com/protocol-buffers/docs/proto3#json\r\n *\r\n * TODO(klimt): We can remove the databaseId argument if we keep the full\r\n * resource name in documents.\r\n */\r\nclass JsonProtoSerializer {\r\n    constructor(databaseId, useProto3Json) {\r\n        this.databaseId = databaseId;\r\n        this.useProto3Json = useProto3Json;\r\n    }\r\n}\r\nfunction fromRpcStatus(status) {\r\n    const code = status.code === undefined ? Code.UNKNOWN : mapCodeFromRpcCode(status.code);\r\n    return new FirestoreError(code, status.message || '');\r\n}\r\n/**\r\n * Returns a value for a number (or null) that's appropriate to put into\r\n * a google.protobuf.Int32Value proto.\r\n * DO NOT USE THIS FOR ANYTHING ELSE.\r\n * This method cheats. It's typed as returning \"number\" because that's what\r\n * our generated proto interfaces say Int32Value must be. But GRPC actually\r\n * expects a { value: <number> } struct.\r\n */\r\nfunction toInt32Proto(serializer, val) {\r\n    if (serializer.useProto3Json || isNullOrUndefined(val)) {\r\n        return val;\r\n    }\r\n    else {\r\n        return { value: val };\r\n    }\r\n}\r\n/**\r\n * Returns a number (or null) from a google.protobuf.Int32Value proto.\r\n */\r\nfunction fromInt32Proto(val) {\r\n    let result;\r\n    if (typeof val === 'object') {\r\n        result = val.value;\r\n    }\r\n    else {\r\n        result = val;\r\n    }\r\n    return isNullOrUndefined(result) ? null : result;\r\n}\r\n/**\r\n * Returns a value for a Date that's appropriate to put into a proto.\r\n */\r\nfunction toTimestamp(serializer, timestamp) {\r\n    if (serializer.useProto3Json) {\r\n        // Serialize to ISO-8601 date format, but with full nano resolution.\r\n        // Since JS Date has only millis, let's only use it for the seconds and\r\n        // then manually add the fractions to the end.\r\n        const jsDateStr = new Date(timestamp.seconds * 1000).toISOString();\r\n        // Remove .xxx frac part and Z in the end.\r\n        const strUntilSeconds = jsDateStr.replace(/\\.\\d*/, '').replace('Z', '');\r\n        // Pad the fraction out to 9 digits (nanos).\r\n        const nanoStr = ('000000000' + timestamp.nanoseconds).slice(-9);\r\n        return `${strUntilSeconds}.${nanoStr}Z`;\r\n    }\r\n    else {\r\n        return {\r\n            seconds: '' + timestamp.seconds,\r\n            nanos: timestamp.nanoseconds\r\n            // eslint-disable-next-line @typescript-eslint/no-explicit-any\r\n        };\r\n    }\r\n}\r\nfunction fromTimestamp(date) {\r\n    const timestamp = normalizeTimestamp(date);\r\n    return new Timestamp(timestamp.seconds, timestamp.nanos);\r\n}\r\n/**\r\n * Returns a value for bytes that's appropriate to put in a proto.\r\n *\r\n * Visible for testing.\r\n */\r\nfunction toBytes(serializer, bytes) {\r\n    if (serializer.useProto3Json) {\r\n        return bytes.toBase64();\r\n    }\r\n    else {\r\n        return bytes.toUint8Array();\r\n    }\r\n}\r\n/**\r\n * Returns a ByteString based on the proto string value.\r\n */\r\nfunction fromBytes(serializer, value) {\r\n    if (serializer.useProto3Json) {\r\n        hardAssert(value === undefined || typeof value === 'string');\r\n        return ByteString.fromBase64String(value ? value : '');\r\n    }\r\n    else {\r\n        hardAssert(value === undefined || value instanceof Uint8Array);\r\n        return ByteString.fromUint8Array(value ? value : new Uint8Array());\r\n    }\r\n}\r\nfunction toVersion(serializer, version) {\r\n    return toTimestamp(serializer, version.toTimestamp());\r\n}\r\nfunction fromVersion(version) {\r\n    hardAssert(!!version);\r\n    return SnapshotVersion.fromTimestamp(fromTimestamp(version));\r\n}\r\nfunction toResourceName(databaseId, path) {\r\n    return fullyQualifiedPrefixPath(databaseId)\r\n        .child('documents')\r\n        .child(path)\r\n        .canonicalString();\r\n}\r\nfunction fromResourceName(name) {\r\n    const resource = ResourcePath.fromString(name);\r\n    hardAssert(isValidResourceName(resource));\r\n    return resource;\r\n}\r\nfunction toName(serializer, key) {\r\n    return toResourceName(serializer.databaseId, key.path);\r\n}\r\nfunction fromName(serializer, name) {\r\n    const resource = fromResourceName(name);\r\n    if (resource.get(1) !== serializer.databaseId.projectId) {\r\n        throw new FirestoreError(Code.INVALID_ARGUMENT, 'Tried to deserialize key from different project: ' +\r\n            resource.get(1) +\r\n            ' vs ' +\r\n            serializer.databaseId.projectId);\r\n    }\r\n    if (resource.get(3) !== serializer.databaseId.database) {\r\n        throw new FirestoreError(Code.INVALID_ARGUMENT, 'Tried to deserialize key from different database: ' +\r\n            resource.get(3) +\r\n            ' vs ' +\r\n            serializer.databaseId.database);\r\n    }\r\n    return new DocumentKey(extractLocalPathFromResourceName(resource));\r\n}\r\nfunction toQueryPath(serializer, path) {\r\n    return toResourceName(serializer.databaseId, path);\r\n}\r\nfunction fromQueryPath(name) {\r\n    const resourceName = fromResourceName(name);\r\n    // In v1beta1 queries for collections at the root did not have a trailing\r\n    // \"/documents\". In v1 all resource paths contain \"/documents\". Preserve the\r\n    // ability to read the v1beta1 form for compatibility with queries persisted\r\n    // in the local target cache.\r\n    if (resourceName.length === 4) {\r\n        return ResourcePath.emptyPath();\r\n    }\r\n    return extractLocalPathFromResourceName(resourceName);\r\n}\r\nfunction getEncodedDatabaseId(serializer) {\r\n    const path = new ResourcePath([\r\n        'projects',\r\n        serializer.databaseId.projectId,\r\n        'databases',\r\n        serializer.databaseId.database\r\n    ]);\r\n    return path.canonicalString();\r\n}\r\nfunction fullyQualifiedPrefixPath(databaseId) {\r\n    return new ResourcePath([\r\n        'projects',\r\n        databaseId.projectId,\r\n        'databases',\r\n        databaseId.database\r\n    ]);\r\n}\r\nfunction extractLocalPathFromResourceName(resourceName) {\r\n    hardAssert(resourceName.length > 4 && resourceName.get(4) === 'documents');\r\n    return resourceName.popFirst(5);\r\n}\r\n/** Creates a Document proto from key and fields (but no create/update time) */\r\nfunction toMutationDocument(serializer, key, fields) {\r\n    return {\r\n        name: toName(serializer, key),\r\n        fields: fields.toProto().mapValue.fields\r\n    };\r\n}\r\nfunction fromDocument(serializer, document, hasCommittedMutations) {\r\n    const key = fromName(serializer, document.name);\r\n    const version = fromVersion(document.updateTime);\r\n    const data = new ObjectValue({ mapValue: { fields: document.fields } });\r\n    const result = MutableDocument.newFoundDocument(key, version, data);\r\n    if (hasCommittedMutations) {\r\n        result.setHasCommittedMutations();\r\n    }\r\n    return hasCommittedMutations ? result.setHasCommittedMutations() : result;\r\n}\r\nfunction fromFound(serializer, doc) {\r\n    hardAssert(!!doc.found);\r\n    assertPresent(doc.found.name);\r\n    assertPresent(doc.found.updateTime);\r\n    const key = fromName(serializer, doc.found.name);\r\n    const version = fromVersion(doc.found.updateTime);\r\n    const data = new ObjectValue({ mapValue: { fields: doc.found.fields } });\r\n    return MutableDocument.newFoundDocument(key, version, data);\r\n}\r\nfunction fromMissing(serializer, result) {\r\n    hardAssert(!!result.missing);\r\n    hardAssert(!!result.readTime);\r\n    const key = fromName(serializer, result.missing);\r\n    const version = fromVersion(result.readTime);\r\n    return MutableDocument.newNoDocument(key, version);\r\n}\r\nfunction fromBatchGetDocumentsResponse(serializer, result) {\r\n    if ('found' in result) {\r\n        return fromFound(serializer, result);\r\n    }\r\n    else if ('missing' in result) {\r\n        return fromMissing(serializer, result);\r\n    }\r\n    return fail();\r\n}\r\nfunction fromWatchChange(serializer, change) {\r\n    let watchChange;\r\n    if ('targetChange' in change) {\r\n        assertPresent(change.targetChange);\r\n        // proto3 default value is unset in JSON (undefined), so use 'NO_CHANGE'\r\n        // if unset\r\n        const state = fromWatchTargetChangeState(change.targetChange.targetChangeType || 'NO_CHANGE');\r\n        const targetIds = change.targetChange.targetIds || [];\r\n        const resumeToken = fromBytes(serializer, change.targetChange.resumeToken);\r\n        const causeProto = change.targetChange.cause;\r\n        const cause = causeProto && fromRpcStatus(causeProto);\r\n        watchChange = new WatchTargetChange(state, targetIds, resumeToken, cause || null);\r\n    }\r\n    else if ('documentChange' in change) {\r\n        assertPresent(change.documentChange);\r\n        const entityChange = change.documentChange;\r\n        assertPresent(entityChange.document);\r\n        assertPresent(entityChange.document.name);\r\n        assertPresent(entityChange.document.updateTime);\r\n        const key = fromName(serializer, entityChange.document.name);\r\n        const version = fromVersion(entityChange.document.updateTime);\r\n        const data = new ObjectValue({\r\n            mapValue: { fields: entityChange.document.fields }\r\n        });\r\n        const doc = MutableDocument.newFoundDocument(key, version, data);\r\n        const updatedTargetIds = entityChange.targetIds || [];\r\n        const removedTargetIds = entityChange.removedTargetIds || [];\r\n        watchChange = new DocumentWatchChange(updatedTargetIds, removedTargetIds, doc.key, doc);\r\n    }\r\n    else if ('documentDelete' in change) {\r\n        assertPresent(change.documentDelete);\r\n        const docDelete = change.documentDelete;\r\n        assertPresent(docDelete.document);\r\n        const key = fromName(serializer, docDelete.document);\r\n        const version = docDelete.readTime\r\n            ? fromVersion(docDelete.readTime)\r\n            : SnapshotVersion.min();\r\n        const doc = MutableDocument.newNoDocument(key, version);\r\n        const removedTargetIds = docDelete.removedTargetIds || [];\r\n        watchChange = new DocumentWatchChange([], removedTargetIds, doc.key, doc);\r\n    }\r\n    else if ('documentRemove' in change) {\r\n        assertPresent(change.documentRemove);\r\n        const docRemove = change.documentRemove;\r\n        assertPresent(docRemove.document);\r\n        const key = fromName(serializer, docRemove.document);\r\n        const removedTargetIds = docRemove.removedTargetIds || [];\r\n        watchChange = new DocumentWatchChange([], removedTargetIds, key, null);\r\n    }\r\n    else if ('filter' in change) {\r\n        // TODO(dimond): implement existence filter parsing with strategy.\r\n        assertPresent(change.filter);\r\n        const filter = change.filter;\r\n        assertPresent(filter.targetId);\r\n        const count = filter.count || 0;\r\n        const existenceFilter = new ExistenceFilter(count);\r\n        const targetId = filter.targetId;\r\n        watchChange = new ExistenceFilterChange(targetId, existenceFilter);\r\n    }\r\n    else {\r\n        return fail();\r\n    }\r\n    return watchChange;\r\n}\r\nfunction fromWatchTargetChangeState(state) {\r\n    if (state === 'NO_CHANGE') {\r\n        return 0 /* NoChange */;\r\n    }\r\n    else if (state === 'ADD') {\r\n        return 1 /* Added */;\r\n    }\r\n    else if (state === 'REMOVE') {\r\n        return 2 /* Removed */;\r\n    }\r\n    else if (state === 'CURRENT') {\r\n        return 3 /* Current */;\r\n    }\r\n    else if (state === 'RESET') {\r\n        return 4 /* Reset */;\r\n    }\r\n    else {\r\n        return fail();\r\n    }\r\n}\r\nfunction versionFromListenResponse(change) {\r\n    // We have only reached a consistent snapshot for the entire stream if there\r\n    // is a read_time set and it applies to all targets (i.e. the list of\r\n    // targets is empty). The backend is guaranteed to send such responses.\r\n    if (!('targetChange' in change)) {\r\n        return SnapshotVersion.min();\r\n    }\r\n    const targetChange = change.targetChange;\r\n    if (targetChange.targetIds && targetChange.targetIds.length) {\r\n        return SnapshotVersion.min();\r\n    }\r\n    if (!targetChange.readTime) {\r\n        return SnapshotVersion.min();\r\n    }\r\n    return fromVersion(targetChange.readTime);\r\n}\r\nfunction toMutation(serializer, mutation) {\r\n    let result;\r\n    if (mutation instanceof SetMutation) {\r\n        result = {\r\n            update: toMutationDocument(serializer, mutation.key, mutation.value)\r\n        };\r\n    }\r\n    else if (mutation instanceof DeleteMutation) {\r\n        result = { delete: toName(serializer, mutation.key) };\r\n    }\r\n    else if (mutation instanceof PatchMutation) {\r\n        result = {\r\n            update: toMutationDocument(serializer, mutation.key, mutation.data),\r\n            updateMask: toDocumentMask(mutation.fieldMask)\r\n        };\r\n    }\r\n    else if (mutation instanceof VerifyMutation) {\r\n        result = {\r\n            verify: toName(serializer, mutation.key)\r\n        };\r\n    }\r\n    else {\r\n        return fail();\r\n    }\r\n    if (mutation.fieldTransforms.length > 0) {\r\n        result.updateTransforms = mutation.fieldTransforms.map(transform => toFieldTransform(serializer, transform));\r\n    }\r\n    if (!mutation.precondition.isNone) {\r\n        result.currentDocument = toPrecondition(serializer, mutation.precondition);\r\n    }\r\n    return result;\r\n}\r\nfunction toPrecondition(serializer, precondition) {\r\n    if (precondition.updateTime !== undefined) {\r\n        return {\r\n            updateTime: toVersion(serializer, precondition.updateTime)\r\n        };\r\n    }\r\n    else if (precondition.exists !== undefined) {\r\n        return { exists: precondition.exists };\r\n    }\r\n    else {\r\n        return fail();\r\n    }\r\n}\r\nfunction fromWriteResult(proto, commitTime) {\r\n    // NOTE: Deletes don't have an updateTime.\r\n    let version = proto.updateTime\r\n        ? fromVersion(proto.updateTime)\r\n        : fromVersion(commitTime);\r\n    if (version.isEqual(SnapshotVersion.min())) {\r\n        // The Firestore Emulator currently returns an update time of 0 for\r\n        // deletes of non-existing documents (rather than null). This breaks the\r\n        // test \"get deleted doc while offline with source=cache\" as NoDocuments\r\n        // with version 0 are filtered by IndexedDb's RemoteDocumentCache.\r\n        // TODO(#2149): Remove this when Emulator is fixed\r\n        version = fromVersion(commitTime);\r\n    }\r\n    return new MutationResult(version, proto.transformResults || []);\r\n}\r\nfunction fromWriteResults(protos, commitTime) {\r\n    if (protos && protos.length > 0) {\r\n        hardAssert(commitTime !== undefined);\r\n        return protos.map(proto => fromWriteResult(proto, commitTime));\r\n    }\r\n    else {\r\n        return [];\r\n    }\r\n}\r\nfunction toFieldTransform(serializer, fieldTransform) {\r\n    const transform = fieldTransform.transform;\r\n    if (transform instanceof ServerTimestampTransform) {\r\n        return {\r\n            fieldPath: fieldTransform.field.canonicalString(),\r\n            setToServerValue: 'REQUEST_TIME'\r\n        };\r\n    }\r\n    else if (transform instanceof ArrayUnionTransformOperation) {\r\n        return {\r\n            fieldPath: fieldTransform.field.canonicalString(),\r\n            appendMissingElements: {\r\n                values: transform.elements\r\n            }\r\n        };\r\n    }\r\n    else if (transform instanceof ArrayRemoveTransformOperation) {\r\n        return {\r\n            fieldPath: fieldTransform.field.canonicalString(),\r\n            removeAllFromArray: {\r\n                values: transform.elements\r\n            }\r\n        };\r\n    }\r\n    else if (transform instanceof NumericIncrementTransformOperation) {\r\n        return {\r\n            fieldPath: fieldTransform.field.canonicalString(),\r\n            increment: transform.operand\r\n        };\r\n    }\r\n    else {\r\n        throw fail();\r\n    }\r\n}\r\nfunction toDocumentsTarget(serializer, target) {\r\n    return { documents: [toQueryPath(serializer, target.path)] };\r\n}\r\nfunction toQueryTarget(serializer, target) {\r\n    // Dissect the path into parent, collectionId, and optional key filter.\r\n    const result = { structuredQuery: {} };\r\n    const path = target.path;\r\n    if (target.collectionGroup !== null) {\r\n        result.parent = toQueryPath(serializer, path);\r\n        result.structuredQuery.from = [\r\n            {\r\n                collectionId: target.collectionGroup,\r\n                allDescendants: true\r\n            }\r\n        ];\r\n    }\r\n    else {\r\n        result.parent = toQueryPath(serializer, path.popLast());\r\n        result.structuredQuery.from = [{ collectionId: path.lastSegment() }];\r\n    }\r\n    const where = toFilter(target.filters);\r\n    if (where) {\r\n        result.structuredQuery.where = where;\r\n    }\r\n    const orderBy = toOrder(target.orderBy);\r\n    if (orderBy) {\r\n        result.structuredQuery.orderBy = orderBy;\r\n    }\r\n    const limit = toInt32Proto(serializer, target.limit);\r\n    if (limit !== null) {\r\n        result.structuredQuery.limit = limit;\r\n    }\r\n    if (target.startAt) {\r\n        result.structuredQuery.startAt = toCursor(target.startAt);\r\n    }\r\n    if (target.endAt) {\r\n        result.structuredQuery.endAt = toCursor(target.endAt);\r\n    }\r\n    return result;\r\n}\r\nfunction convertQueryTargetToQuery(target) {\r\n    let path = fromQueryPath(target.parent);\r\n    const query = target.structuredQuery;\r\n    const fromCount = query.from ? query.from.length : 0;\r\n    let collectionGroup = null;\r\n    if (fromCount > 0) {\r\n        hardAssert(fromCount === 1);\r\n        const from = query.from[0];\r\n        if (from.allDescendants) {\r\n            collectionGroup = from.collectionId;\r\n        }\r\n        else {\r\n            path = path.child(from.collectionId);\r\n        }\r\n    }\r\n    let filterBy = [];\r\n    if (query.where) {\r\n        filterBy = fromFilter(query.where);\r\n    }\r\n    let orderBy = [];\r\n    if (query.orderBy) {\r\n        orderBy = fromOrder(query.orderBy);\r\n    }\r\n    let limit = null;\r\n    if (query.limit) {\r\n        limit = fromInt32Proto(query.limit);\r\n    }\r\n    let startAt = null;\r\n    if (query.startAt) {\r\n        startAt = fromCursor(query.startAt);\r\n    }\r\n    let endAt = null;\r\n    if (query.endAt) {\r\n        endAt = fromCursor(query.endAt);\r\n    }\r\n    return newQuery(path, collectionGroup, orderBy, filterBy, limit, \"F\" /* First */, startAt, endAt);\r\n}\r\nfunction toListenRequestLabels(serializer, targetData) {\r\n    const value = toLabel(serializer, targetData.purpose);\r\n    if (value == null) {\r\n        return null;\r\n    }\r\n    else {\r\n        return {\r\n            'goog-listen-tags': value\r\n        };\r\n    }\r\n}\r\nfunction toLabel(serializer, purpose) {\r\n    switch (purpose) {\r\n        case 0 /* Listen */:\r\n            return null;\r\n        case 1 /* ExistenceFilterMismatch */:\r\n            return 'existence-filter-mismatch';\r\n        case 2 /* LimboResolution */:\r\n            return 'limbo-document';\r\n        default:\r\n            return fail();\r\n    }\r\n}\r\nfunction toTarget(serializer, targetData) {\r\n    let result;\r\n    const target = targetData.target;\r\n    if (isDocumentTarget(target)) {\r\n        result = { documents: toDocumentsTarget(serializer, target) };\r\n    }\r\n    else {\r\n        result = { query: toQueryTarget(serializer, target) };\r\n    }\r\n    result.targetId = targetData.targetId;\r\n    if (targetData.resumeToken.approximateByteSize() > 0) {\r\n        result.resumeToken = toBytes(serializer, targetData.resumeToken);\r\n    }\r\n    else if (targetData.snapshotVersion.compareTo(SnapshotVersion.min()) > 0) {\r\n        // TODO(wuandy): Consider removing above check because it is most likely true.\r\n        // Right now, many tests depend on this behaviour though (leaving min() out\r\n        // of serialization).\r\n        result.readTime = toTimestamp(serializer, targetData.snapshotVersion.toTimestamp());\r\n    }\r\n    return result;\r\n}\r\nfunction toFilter(filters) {\r\n    if (filters.length === 0) {\r\n        return;\r\n    }\r\n    const protos = filters.map(filter => {\r\n        return toUnaryOrFieldFilter(filter);\r\n    });\r\n    if (protos.length === 1) {\r\n        return protos[0];\r\n    }\r\n    return { compositeFilter: { op: 'AND', filters: protos } };\r\n}\r\nfunction fromFilter(filter) {\r\n    if (!filter) {\r\n        return [];\r\n    }\r\n    else if (filter.unaryFilter !== undefined) {\r\n        return [fromUnaryFilter(filter)];\r\n    }\r\n    else if (filter.fieldFilter !== undefined) {\r\n        return [fromFieldFilter(filter)];\r\n    }\r\n    else if (filter.compositeFilter !== undefined) {\r\n        return filter.compositeFilter\r\n            .filters.map(f => fromFilter(f))\r\n            .reduce((accum, current) => accum.concat(current));\r\n    }\r\n    else {\r\n        return fail();\r\n    }\r\n}\r\nfunction toOrder(orderBys) {\r\n    if (orderBys.length === 0) {\r\n        return;\r\n    }\r\n    return orderBys.map(order => toPropertyOrder(order));\r\n}\r\nfunction fromOrder(orderBys) {\r\n    return orderBys.map(order => fromPropertyOrder(order));\r\n}\r\nfunction toCursor(cursor) {\r\n    return {\r\n        before: cursor.before,\r\n        values: cursor.position\r\n    };\r\n}\r\nfunction fromCursor(cursor) {\r\n    const before = !!cursor.before;\r\n    const position = cursor.values || [];\r\n    return new Bound(position, before);\r\n}\r\n// visible for testing\r\nfunction toDirection(dir) {\r\n    return DIRECTIONS[dir];\r\n}\r\n// visible for testing\r\nfunction fromDirection(dir) {\r\n    switch (dir) {\r\n        case 'ASCENDING':\r\n            return \"asc\" /* ASCENDING */;\r\n        case 'DESCENDING':\r\n            return \"desc\" /* DESCENDING */;\r\n        default:\r\n            return undefined;\r\n    }\r\n}\r\n// visible for testing\r\nfunction toOperatorName(op) {\r\n    return OPERATORS[op];\r\n}\r\nfunction fromOperatorName(op) {\r\n    switch (op) {\r\n        case 'EQUAL':\r\n            return \"==\" /* EQUAL */;\r\n        case 'NOT_EQUAL':\r\n            return \"!=\" /* NOT_EQUAL */;\r\n        case 'GREATER_THAN':\r\n            return \">\" /* GREATER_THAN */;\r\n        case 'GREATER_THAN_OR_EQUAL':\r\n            return \">=\" /* GREATER_THAN_OR_EQUAL */;\r\n        case 'LESS_THAN':\r\n            return \"<\" /* LESS_THAN */;\r\n        case 'LESS_THAN_OR_EQUAL':\r\n            return \"<=\" /* LESS_THAN_OR_EQUAL */;\r\n        case 'ARRAY_CONTAINS':\r\n            return \"array-contains\" /* ARRAY_CONTAINS */;\r\n        case 'IN':\r\n            return \"in\" /* IN */;\r\n        case 'NOT_IN':\r\n            return \"not-in\" /* NOT_IN */;\r\n        case 'ARRAY_CONTAINS_ANY':\r\n            return \"array-contains-any\" /* ARRAY_CONTAINS_ANY */;\r\n        case 'OPERATOR_UNSPECIFIED':\r\n            return fail();\r\n        default:\r\n            return fail();\r\n    }\r\n}\r\nfunction toFieldPathReference(path) {\r\n    return { fieldPath: path.canonicalString() };\r\n}\r\nfunction fromFieldPathReference(fieldReference) {\r\n    return FieldPath.fromServerFormat(fieldReference.fieldPath);\r\n}\r\n// visible for testing\r\nfunction toPropertyOrder(orderBy) {\r\n    return {\r\n        field: toFieldPathReference(orderBy.field),\r\n        direction: toDirection(orderBy.dir)\r\n    };\r\n}\r\nfunction fromPropertyOrder(orderBy) {\r\n    return new OrderBy(fromFieldPathReference(orderBy.field), fromDirection(orderBy.direction));\r\n}\r\nfunction fromFieldFilter(filter) {\r\n    return FieldFilter.create(fromFieldPathReference(filter.fieldFilter.field), fromOperatorName(filter.fieldFilter.op), filter.fieldFilter.value);\r\n}\r\n// visible for testing\r\nfunction toUnaryOrFieldFilter(filter) {\r\n    if (filter.op === \"==\" /* EQUAL */) {\r\n        if (isNanValue(filter.value)) {\r\n            return {\r\n                unaryFilter: {\r\n                    field: toFieldPathReference(filter.field),\r\n                    op: 'IS_NAN'\r\n                }\r\n            };\r\n        }\r\n        else if (isNullValue(filter.value)) {\r\n            return {\r\n                unaryFilter: {\r\n                    field: toFieldPathReference(filter.field),\r\n                    op: 'IS_NULL'\r\n                }\r\n            };\r\n        }\r\n    }\r\n    else if (filter.op === \"!=\" /* NOT_EQUAL */) {\r\n        if (isNanValue(filter.value)) {\r\n            return {\r\n                unaryFilter: {\r\n                    field: toFieldPathReference(filter.field),\r\n                    op: 'IS_NOT_NAN'\r\n                }\r\n            };\r\n        }\r\n        else if (isNullValue(filter.value)) {\r\n            return {\r\n                unaryFilter: {\r\n                    field: toFieldPathReference(filter.field),\r\n                    op: 'IS_NOT_NULL'\r\n                }\r\n            };\r\n        }\r\n    }\r\n    return {\r\n        fieldFilter: {\r\n            field: toFieldPathReference(filter.field),\r\n            op: toOperatorName(filter.op),\r\n            value: filter.value\r\n        }\r\n    };\r\n}\r\nfunction fromUnaryFilter(filter) {\r\n    switch (filter.unaryFilter.op) {\r\n        case 'IS_NAN':\r\n            const nanField = fromFieldPathReference(filter.unaryFilter.field);\r\n            return FieldFilter.create(nanField, \"==\" /* EQUAL */, {\r\n                doubleValue: NaN\r\n            });\r\n        case 'IS_NULL':\r\n            const nullField = fromFieldPathReference(filter.unaryFilter.field);\r\n            return FieldFilter.create(nullField, \"==\" /* EQUAL */, {\r\n                nullValue: 'NULL_VALUE'\r\n            });\r\n        case 'IS_NOT_NAN':\r\n            const notNanField = fromFieldPathReference(filter.unaryFilter.field);\r\n            return FieldFilter.create(notNanField, \"!=\" /* NOT_EQUAL */, {\r\n                doubleValue: NaN\r\n            });\r\n        case 'IS_NOT_NULL':\r\n            const notNullField = fromFieldPathReference(filter.unaryFilter.field);\r\n            return FieldFilter.create(notNullField, \"!=\" /* NOT_EQUAL */, {\r\n                nullValue: 'NULL_VALUE'\r\n            });\r\n        case 'OPERATOR_UNSPECIFIED':\r\n            return fail();\r\n        default:\r\n            return fail();\r\n    }\r\n}\r\nfunction toDocumentMask(fieldMask) {\r\n    const canonicalFields = [];\r\n    fieldMask.fields.forEach(field => canonicalFields.push(field.canonicalString()));\r\n    return {\r\n        fieldPaths: canonicalFields\r\n    };\r\n}\r\nfunction isValidResourceName(path) {\r\n    // Resource names have at least 4 components (project ID, database ID)\r\n    return (path.length >= 4 &&\r\n        path.get(0) === 'projects' &&\r\n        path.get(2) === 'databases');\r\n}\n\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\n/**\r\n * An immutable set of metadata that the local store tracks for each target.\r\n */\r\nclass TargetData {\r\n    constructor(\r\n    /** The target being listened to. */\r\n    target, \r\n    /**\r\n     * The target ID to which the target corresponds; Assigned by the\r\n     * LocalStore for user listens and by the SyncEngine for limbo watches.\r\n     */\r\n    targetId, \r\n    /** The purpose of the target. */\r\n    purpose, \r\n    /**\r\n     * The sequence number of the last transaction during which this target data\r\n     * was modified.\r\n     */\r\n    sequenceNumber, \r\n    /** The latest snapshot version seen for this target. */\r\n    snapshotVersion = SnapshotVersion.min(), \r\n    /**\r\n     * The maximum snapshot version at which the associated view\r\n     * contained no limbo documents.\r\n     */\r\n    lastLimboFreeSnapshotVersion = SnapshotVersion.min(), \r\n    /**\r\n     * An opaque, server-assigned token that allows watching a target to be\r\n     * resumed after disconnecting without retransmitting all the data that\r\n     * matches the target. The resume token essentially identifies a point in\r\n     * time from which the server should resume sending results.\r\n     */\r\n    resumeToken = ByteString.EMPTY_BYTE_STRING) {\r\n        this.target = target;\r\n        this.targetId = targetId;\r\n        this.purpose = purpose;\r\n        this.sequenceNumber = sequenceNumber;\r\n        this.snapshotVersion = snapshotVersion;\r\n        this.lastLimboFreeSnapshotVersion = lastLimboFreeSnapshotVersion;\r\n        this.resumeToken = resumeToken;\r\n    }\r\n    /** Creates a new target data instance with an updated sequence number. */\r\n    withSequenceNumber(sequenceNumber) {\r\n        return new TargetData(this.target, this.targetId, this.purpose, sequenceNumber, this.snapshotVersion, this.lastLimboFreeSnapshotVersion, this.resumeToken);\r\n    }\r\n    /**\r\n     * Creates a new target data instance with an updated resume token and\r\n     * snapshot version.\r\n     */\r\n    withResumeToken(resumeToken, snapshotVersion) {\r\n        return new TargetData(this.target, this.targetId, this.purpose, this.sequenceNumber, snapshotVersion, this.lastLimboFreeSnapshotVersion, resumeToken);\r\n    }\r\n    /**\r\n     * Creates a new target data instance with an updated last limbo free\r\n     * snapshot version number.\r\n     */\r\n    withLastLimboFreeSnapshotVersion(lastLimboFreeSnapshotVersion) {\r\n        return new TargetData(this.target, this.targetId, this.purpose, this.sequenceNumber, this.snapshotVersion, lastLimboFreeSnapshotVersion, this.resumeToken);\r\n    }\r\n}\n\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\n/** Serializer for values stored in the LocalStore. */\r\nclass LocalSerializer {\r\n    constructor(remoteSerializer) {\r\n        this.remoteSerializer = remoteSerializer;\r\n    }\r\n}\r\n/**\r\n * Encodes a `BundledQuery` from bundle proto to a Query object.\r\n *\r\n * This reconstructs the original query used to build the bundle being loaded,\r\n * including features exists only in SDKs (for example: limit-to-last).\r\n */\r\nfunction fromBundledQuery(bundledQuery) {\r\n    const query = convertQueryTargetToQuery({\r\n        parent: bundledQuery.parent,\r\n        structuredQuery: bundledQuery.structuredQuery\r\n    });\r\n    if (bundledQuery.limitType === 'LAST') {\r\n        return queryWithLimit(query, query.limit, \"L\" /* Last */);\r\n    }\r\n    return query;\r\n}\r\n/** Encodes a NamedQuery proto object to a NamedQuery model object. */\r\nfunction fromProtoNamedQuery(namedQuery) {\r\n    return {\r\n        name: namedQuery.name,\r\n        query: fromBundledQuery(namedQuery.bundledQuery),\r\n        readTime: fromVersion(namedQuery.readTime)\r\n    };\r\n}\r\n/** Decodes a BundleMetadata proto into a BundleMetadata object. */\r\nfunction fromBundleMetadata(metadata) {\r\n    return {\r\n        id: metadata.id,\r\n        version: metadata.version,\r\n        createTime: fromVersion(metadata.createTime)\r\n    };\r\n}\n\n/**\r\n * @license\r\n * Copyright 2019 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\n/**\r\n * An in-memory implementation of IndexManager.\r\n */\r\nclass MemoryIndexManager {\r\n    constructor() {\r\n        this.collectionParentIndex = new MemoryCollectionParentIndex();\r\n    }\r\n    addToCollectionParentIndex(transaction, collectionPath) {\r\n        this.collectionParentIndex.add(collectionPath);\r\n        return PersistencePromise.resolve();\r\n    }\r\n    getCollectionParents(transaction, collectionId) {\r\n        return PersistencePromise.resolve(this.collectionParentIndex.getEntries(collectionId));\r\n    }\r\n}\r\n/**\r\n * Internal implementation of the collection-parent index exposed by MemoryIndexManager.\r\n * Also used for in-memory caching by IndexedDbIndexManager and initial index population\r\n * in indexeddb_schema.ts\r\n */\r\nclass MemoryCollectionParentIndex {\r\n    constructor() {\r\n        this.index = {};\r\n    }\r\n    // Returns false if the entry already existed.\r\n    add(collectionPath) {\r\n        const collectionId = collectionPath.lastSegment();\r\n        const parentPath = collectionPath.popLast();\r\n        const existingParents = this.index[collectionId] ||\r\n            new SortedSet(ResourcePath.comparator);\r\n        const added = !existingParents.has(parentPath);\r\n        this.index[collectionId] = existingParents.add(parentPath);\r\n        return added;\r\n    }\r\n    has(collectionPath) {\r\n        const collectionId = collectionPath.lastSegment();\r\n        const parentPath = collectionPath.popLast();\r\n        const existingParents = this.index[collectionId];\r\n        return existingParents && existingParents.has(parentPath);\r\n    }\r\n    getEntries(collectionId) {\r\n        const parentPaths = this.index[collectionId] ||\r\n            new SortedSet(ResourcePath.comparator);\r\n        return parentPaths.toArray();\r\n    }\r\n}\n\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\n/** Offset to ensure non-overlapping target ids. */\r\nconst OFFSET = 2;\r\n/**\r\n * Generates monotonically increasing target IDs for sending targets to the\r\n * watch stream.\r\n *\r\n * The client constructs two generators, one for the target cache, and one for\r\n * for the sync engine (to generate limbo documents targets). These\r\n * generators produce non-overlapping IDs (by using even and odd IDs\r\n * respectively).\r\n *\r\n * By separating the target ID space, the query cache can generate target IDs\r\n * that persist across client restarts, while sync engine can independently\r\n * generate in-memory target IDs that are transient and can be reused after a\r\n * restart.\r\n */\r\nclass TargetIdGenerator {\r\n    constructor(lastId) {\r\n        this.lastId = lastId;\r\n    }\r\n    next() {\r\n        this.lastId += OFFSET;\r\n        return this.lastId;\r\n    }\r\n    static forTargetCache() {\r\n        // The target cache generator must return '2' in its first call to `next()`\r\n        // as there is no differentiation in the protocol layer between an unset\r\n        // number and the number '0'. If we were to sent a target with target ID\r\n        // '0', the backend would consider it unset and replace it with its own ID.\r\n        return new TargetIdGenerator(2 - OFFSET);\r\n    }\r\n    static forSyncEngine() {\r\n        // Sync engine assigns target IDs for limbo document detection.\r\n        return new TargetIdGenerator(1 - OFFSET);\r\n    }\r\n}\n\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\n/**\r\n * Verifies the error thrown by a LocalStore operation. If a LocalStore\r\n * operation fails because the primary lease has been taken by another client,\r\n * we ignore the error (the persistence layer will immediately call\r\n * `applyPrimaryLease` to propagate the primary state change). All other errors\r\n * are re-thrown.\r\n *\r\n * @param err - An error returned by a LocalStore operation.\r\n * @returns A Promise that resolves after we recovered, or the original error.\r\n */\r\nasync function ignoreIfPrimaryLeaseLoss(err) {\r\n    if (err.code === Code.FAILED_PRECONDITION &&\r\n        err.message === PRIMARY_LEASE_LOST_ERROR_MSG) {\r\n        logDebug('LocalStore', 'Unexpectedly lost primary lease');\r\n    }\r\n    else {\r\n        throw err;\r\n    }\r\n}\n\n/**\r\n * @license\r\n * Copyright 2018 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\nconst LRU_COLLECTION_DISABLED = -1;\r\nconst LRU_DEFAULT_CACHE_SIZE_BYTES = 40 * 1024 * 1024;\n\n/**\r\n * @license\r\n * Copyright 2020 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\nconst LRU_MINIMUM_CACHE_SIZE_BYTES = 1 * 1024 * 1024;\n\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\n/**\r\n * A map implementation that uses objects as keys. Objects must have an\r\n * associated equals function and must be immutable. Entries in the map are\r\n * stored together with the key being produced from the mapKeyFn. This map\r\n * automatically handles collisions of keys.\r\n */\r\nclass ObjectMap {\r\n    constructor(mapKeyFn, equalsFn) {\r\n        this.mapKeyFn = mapKeyFn;\r\n        this.equalsFn = equalsFn;\r\n        /**\r\n         * The inner map for a key/value pair. Due to the possibility of collisions we\r\n         * keep a list of entries that we do a linear search through to find an actual\r\n         * match. Note that collisions should be rare, so we still expect near\r\n         * constant time lookups in practice.\r\n         */\r\n        this.inner = {};\r\n    }\r\n    /** Get a value for this key, or undefined if it does not exist. */\r\n    get(key) {\r\n        const id = this.mapKeyFn(key);\r\n        const matches = this.inner[id];\r\n        if (matches === undefined) {\r\n            return undefined;\r\n        }\r\n        for (const [otherKey, value] of matches) {\r\n            if (this.equalsFn(otherKey, key)) {\r\n                return value;\r\n            }\r\n        }\r\n        return undefined;\r\n    }\r\n    has(key) {\r\n        return this.get(key) !== undefined;\r\n    }\r\n    /** Put this key and value in the map. */\r\n    set(key, value) {\r\n        const id = this.mapKeyFn(key);\r\n        const matches = this.inner[id];\r\n        if (matches === undefined) {\r\n            this.inner[id] = [[key, value]];\r\n            return;\r\n        }\r\n        for (let i = 0; i < matches.length; i++) {\r\n            if (this.equalsFn(matches[i][0], key)) {\r\n                matches[i] = [key, value];\r\n                return;\r\n            }\r\n        }\r\n        matches.push([key, value]);\r\n    }\r\n    /**\r\n     * Remove this key from the map. Returns a boolean if anything was deleted.\r\n     */\r\n    delete(key) {\r\n        const id = this.mapKeyFn(key);\r\n        const matches = this.inner[id];\r\n        if (matches === undefined) {\r\n            return false;\r\n        }\r\n        for (let i = 0; i < matches.length; i++) {\r\n            if (this.equalsFn(matches[i][0], key)) {\r\n                if (matches.length === 1) {\r\n                    delete this.inner[id];\r\n                }\r\n                else {\r\n                    matches.splice(i, 1);\r\n                }\r\n                return true;\r\n            }\r\n        }\r\n        return false;\r\n    }\r\n    forEach(fn) {\r\n        forEach(this.inner, (_, entries) => {\r\n            for (const [k, v] of entries) {\r\n                fn(k, v);\r\n            }\r\n        });\r\n    }\r\n    isEmpty() {\r\n        return isEmpty(this.inner);\r\n    }\r\n}\n\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\n/**\r\n * An in-memory buffer of entries to be written to a RemoteDocumentCache.\r\n * It can be used to batch up a set of changes to be written to the cache, but\r\n * additionally supports reading entries back with the `getEntry()` method,\r\n * falling back to the underlying RemoteDocumentCache if no entry is\r\n * buffered.\r\n *\r\n * Entries added to the cache *must* be read first. This is to facilitate\r\n * calculating the size delta of the pending changes.\r\n *\r\n * PORTING NOTE: This class was implemented then removed from other platforms.\r\n * If byte-counting ends up being needed on the other platforms, consider\r\n * porting this class as part of that implementation work.\r\n */\r\nclass RemoteDocumentChangeBuffer {\r\n    constructor() {\r\n        // A mapping of document key to the new cache entry th